{
    "Title": "Benchmarking Large Language Model Volatility",
    "Authors": "Yu, Boyang",
    "Year": "No year available",
    "Abstract": "The impact of non-deterministic outputs from Large Language Models (LLMs) is\nnot well examined for financial text understanding tasks. Through a compelling\ncase study on investing in the US equity market via news sentiment analysis, we\nuncover substantial variability in sentence-level sentiment classification\nresults, underscoring the innate volatility of LLM outputs. These uncertainties\ncascade downstream, leading to more significant variations in portfolio\nconstruction and return. While tweaking the temperature parameter in the\nlanguage model decoder presents a potential remedy, it comes at the expense of\nstifled creativity. Similarly, while ensembling multiple outputs mitigates the\neffect of volatile outputs, it demands a notable computational investment. This\nwork furnishes practitioners with invaluable insights for adeptly navigating\nuncertainty in the integration of LLMs into financial decision-making,\nparticularly in scenarios dictated by non-deterministic information.Comment: 7 pages, 2 figures, Workshop on AI Safety and Robustness In Finance,\n  ICAIF 202",
    "Keywords": "No keywords available",
    "Publisher": "",
    "Publication Date": "No publication date available",
    "Journal": "No journal available",
    "Citation Count": 0,
    "Full Text": "Benchmarking Large Language Model VolatilityBOYANG YU∗, Center for Data Science, New York University, USAThe impact of non-deterministic outputs from Large Language Models (LLMs) is not well examined for financial text understandingtasks. Through a compelling case study on investing in the US equity market via news sentiment analysis, we uncover substantialvariability in sentence-level sentiment classification results, underscoring the innate volatility of LLM outputs. These uncertaintiescascade downstream, leading to more significant variations in portfolio construction and return. While tweaking the temperatureparameter in the language model decoder presents a potential remedy, it comes at the expense of stifled creativity. Similarly, whileensemblingmultiple outputs mitigates the effect of volatile outputs, it demands a notable computational investment. This work furnishespractitioners with invaluable insights for adeptly navigating uncertainty in the integration of LLMs into financial decision-making,particularly in scenarios dictated by non-deterministic information.Additional Key Words and Phrases: Large language model, Uncertainty quantification, Robustness, Sentiment analysisACM Reference Format:Boyang Yu. 2023. Benchmarking Large Language Model Volatility. In AISRF ’23: ICAIF Workshop on AI Safety and Robustness in Finance,November 27, 2023, New York, NY. ACM, New York, NY, USA, 7 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn1 INTRODUCTIONLarge Language Models (LLMs) have demonstrated impressive capabilities in various natural language processingtasks[7, 9, 14], including sentiment prediction. However, their application in the financial domain presents uniquechallenges, primarily stemming from the inherently abstract nature of the task[8].In the context of financial decision-making, the ability to quantify volatility has paramount importance. Understandingand managing volatility allows for a more informed and robust approach towards financial strategies, whether it’sdetermining the allocation of assets in a portfolio or evaluating the potential risks and returns associated with specificinvestment opportunities.The broader landscape of uncertainty quantification in textual analysis offers crucial insights. In various domains,subjective judgments, vague language, and diverse interpretations necessitate a nuanced approach to uncertaintyassessment. For instance, consider sentiment analysis in customer reviews for a product. A statement like \"The productis good, but not great\" introduces ambiguity. Similarly, in legal documents, the interpretation of contractual clausesmay hinge on subtle linguistic nuances. Here, techniques like semantic ambiguity detection or probabilistic modelingprovide avenues for handling uncertainty[7, 8]. There are many quantitative metrics to evaluate the level of uncertainty,such as model confidence or entropy[2, 6].However, traditional uncertainty quantification methods often rely on model generated probabilities or embeddings,requiring direct access to language model’s intermediate output. In modern large language models, such as ChatGenerative Pre-trained Transformers (ChatGPT)[10] and Large Language Model Meta AI (LLaMA)[12], end users oftenlack a direct access to anything other than the generated text. This lack of transparency can make it challenging toPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are notmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for componentsof this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or toredistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.© 2023 Association for Computing Machinery.Manuscript submitted to ACM1arXiv:2311.15180v1  [q-fin.TR]  26 Nov 2023AI Safety and Robustness in Finance Workshop on ICAIF, 2023, New York, NY B. Yuunderstand how and why the model arrives at a particular prediction or output. As a result, it becomes crucial to developmethods that allow for a practical assessment of uncertainty in order to enhance the reliability and trustworthiness ofmodel outputs.The task of news sentiment analysis presents an ideal evaluation ground for assess the level of variation, orvolatility. Inherent uncertainties and non-deterministic outputs both contribute to volatility. Furthermore, tracingthe effects of volatile outputs in the subsequent investment process provides a tangible demonstration of how thesenuances reverberate through each stage of decision-making. A previous study investigates stock price prediction usingChatGPT[9]. Researchers extract news sentiment related to price change, aggregate sentiment scores at a daily tickerlevel, analyze the relationship between sentiment score and excess return, and ultimately construct a portfolio for theUS stock market. Their primary focus was on assessing the impact of increased language model capacity on returnpredictability. However, the volatility perspective remained unexplored. Our work aims to delve deeper, evaluating howvolatile model outputs potentially impact investment returns and to what extent.This study seeks to address a series of pertinent research questions that arise from the interaction between LLMs,financial sentiment prediction, and volatility quantification. We are interested in• Quantifying LLM uncertainty without direct access to model generated probabilities• Understanding the limitations of volatile sentiment predictions on trading signals executionWe first demonstrate that the presence of uncertainty in sentiment classification regardless of temperature settingand its profound implications on downstream tasks, particularly in portfolio construction and return. The resultingvariability underscores the need for careful consideration when utilizing LLMs in financial decision-making processes.This discovery reinforces the importance of acknowledging and managing the inherent non-determinism in LLMoutputs.The paper is organized as follows: Section 2 provides background on uncertainty quantification and sentimentanalysis for trading strategy. Section 3 covers methodology, including data description and modeling. Section 4 outlinesexperiment design and results. Finally, Section 5 concludes and discusses key findings.2 BACKGROUNDIn this section, we describe the specific type of uncertainty under examination in the context of using Large LanguageModels to perform sentiment analysis for investment decision making, meanwhile introducing terminologies used inthe rest of the paper.2.1 Pre-trained Large Language ModelsPre-trained Large Language Models(LLMs) are powered by deep learning techniques and undergo training on extensivetext corpora. Their primary objective is to predict the next token given previous sequence. By learning conditionalprobability distributions for tokens based on prior sequences, LLMs gain a profound understanding of language nuances.The success of large languagemodels hinges on their information encoding and token sampling processes. State-of-the-art model architectures, such as GPT and LLaMA, employ transformer architectures with self-attention mechanisms[13],enabling them to grasp intricate language nuances. During the sampling phase, tokens with higher probabilities arefavored as the next token. This preference is modulated by the temperature parameter, which governs the smoothnessof probability distribution. Increasing temperature leads to more creative prediction. In practice, a temperature of 0 ischosen for the goal of determinism[9, 14, 15].2Benchmarking Large Language Model Volatility AI Safety and Robustness in Finance Workshop on ICAIF, 2023, New York, NYAI community have an ongoing debate about model sharing. Some advocate open source, such as Meta LLaMA,promoting that shared tools encourage collaboration, transparency, and accessibility. Some are extremely cautious inopen source, such as OpenAI ChatGPT, arguing that unrestricted access to advanced AI models might lead to potentialmisuse of the technology[10]. Despite the attitude, both sides have made outstanding progress in natural languageunderstanding tasks, where GPT-3.5( backend of free version of ChatGPT) and LLaMA2 excel in many benchmarks.In the analysis, we use both the GPT and LLaMA model families. Specifically, we focus on the light weighted versionsof their interactive chatbot backends, GPT-3.5-turbo and LLaMA-7b. We study the models in a zero-shot setup, i.e.,without providing additional training where we present text to models and ask them to provide a response containingsentiment labels.2.2 Sentiment Analysis and Investment Decision-MakingSentiment extraction benefits from LLMs’ linguistic capabilities, while not explicitly designed for predicting assetprices[9, 14, 15]. These models’ ability to discern contextual meanings and linguistic patterns could potentially extractvaluable insights about a firm’s prospects from textual data, such as news headlines, even in the absence of directfinancial training. This opens up new avenues for utilizing natural language processing in financial analysis.Recent studies that use ChatGPT in investment decision-making process include Lopez-Lira and Tang findingChatGPT is able to predict stock movement[9], and Yang and Menczer[15] demonstrating ChatGPT successfullyidentifies credible news outlets. These studies collectively illustrate the potential of Large Language Models (LLMs) inenhancing financial decision-making.2.3 VolatilityQuantificationAn unspoken rule in combining LLMs and financial text is setting temperature equals 0 to maximize determinism ofmodel output. Now the question is, how much volatility is left and how much will there be if we increase temperature.Volatility in non-deterministic model outputs refers to the degree of variation or instability in the generated responsesof a model. In the context of language models or AI systems, this means that when the same input is given multipletimes, the model produces different responses. It’s important to understand and manage this volatility based on thespecific requirements and goals of the application.The temperature parameter plays a pivotal role in regulating the randomness in the generation process. It is ahyper-parameter that controls the likelihood of selecting tokens during text generation. When the temperature is set toa high value, such as 1.0 or 2.0, it introduces more randomness by assigning nearly equal probabilities to a wide rangeof tokens. In contrast, setting temperature to a low value, such as 0, the generation process becomes less random.Published studies favors zero temperature to maximize reproducibility[7, 9, 14, 15]. Note that a temperature of 0has its downsides. First, it does not guarantee determinism since small numerical discrepancies in floating precisionand distributed computation can cause deviations in the output. Moreover, in financial sentiment extraction, zerotemperatures limit the model’s capability to explore different interpretations and provide a more comprehensiveunderstanding of the text.We propose to analyse language processes through their generated samples, because black-box LLMs do not explicitlyreturn probability scores[7, 8]. In light of comparing model output in multiple repetitions in uncertainty quantificationliterature(MC dropout[2] and deep ensemble[6]), we calculate lexical and semantic variation statistics on model outputsacross different runs[3].3AI Safety and Robustness in Finance Workshop on ICAIF, 2023, New York, NY B. Yu3 METHODS3.1 DataWe utilize two primary data sources for our analysis: Unicorn Data Services (EOD Historica lData | EODHD) forhistorical price data and news headlines, as well as Aylien for addtional news headlines. The sample period begins inOctober 2021 (which avoids potential coverage of ChatGPT’s training data) and ends in September 2023. This sampleperiod ensures that our evaluation is based on information not present in the ChatGPT’s training data, allowing for amore accurate “out-of-sample” assessment of its predictive capabilities. For LLaMA, as it’s training data is as recent asJuly 2023, we believe if we keep the strict “out-of-sample” assessment requirement, we will have an extremely shortperiod of evaluation data. So we keep the entire data since October 2021, and are interested in if additional trainingdata in LLaMA improves sentiment analysis and investment performance.The EODHD provides API to retrieve daily stock prices, and finance news feeds from Yahoo. Our analysis focuson S&P 500 companies for simplicity and best reproducibility. We filter news feeds mentioning related s&p tickersand only related to less than three tickers. The Aylien API[4] serves as an additional data source for collecting newsheadlines from other sources, namely MSN, CNN, Seeking Alpha and Fox Business. In this data source, we explicitly setticker prominence greater than or equal to 0.8 to ensure only relevance. Furthermore, we eliminate duplicated newsentries by headlines and timestamp. Altogether we collect 216,737 headlines for S&P 500 tickers.We map the timing in daily price data and dense news feed data by date. The date of news feed is defined by settinga cutoff time for daily trading at 3pm and setting the news effective date as its next actionable trading date.3.2 PromptPrompt engineering is a crucial step in seeking applicable LLMs responses. A concise and instructive prompt providescontext and saves computation time.For open source models, such as LLaMA2-7B, we apply a customized prompt, see Tab. 1 to each of the headlines. Thespecial tokens at the beginning and near the end are LLaMA2 specific template to create templates for system messagesin chatbot-like LLMs. The prompt asks the LLM to produce sentiment labels and associate confidence.For close source models like GPT-3.5, we need to consider reduce repeated system messages to overcome query ratelimit constraint[1]. We deploy a batch-prompt strategy where we integrate 50 news headlines in one prompt, indexedby numbers, shown in Tab. 1. Similarly, we begin and end the prompt with specific instructions. The final instructionsin the bracket is to avoid later sentences omitted due to a hard cutoff in model output length.3.3 Volatility metricsLexical volatility is measured by edit distance betweenmodel outputs for each headline. For instance, all zero temperatureruns generate altogether three outputs, named by 𝑂𝑖 (𝑖 = 1, ..., 𝑘). The final edit distance is given by 𝐷𝑖 𝑗/𝐿𝑖 + 𝐷𝑖 𝑗/𝐿𝑗where 𝐷𝑖 𝑗 stands for the edit distance between the i-th and j-th output, the 𝐿 term is the string length. This aggregationensure the metric is output length invariant. Aggregating headline level metric gives overall volatility in lexical aspect.Semantic volatility is explicitly measured at different levels, feed-level and ticker-level. For each output, we extractsentiment labels using rule-based string comparison to search for the appearance of \"positive\", \"neutral\" and \"negative\"and possible negations to derive a feed-level sentiment class label for each headline. The final label is 1 if \"positive\" or\"not negative\" presents in the response. It is -1 if \"negative\" or \"not positive\" is found. All other ambiguous responsesare assigned 0 as a proxy for neural. We split the batch-prompt response by headline indexes given in the prompt and4Benchmarking Large Language Model Volatility AI Safety and Robustness in Finance Workshop on ICAIF, 2023, New York, NYTable 1. Prompt design.LLaMA GPTInput<s>[INST] {{ You are a helpful assistant who onlyreplies according to instructions. Decide the text’ssentiment is positive, neutral, or negative. Indicateyour confidence using a float between 0 and 1.Text: {HEADLINE} (instruction) Please answerin the form of SENTIMENT_LABEL(CONFIDENCE). }} [/INST]Ans:Decide whether each piece of text’s sentiment ispositive, neutral, or negative. Indicate yourconfidence for each piece using a float numberbetween 0 and 1.Text:1. {HEADLINE_1}2. {HEADLINE_2}...50. {HEADLINE_50}Sentiment for each(label and score only):use the same rule to match sentiment labels. At feed-level, we calculate the range of sentiment score across differentruns. At ticker-level, if a ticker has multiple feeds per day, we take the average sentiment scores as the ticker-levelsentiment score and derive the range of variation. Both feed-level and ticker-level ranges are averaged over the entirecorpus to measure overall explicit semantic volatility.Semantic volatility can be implicit, when using volatile sentiment scores for downstream investment decision. Wedeploy a simple trading daily trading strategy using ticker-level sentiment scores without fitting. These scores aretransformed into stock positions by calculating sentiment score deviation from all tickers’ historical rolling mean witha look back window of one month. The deviation accounts cross-sectional recent fluctuations and LLMs’ bias towardspositivity([11]). We adopt a long-short strategy to adjust holding positions on a daily basis. The back test period coversOctober 2021 to September 2023.4 RESULTSFor open source LLaMA, we investigate 4 temperature settings (t = 0, 0.25, 0.5, 1.0, following an experimental workwith general language generation [5]) with 3 repetitions each. For close source ChatGPT, we only verify our findingswith 2 temperature settings (t = 0, 1).Fig. 1. Volatility persists in LLM output. \"Feed\" refers to variation in individual LLM response. \"Ticker\" refers to daily sentiment scorefor each stock. (Left) Average edit distance over model generated text corpus. (Right) Sentiment score discrepancy is inherent at bothfeed-level and ticker-level.5AI Safety and Robustness in Finance Workshop on ICAIF, 2023, New York, NY B. YuTable 2. Strategy performance is affected by volatile sentiment scores. We report the mean and standard deviation of total return andSharpe.Temperature t = 0.0 t = 0.25 t = 0.5 t = 1.0LLaMARet(%) 8.51 ± 0.25 8.22 ± 1.19 7.92 ± 2.64 8.82 ± 2.72Sharpe 1.41 ± 0.04 1.48 ± 0.15 1.38 ± 0.38 1.46 ± 0.45ChatGPTRet(%) 6.13 ± 0.88 - - 7.53 ± 0.84Sharpe 1.12 ± 0.13 - - 1.45 ± 0.17Fig. 2. A long-short strategy show volatile returns using LLM sentiment scores. The accumulated PnLs are plotted for two settings,low temperature (t=0.0) and high temperature (t=1.0). Each setting is repeated three times. Curves reflect: 1) Non-deterministic modeloutputs cause instability in portfolio return. 2) High temperature produce more volatile investment strategies.4.1 Lexical and Semantic Volatility Persists in LLM outputNon-deterministic LLMs outputs show variations in formats and word choices of natural language. Average editdistance between responses are greater than zero for all temperature settings, as shown in Fig. 1. Notably, even at azero temperature setting, subtle variations persist. As the temperature increases, the volatility of text generation resultsalso escalates. It it worth noticing that GPT responses are move volatile, partly due to the batch-prompt approach. Aninteresting future direction is to investigate a low-volatile and token-efficient prompt.The diversity and variations in the meanings or interpretations of persist in LLM generated responses. In bothfeed-level and ticker-level, both LLaMA and GPT model show substantial amount of discrepancy across runs. Again,zero temperature does not eliminate semantic volatility. Model-wise, GPT model responses are more stable in changingtemperature setting.4.2 Long-Short Performance Fluctuation with Non-Deterministic SentimentsQualitative volatility in strategy performance is shown in Fig. 2. Lower temperatures are successful in reducing volatility,but they underperform in comparison to the best results achieved at higher temperatures. Notably, the significantdisparity (11% return v.s. 5% percent return) between the best and worst-performing high-temperature repetitions raisesconcerns about the robustness of AI in safety-critical systems.We report quantitative strategy performance in Tab. 2. We highlight again the increasing return and Sharpe ratiocomes together with more variation in a high temperature setting. Similar to previous subsection, we observe theLLaMA model being more sensitive to the change in temperature. This observation underscores the importance ofcarefully evaluating the reliability and performance of AI models in the context of automated trading applications.6Benchmarking Large Language Model Volatility AI Safety and Robustness in Finance Workshop on ICAIF, 2023, New York, NYREFERENCES[1] Arefeen, M. A., Debnath, B., and Chakradhar, S. Leancontext: Cost-efficient domain-specific question answering using llms. arXiv preprintarXiv:2309.00841 (2023).[2] Gal, Y., and Ghahramani, Z. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In international conferenceon machine learning (2016), PMLR, pp. 1050–1059.[3] Giulianelli, M., Baan, J., Aziz, W., Fernández, R., and Plank, B. What comes next? evaluating uncertainty in neural text generators againsthuman production variability. arXiv preprint arXiv:2305.11707 (2023).[4] Hokamp, C., Ghalandari, D. G., and Ghaffari, P. News signals: An nlp library for text and time series. In 3rd Workshop for Natural LanguageProcessing Open Source Software (2023).[5] Kuhn, L., Gal, Y., and Farqhar, S. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. arXivpreprint arXiv:2302.09664 (2023).[6] Lakshminarayanan, B., Pritzel, A., and Blundell, C. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances inneural information processing systems 30 (2017).[7] Lin, Z., Trivedi, S., and Sun, J. Generating with confidence: Uncertainty quantification for black-box large language models. arXiv preprintarXiv:2305.19187 (2023).[8] Liu, S., Kaku, A., Zhu, W., Leibovich, M., Mohan, S., Yu, B., Huang, H., Zanna, L., Razavian, N., Niles-Weed, J., et al. Deep probabilityestimation. arXiv preprint arXiv:2111.10734 (2021).[9] Lopez-Lira, A., and Tang, Y. Can chatgpt forecast stock price movements? return predictability and large language models. arXiv preprintarXiv:2304.07619 (2023).[10] OpenAI. Gpt-4 technical report, 2023.[11] Seshadri, P., Pezeshkpour, P., and Singh, S. Quantifying social biases using templates is unreliable. arXiv preprint arXiv:2210.04337 (2022).[12] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama:Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).[13] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. Attention is all you need. Advances inneural information processing systems 30 (2017).[14] Woodhouse, D., and Charlesworth, A. Can chatgpt predict future interest rate decisions? Available at SSRN 4572831 (2023).[15] Yang, K.-C., and Menczer, F. Large language models can rate news outlet credibility. arXiv preprint arXiv:2304.00228 (2023).5 ACKNOWLEDGMENTSThe author appreciates insightful discussion with Minhua Zhang and Michal Mucha.6 APPENDICES7 COSTEODHD API subscription costs $19.99. ChatGPT costs about $14.5 for one pass (estimated error rate about 5%, needaddtional budget to rerun these queries). All ChatGPT experiments costs $ 67.98.accepted 19 November 20097",
    "Link": "http://arxiv.org/abs/2311.15180"
}