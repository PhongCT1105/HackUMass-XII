{
    "Title": "Using Parsimonious Language Models on Web Data",
    "Authors": "Hiemstra, Djoerd, Kamps, Jaap, Kaptein, Rianne, Li, Rongmei",
    "Year": "No year available",
    "Abstract": "In this paper we explore the use of parsimonious language models for web retrieval. These models are smaller thus more efficient than the standard language models and are therefore well suited for large-scale web retrieval. We have conducted experiments on four TREC topic sets, and found that the parsimonious language model results in improvement of retrieval effectiveness over the standard language model for all data-sets and measures. In all cases the improvement is significant, and more substantial than in earlier experiments\\ud\non newspaper/newswire data",
    "Keywords": "No keywords available",
    "Publisher": "ACM Press",
    "Publication Date": "No publication date available",
    "Journal": "No journal available",
    "Citation Count": 0,
    "Full Text": "Using Parsimonious Language Models on Web Data\nRianne Kaptein1 Rongmei LI2 Djoerd Hiemstra2 Jaap Kamps1,3\n1 Archives and Information Studies, Faculty of Humanities, University of Amsterdam\n2 Database Group, University of Twente\n3 ISLA, Informatics Institute, University of Amsterdam\nABSTRACT\nIn this paper we explore the use of parsimonious language mod-\nels for web retrieval. These models are smaller thus more efficient\nthan the standard language models and are therefore well suited for\nlarge-scale web retrieval. We have conducted experiments on four\nTREC topic sets, and found that the parsimonious language model\nresults in improvement of retrieval effectiveness over the standard\nlanguage model for all data-sets and measures. In all cases the\nimprovement is significant, and more substantial than in earlier ex-\nperiments on newspaper/newswire data.\nCategories and Subject Descriptors: H.3 [Information Storage and Re-\ntrieval]: H.3.3 Information Search and Retrieval\nGeneral Terms: Measurement, Experimentation, Performance\nKeywords: Web Retrieval, Language Models, Parsimonious Language Mod-\nels\n1. INTRODUCTION\nWe examine the use of parsimonious language models for re-\ntrieval on a large-scale web data. The parsimonious language model—\nas introduced by Sparck-Jones et al. [3] and practically implemented\nin Hiemstra et al. [1]—overcomes some of the weaknesses of the\nstandard language modeling approach. Instead of blindly modeling\nlanguage use, we should model what language use distinguishes a\nrelevant document from other documents. Words that are common\nin general English, and words that occur only occasionally in doc-\numents, are already well explained by the background corpus, and\ntherefore do not have to be included in a document model. This\nresults in language models with far fewer terms, and when used at\nindexing time leads to smaller indexes and more efficient retrieval,\nmaking them especially attractive for large-scale web retrieval. The\ndecrease in index size should not be at the cost of a loss of retrieval\nperformance, in fact, the parsimonious model may improve perfor-\nmance. We will focus exclusively on the effectiveness here.\n2. MODELS\nIn this paper we use a unigram language model. It uses a mixture\nof the document model with a general collection model as follows,\ni.e., for a collection C, document D and query q:\nP (q|D) =\nY\nt∈q\n(λP (t|D) + (1− λ)P (t|C)) ,\nCopyright is held by the author/owner(s).\nSIGIR’08, July 20–24, 2008, Singapore.\nACM 978-1-60558-164-4/08/07.\nwhere\nPmle(t|D) = tft,DP\nt tft,D\nPmle(t|C) = doc freq(t, C)P\nt′∈C doc freq(t\n′, C)\nInstead of using maximum likelihood estimation to estimate the\nprobability P (t|D), it can also be estimated using parsimonious\nestimation. The parsimonious model concentrates the probabil-\nity mass on fewer terms than a standard language model. Terms\nthat are better explained by the general language model P (t|C)\n(i.e. terms that occur about as frequent in the document as in the\nwhole collection) can be assigned zero probability, thereby making\nthe parsimonious language model smaller than a standard language\nmodel. The model automatically removes stopwords, and words\nthat are mentioned occasionally in the document [1].\nThe model is estimated using Expectation-Maximization:\nE-step: et = tft,D · αP (t|D)\nαP (t|D) + (1− α)P (t|C)\nM-step: P (t|D) = etP\nt et\n, i.e. normalize the model\nIn the initial E-step, the maximum likelihood estimates are used to\nestimate P (t|D). The E-step benefits terms that occur relatively\nmore frequent in the document than in the whole collection. The\nM-step normalizes the probabilities. After the M-step terms that re-\nceive a probability below a certain threshold or pruning factor are\nremoved from the model. In the next iteration the probabilities of\nthe remaining terms are again normalized. The iteration process\nstops after a fixed number of iterations or when the probability dis-\ntribution does not change significantly anymore. For α = 1, and\na threshold of 0, the algorithm produces the maximum likelihood\nestimate Pmle(t|D) as defined before. Lower values of α result in\na more parsimonious model. We will denote the resulting estimate\nby Ppars(t|D).\nTo illustrate the effect of the parsimonious language models,\nwe selected a topic (Terabyte track topic “model railroads”) and\nbuilt three different models of the top 10 results: a standard lan-\nguage model (using maximum likelihood estimation); a standard\nlanguage model that removes stopwords; and a parsimonious lan-\nguage model. In Table 1 the top ranked terms of all three models\nare shown. The standard language model that excludes stopwords\nstill contains some words that could be considered as stopwords,\nlike ‘m’ and ‘p’. When a standard stopword list is used there is al-\nways a trade-off between being complete and being too aggressive.\nWhen the parsimonious model is used, the document is compared\nto the background corpus to remove all words that do not occur\nmore frequently in the document as in the background corpus, e.g.\nTable 2: Retrieval results on the TREC data sets\nDataset TREC-8 Terabyte ’04 Terabyte ’05 Terabyte ’06\n# Topics 50 49 50 50\nP (t|D) MLE Parsimonious MLE Parsimonious MLE Parsimonious MLE Parsimonious\nMAP 0.2331 0.2428 +4.2%? 0.2095 0.2206 +3.3%??? 0.2461 0.2567 +4.3%? 0.2139 0.2374 +11.0%???\nBpref 0.2481 0.2571 +3.6%? 0.2926 0.3048 +4.2%? 0.3014 0.3103 +3.0%?? 0.3234 0.3422 +5.8%??\nP@10 0.3640 0.4040 +11.0%?? 0.3265 0.3714 +13.8%??? 0.4200 0.4700 +11.9%??? 0.3300 0.3660 +10.9%?\nSignificance of Pars. over MLE according to t-test, one-tailed, at significance levels 0.05 (?), 0.01 (??), and 0.001 (???).\nTable 1: Top ranked terms of topic “model railroads”\nStandard LM Standard LM Parsimonious LM\nNo stopwords\nTerm Pmle(t) Term Pmle(t) Term Ppars(t)\nthe 0.0440 m 0.0203 museum 0.0527\nand 0.0289 museum 0.0143 railroad 0.0402\nof 0.0261 p 0.0119 train 0.0344\na 0.0205 railroad 0.0112 tel 0.0280\nm 0.0140 train 0.0093 trains 0.0233\nin 0.0130 www 0.0089 adults 0.0185\nto 0.0125 hours 0.0085 museums 0.0169\nfor 0.0118 ca 0.0084 depot 0.0142\nthe word “www” is very common in the .GOV2 corpus and does\ntherefore not occur in the parsimonious model. The parsimonious\nmodel does not only remove all standard stopwords, but also the\ncorpus specific stopwords.\n3. EXPERIMENTS\n3.1 Experimental Set-up\nWe test our models on four TREC datasets, Web track TREC-8\n(WT2g collection of 250K documents) and Terabyte tracks 2004,\n2005 and 2006 (.GOV2 collection of 25M documents) [4]. Using\nparsimonious language models at indexing time can significantly\nreduce the index size, but in order to experiment with all parame-\nters we choose to use parsimonious models at retrieval time. For\nefficiency reasons, we only rerank top 1,000 results of the standard\nlanguage model. We use the standard language model as described\nin Section 2, where P (t|D) is calculated using either maximum\nlikelihood estimation, Pmle(t|D), or according to the parsimonious\nmodel, Ppars(t|D). Stopwords are not removed.\nIn ad hoc retrieval, the standard value of the smoothing parame-\nter λ in the language model is 0.15. In the TREC Terabyte tracks,\nit is known that the .GOV2 collection requires little smoothing [2],\ni.e. a value of 0.9 for λ gives the best results. Experiments on the\nTREC-8 web data confirm that also the small Web data collection\nrequires substantially less smoothing, so for both datasets we use a\nvalue of 0.9 for λ.\nFor the parsimonious model we have to set the parameters α and\nthe threshold parameter. We set the threshold parameter at 0.0001,\ni.e. words that occur with a probability less than 0.0001 are re-\nmoved from the index. We setα = 0.1 for the parsimonious model,\nbased on initial experiments with a part of the topic set.\n3.2 Results\nThe results of the models on the different topic sets are summa-\nrized in Table 2. A number of observations present themselves:\nWe see that the use of the parsimonious language model leads to\nthe improvement of retrieval effectiveness on all four data-sets. In\nfact, we see a substantial improvement on all three measures: mean\naverage precision (MAP) increases with 3% to 11%; binary pref-\nerence (Bpref) increases with 3% to 6%; and precision at rank 10\n(P@10) increases with 11% to 14%.1 The fact that both early pre-\ncision (P@10) and overall precision (MAP) improve signals that\nthe parsimonious models have a beneficial effect on both precision\nand recall. Moreover, all the improvements on all four data-sets\nand three measures are statistically significant, signalling that these\nbeneficial effects apply to a large fraction of the topics. Further-\nmore, additional experiments show that a larger improvement can\nbe attained when stemming is used, i.e. increases in MAP up to\n14%.\n4. CONCLUSIONS\nFrom our experiments, we can conclude that the parsimonious\nlanguage model is to be preferred over the standard language model.\nThe parsimonious model produces smaller document models (and\nhence reduces the index) and obliviates the need for stopword lists.\nRetrieval results of the parsimonious model are superior to the stan-\ndard language model, over a range of measures and four TREC data\nsets.\nEarlier experiments [1] found only moderate improvements in\nMAP of around 3% for the TREC 7 and TREC 8 adhoc track using\nnewspaper/newswire data. We find improvements in MAP in the\nrange 3% to 11% for Web data. Arguably, the larger Web collec-\ntions are more susceptible to the parsimonious language model.\nAcknowledgments This research was supported by the Netherlands\nOrganization for Scientific Research (NWO, under project # 612.066.513).\nREFERENCES\n[1] D. Hiemstra, S. Robertson, and H. Zaragoza. Parsimonious language\nmodels for information retrieval. In Proceedings of the 27th Annual\nInternational ACM SIGIR Conference on Research and Development\nin Information Retrieval, pages 178–185. ACM Press, New York NY,\n2004.\n[2] J. Kamps. Effective smoothing for a terabyte of text. In The Four-\nteenth Text REtrieval Conference (TREC 2005). National Institute of\nStandards and Technology. NIST Special Publication, 2006.\n[3] K. Sparck-Jones, S. Robertson, D. Hiemstra, and H. Zaragoza. Lan-\nguage modelling and relevance. In W. Croft and J. Lafferty, editors,\nLanguage Modeling for Information Retrieval, pages 57–71. Kluwer\nAcademic Publishers, 2003.\n[4] TREC. Text REtrieval Conference, 2008. http://trec.nist.\ngov/.\n1We use binary preference mainly as a safe-guard. The parsimonious mod-\nels are potentially retrieving documents not part of the original assessment\npool. Since Bpref and MAP are in agreement, we have no reason to distrust\nthe MAP scores.\n",
    "Link": "https://core.ac.uk/download/pdf/11468391.pdf"
}