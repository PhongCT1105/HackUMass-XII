{
    "Title": "Validating generic metrics of fairness in game-based resource allocation scenarios with crowdsourced annotations",
    "Authors": "Grappiolo, Corrado, Martinez, Hector P., Workshop on Optimization & Machine Learning (OPML), Yannakakis, Georgios N.",
    "Year": "No year available",
    "Abstract": "Being able to effectively measure the notion of fairness is of vital importance as it can provide insight into the formation and evolution of complex patterns and phenomena, such as social preferences, collaboration, group structures and social conflicts. This paper presents a comparative study for quantitatively modelling the notion of fairness in one-to-many resource allocation scenarios - i.e. one provider agent has to allocate resources to multiple receiver agents. For this purpose, we investigate the efficacy of six metrics and cross-validate them on crowdsourced human ranks of fairness annotated through a computer game implementation of the one-to-many resource allocation scenario. Four of the fairness metrics examined are well-established metrics of data dispersion, namely standard deviation, normalised entropy, the Gini coefficient and the fairness index. The fifth metric, proposed by the authors, is an ad-hoc context-based measure which is based on key aspects of distribution strategies. The sixth metric, finally, is machine learned via ranking support vector machines (SVMs) on the crowdsourced human perceptions of fairness. Results suggest that all ad-hoc designed metrics correlate well with the human notion of fairness, and the context-based metrics we propose appear to have a predictability advantage over the other ad-hoc metrics. On the other hand, the normalised entropy and fairness index metrics appear to be the most expressive and generic for measuring fairness for the scenario adopted in this study and beyond. The SVM model can automatically model fairness more accurately than any ad-hoc metric examined (with an accuracy of 81.86%) but it is limited by its expressivity and generalisability.Being able to effectively measure the notion of fairness is of vital importance as it can provide insight into the formation and evolution of complex patterns and phenomena, such as social preferences, collaboration, group structures and social conflicts. This paper presents a comparative study for quantitatively modelling the notion of fairness in one-to-many resource allocation scenarios - i.e. one provider agent has to allocate resources to multiple receiver agents. For this purpose, we investigate the efficacy of six metrics and cross-validate them on crowdsourced human ranks of fairness annotated through a computer game implementation of the one-to-many resource allocation scenario. Four of the fairness metrics examined are well-established metrics of data dispersion, namely standard deviation, normalised entropy, the Gini coefficient and the fairness index. The fifth metric, proposed by the authors, is an ad-hoc context-based measure which is based on key aspects of distribution strategies. The sixth metric, finally, is machine learned via ranking support vector machines (SVMs) on the crowdsourced human perceptions of fairness. Results suggest that all ad-hoc designed metrics correlate well with the human notion of fairness, and the context-based metrics we propose appear to have a predictability advantage over the other ad-hoc metrics. On the other hand, the normalised entropy and fairness index metrics appear to be the most expressive and generic for measuring fairness for the scenario adopted in this study and beyond. The SVM model can automatically model fairness more accurately than any ad-hoc metric examined (with an accuracy of 81.86%) but it is limited by its expressivity and generalisability.peer-reviewe",
    "Keywords": "No keywords available",
    "Publisher": "Springer, Berlin, Heidelberg",
    "Publication Date": "No publication date available",
    "Journal": "No journal available",
    "Citation Count": 0,
    "Full Text": "Validating Generic Metrics of Fairnessin Game-based Resource Allocation Scenarioswith Crowdsourced AnnotationsCorrado Grappiolo1, He´ctor P. Mart´ınez2, Georgios N. Yannakakis21 Center for Computer Games Research, IT University of Copenhagen, Denmarkcogr@itu.dk2 Institute of Digital Games, University of Malta, Malta{hector.p.martinez, georgios.yannakakis}@um.edu.mtAbstract. Being able to effectively measure the notion of fairness is ofvital importance as it can provide insight into the formation and evo-lution of complex patterns and phenomena, such as social preferences,collaboration, group structures and social conflicts. This paper presentsa comparative study for quantitatively modelling the notion of fairnessin one-to-many resource allocation scenarios — i.e. one provider agenthas to allocate resources to multiple receiver agents. For this purpose, weinvestigate the efficacy of six metrics and cross-validate them on crowd-sourced human ranks of fairness annotated through a computer gameimplementation of the one-to-many resource allocation scenario. Four ofthe fairness metrics examined are well-established metrics of data dis-persion, namely standard deviation, normalised entropy, the Gini coeffi-cient and the fairness index. The fifth metric, proposed by the authors,is an ad-hoc context-based measure which is based on key aspects ofdistribution strategies. The sixth metric, finally, is machine learned viaranking support vector machines (SVMs) on the crowdsourced humanperceptions of fairness. Results suggest that all ad-hoc designed metricscorrelate well with the human notion of fairness, and the context-basedmetrics we propose appear to have a predictability advantage over theother ad-hoc metrics. On the other hand, the normalised entropy andfairness index metrics appear to be the most expressive and generic formeasuring fairness for the scenario adopted in this study and beyond.The SVM model can automatically model fairness more accurately thanany ad-hoc metric examined (with an accuracy of 81.86%) but it is lim-ited by its expressivity and generalisability.Keywords: Fairness, Social Preference, Resource Allocation, Dictator Game,Crowdsourcing, Preference Learning, Support Vector Machines, Feature Selec-tion, Genetic Algorithms.1 IntroductionThe control and influence of virtual or artificial societies is a highly complextask, in part, due to the difficulty of predicting the reaction and evolution of thepopulation to dynamic elements or changes. To monitor and predict evolutionof a society such as a complex adaptive system [37] one needs to monitor thebehaviour of single individual agents within the society. The behaviour of theindividuals collectively generates complex (and emergent) global dynamics andphenomena (e.g. friendship networks); these in turn affect the individuals, whowill adapt their behaviour autonomously creating a loop that regulates how thesociety evolves. For example, the level of collaboration among the individuals in alocal community can be utilised to develop a plan that allows for the integrationof different ethnic group identities [53]. Alternatively, in a virtual society (e.g. aserious multiplayer game) collaboration could be monitored to effectively teachsoft social skills [61].In this paper we investigate a number of metrics to measure the fairness thatone individual agent manifests depending on its interactions with other agents.We claim that fairness is a key feature characterising the interactions, whichcould bring further insight into the ongoing complex dynamics. The computa-tional models of fairness derived can assist in the inference of social preferences,collaboration, group structures and consequently social conflicts within artificialsocieties and complex networks. For instance, an individual who treats individ-uals differently might suggest the existence of preference; this would also haveimplications for the reciprocity of such treatment, and possibly for altruism,collaboration, and group identities [9, 15].We restrict our investigation to a virtual environment featuring a resource al-location scenario, which can allow us to simulate well and isolate scenarios whichcan be encountered in real-life situations. In the one-to-many scenario examined,an agent has to collect and share several resources among a population of agentsdivided into two visible groups. Although the scenario under investigation hasfeatures which are common to well-studied social dilemmas, such as the other-other game [6, 35], the dictator game [3] and, partly, the ultimatum game [9, 15],the perspective we take and the interpretation we give to the term “fairness”differs from those adopted in game theory studies. In particular, the metrics weinvestigate do not aim to model the utility of the actions performed (inequityaversion) [4, 16, 17, 48], as we rather focus on identifying measures of equalityof treatment towards multiple individuals independently of the provider’s pay-off. Furthermore, we are not making the canonical game theoretical assumptionthat the individuals considered in our scenarios are merely greedy [15], hence,we do not aim to investigate how the observed behaviours differ from some ref-erence value (e.g. Nash equilibrium) [15]. In other words, we aim to investigatea property of the interactions which is complementary to the concepts of socialpreference’s “altruism” and “reciprocity” [15]. Our concept of fairness assumesthat individuals behave “well” (i.e. they are fair) within a subset of individualsof the population only: fairness aims to provide measures capable of identifyingwhether this inequality is occurring.In this paper we test and compare four simple standard dispersion measures— namely standard deviation, normalised entropy [57], the Gini coefficient [41],and the fairness index [29] — that approximate fairness based on the levelsof satisfaction of resource acquisition manifested by the receiver individuals.We also propose a new, ad-hoc metric — hereafter called temporal group-basedfairness — which is based on single interactions (resource allocations) and theability of an individual agent to identify itself as part of a group [9]. We validatethe five metrics against the reports of an online crowdsourcing survey in whichhuman participants ranked the level of fairness in a wide variety of resourceallocation scenarios. Additionally, we propose a sixth, data-driven modelling ap-proach, in which genetic-feature selection combined with ranking Support VectorMachines (SVMs) [30] extract the most relevant context-based features of thescenario and infer a non-linear mapping between scenario attributes and thecrowdsourced notions of fairness. Results obtained show that all ad-hoc met-rics are highly consistent with the human notion of fairness as obtained from thecrowdsourced data; the temporal group-based metric proposed, however, outper-forms the other ad-hoc metrics in this scenario. Finally, the rank SVM, managesto produce a non-linear model that reaches 81.86% of accuracy in predictingfairness and proves to be the most consistent with the human notion of fairness.This study is novel as, to the best of the authors’ knowledge, there has notbeen any prior attempt to design, compare and cross-validate metrics of fair-ness against crowdsourced annotations of fairness. Moreover, this paper buildsupon and extends the metric validation method proposed in [57] by introducingrank-based crowdsourcing as a tool for annotating complex social dynamics suchas fairness. Clearly, our crowdsourced cross-validation study would strengthenearlier work, which used the metrics we considered [22–24, 41]; moreover, theproposed metrics open a plethora of new applications. For instance, they can beused as a mechanism for evaluating and promoting fairness in educational (seri-ous) games [22] and, similarly, cooperation/altruism [7]; they could also be usedas metrics to understand and evaluate collaborative games [12, 49, 54] — underthe collective intelligence perspective — together with, or as an alternative to,the use of expert knowledge [50]. They could be used in fields not strictly linkedto computer games, such as social network analysis [13, 45] or, even further, astools aimed to understand the goodness of the partitioning of (social) networksinto community structures [20, 36]. Moreover, the combination of crowdsourcingwith game-based scenarios introduces a first insight for categorising discrepanciesbetween experiments conducted on artificial societies [2, 14] and those on humanparticipants [15, 25]. Additionally, the metrics could also be embedded withinsuch artificial agents, e.g. together with inequity aversion [10, 56], in order togenerate believable, human-like adaptive artificial societies which manifest bothgreedy and group-based behaviours [47], allowing thus to further investigate thenotion of evolution of (group-based) collaboration [6, 25, 26, 44].The remainder of the paper is organised as follows: Section 2 lists some of themost relevant work to this study. Section 3 describes, formally, the one-to-manyresource allocation interaction scenario used in our research; it illustrates howthe scenario is implemented in a game-based virtual environment, and finallyit delineates the design of the crowdsourcing protocol. Section 4 and Section 5describe, respectively, the application of the ad-hoc generic metrics of fairnessand the use of SVMs for the one-to-many scenario. Section 6 presents the keyresults of this study. Section 7 discusses the limitations and the generalisabilityof the key findings and Section 8 concludes the paper.2 Related WorkThis study shares aspects of two main research fields: evolutionary game theoryand game-based modelling. The studies on the ultimatum and the dictator game— linked to the resource allocation game we investigate in this paper — are nu-merous (see [3, 16, 17] and [33] among others). The aforementioned studies hold apure game theoretical perspective: they aim to understand why the experimentsconducted on human participants deviate from the Nash equilibrium — whichassumes the existence of solely greedy individuals — towards more altruisticbehaviours. The focus of our research, instead, is to provide metrics capable ofcapturing whether the individuals of a population are manifesting different levelsof altruism, depending on who they interact with, as a key aspect of complexdynamics, such as the existence of group structures and group identities [9].Possibly, even closer to our research aim, there exist studies focused on un-derstanding the influence that group identities have on the behaviours of theparticipants of game theory experiments (see [1, 5, 6] and [34] among others);however, our work differs from these in its investigation of non-payoff (utility)based measures. Similarly, Marzo et al. [42] investigated how the existence offriendship structures affects the levels of altruism of human participants in Col-ored Trails [18], a computer game with similar mechanics to the ultimatum game.Their work puts the emphasis on describing how social relationships influencethe behaviour of the participants in their experiment, which is in line with ourassumptions about fairness; however, our work goes a step further by assumingthe existence of such behaviours within the population and aiming to providemetrics capable of identifying them.Studies on social preferences have benefited from the relatively novel agent-based modelling approach for simulating complex dynamics in artificial soci-eties [14, 26]. This approach has a close, if not exact, relationship with theresearch fields of evolutionary dynamics, collective behaviour, and simulationstudies, which aim to better understand how collaboration emerges from the re-peated interactions among the agents [2, 28, 44]. Although our global aim is theunderstanding of the evolution of collaboration and group structures, the studypresented in this paper does not rely on simulations of artificial societies and onthe search for behavioural rules embedded in the agents.Relevant metrics to fairness, such as balance [38] and symmetry [41] — keyconcepts in computer games research and design — have been constructed asthey intuitively have an impact on both the entertainment and learning goals ofthe game; however, we argue that the notion of fairness is both different and morecomplex than symmetry and balance as it factors in social, behavioural and re-lationship effects. The context-based metrics proposed in this paper follow botha top-down expert-driven and a bottom-up data-driven [60] approach for cap-turing fairness inspired by methodologies for deriving accurate user-interactionmetrics in games [57]. While our expert-driven metrics are directly designed onkey aspect of the one-to-many scenario in use, the evaluation and constructionof the data-driven metric is based on game-based crowdsourced annotations.The use of crowdsourcing and the correlation analysis we performed has beenused in game artificial intelligence research, though centred on affect modellingin single player game environments [51, 57, 59]. Our one-to-many interaction sce-nario, however, provides the basis for the investigation of multi-agent and mul-tiplayer scenarios [21, 23, 24].The Fairness Index (FI) we decided to consider in this study [29] belongs tothe vast research field of fairness of resource allocation in information networks(consider [11, 32, 43, 46, 52] and [55] as a non-exhaustive list). Generally speak-ing, the standard problem regards the fair allocation of resources (e.g. CPUand memory) to a set of requesting units (e.g. jobs) in order to e.g. maximisethe overall system’s utility. Although our scenario and aim is more targeted to-wards social and economical contexts, the positive correlation of FI with theperceived notion of fairness gathered in our crowdsourcing survey suggests thatFI is relevant for our purposes.3 Fairness Scenario and CrowdsourcingThis section presents the one-to-many resource allocation scenario on whichwe base our fairness modelling studies and describes the game-based virtualenvironment designed for encapsulating the key characteristics of the scenario.The section ends with a description of the protocol followed for crowdsourcingannotations of fairness through the virtual environment.3.1 One-to-many Resource Allocation ScenarioFormally, the one-to-many resource allocation scenario investigated in this papercan be described by the following tuple:scenario = (P,R,A,G, g, v, s) (1)where:– P is the population (society) of n+1 individuals (agents), P = {a0, a1, . . . , an}.– R is the set of m resources R = {r0, r1, . . . , rm−1}.– A ⊆ R is the temporally ordered sequence of resources allocated by theprovider agent, A ={rt=1i , rt=2j , . . .}.– G is the set of group structures present in P ; G constitutes a partition of P .– g : P → G is the group identity function mapping each agent in P to onegroup structure in G. The group identity of the provider agent is unknownto the observer of the distribution strategy; for simplicity, we will refer tothe single group identity g(ai) as gi.– v : R → (0, 1] is the resource value function which assigns a value to eachresource in R. For simplicity we will refer to the resource value of resourcerj as vj .– s : P → [0, 1] is the receiver satisfaction function mapping each receiveragent in P to a satisfaction value between 0 and 1. For simplicity we willrefer to the satisfaction value of ai, as si.All the agents ai have their satisfaction values si decreasing over time by aconstant value δ, si ← max(si − δ, 0). An agent ai receiving a resource rj willhave its satisfaction value updated as follows: si ← min(si + vj , 1). Intuitively,si gives an indication of the amount of resources acquired by ai.One agent takes the role of the provider agent (we will refer to it as ap ∈ P ),and the remaining n individuals take the role of the receiver agents. The provideragent has the duty to fill up A by allocating 0 ≤ |A| ≤ m resources among then receiver agents in |A| steps (i.e. one resource at a time, the provider agentmay not distribute any resources, a receiver agent may obtain more than one re-source). Each receiver agent ai has a goal which corresponds to the maximisationof its si. However, the receiver agents cannot acquire the resources by themselves;they will only acquire the resources distributed by the provider agent.The features describing the scenario allow the provider agent to adopt manydifferent strategies to define A, which would suggest, to an external observer,different levels of fairness towards the receiver agents and, possibly, also receivergroups.3.2 The Resource Allocation GameTo obtain a test-bed to evaluate the ad-hoc fairness metrics, and machine learn-ing alternative data-driven metric, the one-to-many resource allocation scenariodescribed in Section 3.1 was implemented as a three-dimensional (3D), singleplayer game-based virtual environment; a virtual camera follows the movementof the provider agent, creating a third-person perspective of the gameplay. Theprovider agent finds himself in the environment together with receiver agentsand resources; his duty is to allocate the resources among the receiver agentswithin a time limit by carrying only one resource at a time.The satisfaction values of each receiver agent, which decrease constantly overtime, can be inferred by observing their yellow hats, which range in transparencylevels: the more transparent, the lower the satisfaction. When the receiver agentacquires a resource, its satisfaction level is increased (i.e. its yellow hat gets moreopaque) by the value of the resource obtained. The resources are represented aspurple balls and their values are represented by their size: the smaller the ball,the smaller its value provided.The receiver agents have a coloured body which represents the group theybelong to (group identity). For the study presented in this paper, we examinethe presence of only two group structures, namely the red and the blue group.A single distribution scenario (Equation 1) is interpreted, in our game-basedFig. 1. A snapshot of the resource allocation game: 3 receiver agents (2 belonging tothe blue group and 1 belonging to the red group) and their satisfaction levels (yellowhats), 4 resources of different sizes and the provider agent are depicted.environment, as a game level. A snapshot of the resource allocation game canbe observed in Figure 1.The decision to consider only two groups in our study is motivated by severalarguments, both theoretical and practical. First, the red and blue groups can beeasily linked to the in-group vs. out-group dichotomy [6, 9]: the detection ofunfair treatments — even across the whole population, i.e. independently onthe agent colours/groups — could be augmented by further detection of thetargeted subset of the population which received the most generous treatments,and hence the subsequent identification of the colour/group the provider agentbelongs to [23, 24]. Second, the fact that some of the most relevant studies ongroup behaviour and inequity aversion in human-centred experiments [6, 34, 42]are based on two groups would allow for a possibly easier bridging betweenthe two different interpretations given to fairness. Finally, we did not want tointroduce any further complexity to the game-based scenario, which could bringdifficulties with respect to the perception of group-based unfair treatments (seeSubsection 4.5), given the novelty of the approach we decided to adopt.3.3 Crowdsourcing Experimental ProtocolThe game-based virtual environment was then used in a crowdsourcing survey.In the survey, participants watched and annotated a sequence of strategy videos,which reproduce resource distribution tasks (strategies) of our game. We haverelied on the ability of participants to compare and rank gameplay strategiesgiven in pairs (pairwise preference scheme) rather than having participants rat-ing the strategies, for a number of advantages including the elimination of thesubjective notion of scaling and effects related to reporting order [58].Table 1. Initial conditions of the four different scenarios of the survey. The si valuesare partitioned according to the two red and blue group identities.Scenario nred nblue m sred sblue vR2 receivers 1 1 2 0.1 0.5 0.5, 0.93 receivers 2 1 4 0.1, 0.5 0.5 0.1, 0.3, 0.5, 0.94 receivers 2 2 3 1, 0.8 0.2, 0.1 0.8, 0.4, 0.25 receivers 3 2 4 0.1, 0.3, 0.5 0.7, 0.9 0.3, 0.5, 0.7, 0.9Six different strategies were recorded for four different scenarios — consistingof 2, 3, 4 and 5 receiver agents — resulting in 24 strategy videos in total3. Theset of game-playing strategy videos used in the survey was defined in order toshow resource distribution strategies as different from each other as possible.With respect to the game features we have described in Section 3.2, each game-playing strategy is limited to 30 seconds. Table 1 illustrates the key featuresof the four different scenarios designed: number of red receiver agents (“nred”column), number of blue receiver agents (“nblue” column), number of resources(“m” column), initial satisfaction values of the receiver agents (“sred” and “sblue”columns) and value of the resources (“vR” column). As can be noted, the fourscenarios present unbalanced initial conditions, both with respect to the singleagents and to the average group satisfaction values.The key protocol steps of the survey are as follows:1. The participant fills in a demographic questionnaire (age, gender, experiencein playing games, whether the participant has already taken part in thesurvey) and reads the instructions of the survey, which describe the resourceallocation scenario and the ways to provide feedback about the strategies.2. A pair of strategy videos, A and B, is selected and presented on the samescreen (see Figure 2) — there is a 50% probability that the order of appear-ance (left or right) of two strategies is inverted. The pair of strategy videospresented to the participants belong to the same scenario (i.e. same numberof receivers).3. The participant watches the videos and provides feedback through a 4-alternative forced choice questionnaire (4-AFC), which asks the participantif the behaviour of the provider was: (a) more fair in video A; (b) more fairin video B; (c) equally fair in both video A and video B; (d) unfair in bothvideo A and video B. In order to allow the participant to fully grasp thedistribution dynamics, each video can be paused at any time and replayedunlimitedly.4. The participant can write additional comments via a free-response text boxand is free to take part in another session of the survey, ensuring that hedoes not watch the same pair of strategy videos; otherwise the survey ends.3 The videos of the 24 Scenarios can be found on the following link:http://itu.dk/people/cogr/FairnessExperiment/TCCI_index.phpFig. 2. A snapshot of the online surveyConsidering that we have designed six strategies per scenario, and that weshow pairs of different strategies of the same scenario, we get C6,2 = 15 possiblecombinations of video pairs by excluding repetitions and order of appearance onscreen (left or right). Any possible order effects are minimised via the randomi-sation of the video ordering previously described.For each of the four scenarios and the 15 possible combinations, we collectedfour pairwise preferences. Thus, in total, our analysis is based on 4 · 15 · 4 = 240strategy pairs that are labelled by our participants. The participants were gath-ered through advertisement of the experiment on the well-know Facebook4 socialnetwork online platform, in order to achieve the most diverse audience. The num-ber of unique participants out of the 240 reports are 141, 74% of which are maleand 50.3% consider themselves gamers. The average age is 30.24 years and itsstandard deviation is 6.84. Furthermore, 77% of the participants declared them-selves as being either not a gamer or occasional gamers (i.e. playing up to 2hours per week), 11% declared playing games from 2 to 5 hours per week, 8%play from 5 to 10 hours per week, and 4% play for more than 10 hours per week.4 Ad-Hoc Metrics of FairnessThis section first introduces the four generic metrics of dispersion of the dataused in our study, given the particular scenario described by the tuple definedin Equation 1. The section ends with the definition of a new, ad-hoc designedfairness metric proposed by the authors, which is tightened to the scenario in-vestigated.4 http://www.facebook.com4.1 Standard DeviationAt the end of the distribution task, we calculate the average satisfaction of allreceiver agents as follows:µ =1nn∑i=1si (2)The standard deviation is therefore defined as follows:σ =√√√√ 1nn∑i=1(si − µ)2 (3)Since the upper bound of σ is 1 — both µ and si values range within the [0, 1]interval — we can subtract σ from its maximum value in order to give it apositive connotation of fairness:SD = 1− σ (4)In presence of fairness, the si values are similar to each other, making σ closeto zero and SD high. In contrast, in presence of unfair treatments, the si valuesare very different from each other, making σ high and SD low.4.2 Normalised EntropyThe Normalised Entropy [57] is calculated at the end of each distribution taskas follows:NH = − 1log(n)n∑i=1sˆi log sˆi (5)where sˆi represents the normalised satisfaction value of each receiver agents:sˆi =si∑nj=1 sj(6)In presence of fairness, the sˆi values are similar to each other, thus yieldinga high normalised entropy. In contrast, in presence of unfair treatments, the sˆivalues are very different from each other, yielding low normalised entropy values.4.3 Gini CoefficientThe Gini Coefficient [19] is a well-known measure of equality used in economicstudies. Providing that, at the end of each level, the si values of the receiveragents are ordered by increasing values, that is:ski ≤ sk+1j , i, j ∈ [1, n] (7)The calculation of the Gini Coefficient in our game-based scenario is done asfollows:GI =1n− 1(n+ 1− 2(∑nk=1 (n+ 1− k) sk∑nk=1 sk))(8)Note that we have omitted the indices i in the representation for sk for simplicity.GI lies within the [0, 1] interval: the lower the coefficient, the higher the fairness.Hence, similarly to the SD implementation, we will take into consideration theinverse of the Gini Coefficient:GC = 1−GI (9)4.4 Fairness IndexThe Fairness Index [29] is a well-known measure of equality of resource allocationvastly used in information networks. The metric is calculated at the end of eachdistribution task as follows:FI =(∑ni=1 si)2n∑ni=1 s2i(10)FI has value one in presence of completely fair treatments among the wholepopulation, and it decreases as the disparity increases towards a subset of fewindividuals.4.5 Temporal Group-based Metrics of FairnessWe here propose a new metric of fairness — which is not as generic as the fouraforementioned metrics previously introduced — whose design is based on (andbounded by) the following three constraints (or criteria):(C1) The group identities of the receiver agents are not hidden from the provideragent. The provider agent can be influenced by such information and there-fore aim to deliver the resources based on the existing group structures,rather than just focusing on the receiver agents’ satisfaction values.(C2) The complex (and dynamic) structure of the scenario might have an impacton the willingness of the provider agent to be either fair or unfair. Themetrics calculation should take into account the intermediate steps of thedistribution task, rather than solely focusing on the calculation at the endof the scenario.(C3) The initial configuration of each scenario might already depict an unfairdistribution of si values. A provider agent, who is willing to maximise thesatisfaction values of the whole population, should not avoid the delivery ofresources.In our game, which considers two group structures — the red and blue agents,see Section 3.2 — constraint (C1) is satisfied by the average satisfaction of thered and the blue groups:µred =1nrednred∑i=0si, µblue =1nbluenblue∑i=0si (11)where, nred + nblue = n is the number of receiver agents belonging to the redand the blue group, respectively. The between-group fairness is defined as theabsolute value:|µred − µblue| (12)Constraint (C2) is satisfied by averaging the between-group difference across the0 < |A| ≤ m distributions:1|A||A|∑t=1∣∣µtred − µtblue∣∣ (13)Where µtred and µtblue represent, respectively, the between-group satisfaction val-ues of the red and the blue groups after the t-th resource allocation. Finally, weconsider the case |A| = 0 in order to satisfy (C3):TGB ={0 if |A| = 01− 1|A|∑|A|t=1 |µtred − µtblue| if 0 < |A| ≤ m(14)In presence of group-based fairness throughout the whole distribution task, theµred and µblue values are, on average, similar to each other, thus yielding highTGB values. In contrast, in presence of group-based unfair treatments through-out the whole distribution task, the µred and µblue are, on average, different fromeach other, generating low TGB values.5 Data-Driven Approach: Preference LearningWe propose a data-driven method to model fairness as an alternative to thehand-crafted metrics defined in Section 4. This approach imposes minimal expertknowledge on the metrics which are instead shaped according to a specific datasetcontaining strategies with different levels of fairness compared by human judges.A data-driven technique, as opposed to hand-crafted metrics, can handle largeamounts of user data and learn patterns that human experts may have overseen.We use ranking Support Vector Machines (SVMs) [27, 31], a well-knownmethod for learning non-linear estimators of user pairwise preferences such asthose present in the experimental data used in this paper. This method requiresthat each input sample (i.e. strategy) is coded as a vector of numeric featuresgiven by the designer. To reduce the human bias that could be introduced inTable 2. Full feature list extracted for each allocation video across the four scenarios.Bold feature numbers indicate the best extracted features by SVM’s the genetic featureselection phase.Feature Name Descriptionnred/n, nblue/n number of red/blue agents|A|/m number of deliveriesnred/3, nblue/2number of red/blue agents divided by 3/2, i.e.their maximum number across all scenariosnred/5, nblue/5number of red/blue agents divided by 5, i.e. themaximum number of agents across all scenariosm/4number of resources divided by 4, i.e. theirmaximum number across all scenarios|A|/4 number of deliveries divided by 4, i.e. the maximumnumber of possible deliveries across all scenariosµ0red, µ0blue initial average happiness of the red/blue agents∑mj=1 vj average satisfaction value of the resourcesvtjfor t = 1, 2, 3, 4, the value of the t-th resourcedelivered. If |A| < t then the feature has value zero.µtredfor t = 1, 2, 3, 4, average happiness of the red agentsafter the t-th delivery. If the resource was deliveredto the blue group, then µtred = µt−1red − δ. If |A| < tthen the feature has value zero.µtbluefor t = 1, 2, 3, 4, average happiness of the blue agentsafter the t-th delivery. If the resource was deliveredto the red group, then µtblue = µt−1blue − δ. If |A| < tthen the feature has value zero.this step, we use a large vector to describe each distribution strategy within ascenario and later reduce it by automatic feature selection. The remainder of thissection describes the feature extraction process, the SVM, and the genetic-searchfeature selection algorithm used.5.1 Fairness Strategy Feature ExtractionTo capture most aspects of the scenario in a format suitable for data-drivenmodelling we extract a large number of features which could represent both itsinitial conditions and its intermediate ones. In total, we extracted 24 features,presented in Table 5.1.5.2 Ranking Support Vector MachinesA Support Vector Machine is a binary classifier consisting of a linear combinationof training vectors:w =∑xi∈Dαiφ(xi) (15)The hyper-plane defined by this combination separates the data samples xi intotwo classes in projected space φ(X). In this paper we are not interested in abinary classifier but rather a function that maps data samples (strategies) intoa real-valued variable (estimation of fairness); additionally, our data samples areassociated with pairwise comparisons instead of discrete classes. Thus, we useda variant of SVMs known as ranking SVM [27, 31], which is tailored to problemswith the same formulation. The model is still a linear combination of transformedtraining vectors which is trained by optimising the following problem:minimise:12||w||2 + C∑ξisubject to: ∀(xiP,xiN) ∈ D,w · (φ(xiP)− φ(xiN)) ≥ 1− ξi∀i ξi ≥ 0(16)where D is the complete set of training samples, (xiP,xiN) are pairs of trainingsamples such that the feature vector xiP was preferred (reported as more fairin this paper) over the feature vector xiN, ξi are non-negative variables, C aweighting parameter, w the trained decision boundary and ||w|| its module.Once w is trained, given a pair of samples {xi,xj} the SVM predicts that xi ispreferred over xj if w·φ(xi) > w·φ(xj); thus, w·φ(x) is a computational predictorof fairness. Although the SVM creates a linear separation, this is defined on thetransformed space defined by φ, which yields more complex functions in theinput space. As the transformation of the space can lead to an infinite numberof dimensions [27], and also in order to reduce computational costs, the predictoris redefined in terms of the training examples and a kernel function:w · φ(x) =∑(xiP,xiN)∈Dαi(κ(x,xiP)− κ(x,xiN)) (17)where αi are non-negative coefficients, κ(xjxj) is the kernel function and (xiP,xiN)are pairs of training samples.For all experiments reported in this paper, we use a Gaussian projection (i.e.Gaussian kernel) as it can generate a wide range of non-linear functions while itcontains one single parameter (γ). We set C = 0.001 and γ = 1.0 after systematicadjustment of their values.5.3 Automatic Feature SelectionFeature selection is a procedure commonly used in data mining to reduce the di-mensionality of training data by removing features that seemingly do not containrelevant information about the function modelled. The basic procedure consistsof evaluating several combinations of features using a predefined fitness func-tion. In this paper we use a genetic algorithm to search the space of all possiblecombinations of features — this is known as Genetic-search Feature Selection(GFS) [40]. We use a population of 19 bit-chromosomes — their length beingthe total number of features extracted — that represent whether a particularfeature is selected (1) or not (0). Across 15 iterations, pairs of feature subsets areselected based on a ranking selection method (the higher the fitness of a featuresubset, the greater the probability of being selected) and recombined via uni-form crossover (probability of 0.8) to generate new feature subsets (offspring).A mutation operator adds or removes one feature to the offspring’s chromosomewith probability 0.01.The fitness of each subset of features is calculated as the average 10-foldcross-validation (CV) accuracy of an SVM employing a Gaussian kernel trainedon the available data using only the selected subset of features.6 Results and AnalysisTo measure the degree of agreement between the values provided by SD, NH,GC, FI and TGB and the crowdsourced self-reports, we calculate the correla-tion coefficients between them, following the statistical analysis procedure forpairwise preference data presented in [57] using the test statistic:c(z) =N∑i=1{zi/N} (18)where N is the total number of samples to correlate, zi = +1, if the videoreported as more fair in pair i yields a higher metric than the video reportedas less fair, and zi = −1, if the video reported as more fair in pair i yieldsa lower metric than the video reported as less fair. In the calculation of c(z)we only take into account clear preferences, that is, we only consider pairs inwhich a clear preference — A is more fair than B or B is more fair than A(2-AFC) — is expressed, that is, N = 147. The p-values of c(z) are obtainedvia the binomial distribution. Tables 3(a), 3(b), 3(c), 3(d) and 3 present thec(z) values and their corresponding p-values, for each scenario and in total, forthe metrics SD,NH, CG, FI and TGB respectively. The first three columns(after the “Scenario” column) report the number of choices for the alternatives ofthe 4-AFC. Columns “Match” and “Mismatch” represent the number of 2-AFCpreferences that respectively, match and mismatch the metric value.6.1 Validating the Ad-hoc Metrics of FairnessThe first observable result is that all four metrics (SD, NH, GC and FI —see Tables 3(a), 3(b), 3(c) and 3(d)) appear to be consistent with the reportedpreferences. NH — and consequently FI, which presents the exact same results— yield correlation values above 0.7 for the 4 receivers scenario, whilst the c(z)values are not as high (just above 0.4) for the 2, 3, and 5 receiver scenarios. Asimilar behaviour and c(z) values are observed for the GC metric.Even though SD appears to be consistent with the notion of fairness, notsurprisingly, it is the metric which scores the lowest correlation coefficients, sinceTable 3. Analysis of correlation c(z) between fairness metrics and reported fairness.Significant c(z) values appear in bold — significance is 5%.(a) SDScenario2-AFC Equally BothMatch Mismatch c(z) p-valuePreference Fair Unfair2 receivers 38 9 13 28 10 0.47 0.033 receivers 41 4 15 24 17 0.17 0.454 receivers 36 11 13 31 5 0.72 < 0.015 receivers 32 6 22 24 8 0.50 0.01Total 147 30 63 107 40 0.46 0.02(b) NHScenario2-AFC Equally BothMatch Mismatch c(z) p-valuePreference Fair Unfair2 receivers 38 9 13 29 9 0.53 0.013 receivers 41 4 15 29 12 0.41 0.054 receivers 36 11 13 31 5 0.72 < 0.015 receivers 32 6 22 25 7 0.56 < 0.01Total 147 30 63 114 33 0.55 < 0.01(c) GCScenario2-AFC Equally BothMatch Mismatch c(z) p-valuePreference Fair Unfair2 receivers 38 9 13 29 9 0.53 0.013 receivers 41 4 15 29 12 0.42 0.054 receivers 36 11 13 30 6 0.67 < 0.015 receivers 32 6 22 25 7 0.56 < 0.01Total 147 30 63 113 34 0.54 < 0.01(d) FIScenario2-AFC Equally BothMatch Mismatch c(z) p-valuePreference Fair Unfair2 receivers 38 9 13 29 9 0.53 0.013 receivers 41 4 15 29 12 0.41 0.054 receivers 36 11 13 31 5 0.72 < 0.015 receivers 32 6 22 25 7 0.56 < 0.01Total 147 30 63 114 33 0.55 < 0.01(e) TGBScenario2-AFC Equally BothMatch Mismatch c(z) p-valuePreference Fair Unfair2 receivers 38 9 13 27 11 0.42 0.063 receivers 41 4 15 35 6 0.71 < 0.014 receivers 36 11 13 31 5 0.72 < 0.015 receivers 32 6 22 23 9 0.44 0.04Total 147 30 63 116 31 0.58 0.01standard deviation is a measure of dispersion of the data with respect to a refer-ence mean value. Although SD correlates well with the human notion of fairnesswhen highly fair and unfair strategies are existent, this does not necessarily holdfor strategies of intermediate levels of fairness.Overall, TGB (see Table 3) scores a correlation coefficient higher (but notsignificantly higher) than any other ad-hoc metric. Therefore, we can state thatTGB,NH — and consequentlyGC and FI — represent the notion of fairness forthe one-to-many interaction scenario equally well overall. TGB yields correlationvalues above 0.7 for the 3 and 4 receivers scenario, whilst the c(z) values are notas high (just above 0.4) for the 2 and the 5 receivers scenarios.Compared to NH and FI, TGB manages to improve the correlation withthe perceived fairness for the 3 receivers scenario, however, at a cost of moremismatches for the 2 and the 5 receivers scenarios. The 2 and 4 receivers scenariosare those for which the c(z) values of TGB,NH,GC and FI are almost identical.There is no doubt that 3 receivers is the most complex scenario among the 4we have considered in our experimental setup: there is a difference in the groupsizes (nred = 2 and nblue = 1), a high amount of resources (m = 4), a bigdifference in satisfaction within the red group itself, and finally, the resourcevalues are generally low, except for one, for which vi = 0.9 — see Table 1.The 3 receiver scenario appears to have instigated different and complicatedperceptions of fairness among the participants, which can be better captured byTGB, as opposed to the other metrics.NH, GC and FI outperform TGB in the 5 receivers scenario as the metricsgenerate two very different orderings of the strategies. It appears that the largepopulation size and the many available resources lead to a lower impact of exist-ing group structures on the perception of fairness. In support of this hypothesismany submitted comments of the participants suggest that a fair distributionstrategy should first prioritise the fulfilment of all receivers’ satisfaction indepen-dently of their group identities and, only subsequently, distribute the resourcesaccording to a group-based strategy.The crowdsourced reports highlight that it is easier to report a clear fairnesspreference (i.e. 2-AFC) for scenarios with a lower population (2 and 3 receivers)rather than scenarios with a high population (4 and 5 receivers). This findingsuggests that there might be potential difficulties in observing and distinguishingcomplex distribution strategies within our 3D game design. It is worth notingin this respect that we received only three additional comments related to thedifficulty to perceive the distribution strategies; however, these were submittedby inexperienced players, who spent only up to two hours on gaming per week,as we could retrieve from their demographic entries.6.2 Modelling Fairness via Preference LearningAs an alternative to ad-hoc metric design, we investigated the inverse approachand followed a data-driven methodology to construct a model that is directlybuilt on the crowdsourced pairwise preferences, to be compared to the ad-hocmetrics. For that purpose, we run GFS 10 times and pick the feature subset thatTable 4. Average and best performance across 10 trials of the rank SVM algorithm.Performance accuracy is assessed through 10-fold cross-validation. Correlation values(c(z)) are derived from the 10-fold CV accuracy.Feature Set Accuracy (%) Matches Mismatches c(z)Random FeaturesAverage 73.54 108 39 0.47Best 77.09 113 34 0.54All FeaturesAverage 74.95 110 37 0.50Best 76.81 112 35 0.52Best Feature SubsetAverage 79.33 117 30 0.59Best 81.86 120 27 0.63feeds an SVM model (as described in Section 5) which yields the highest 10-foldCV accuracy on the pairwise preference data. In order to reduce the impact ofnon-determinism existent in the separation of the data into folds, we run 10 trialsof the algorithm using three different feature sets: the best-performing featureset, the set that contains all 19 features extracted, and randomly selected fea-tures. Table 4 reports the average and highest accuracies and the correspondingc(z) values of the three different feature sets. The best performing feature setyields accuracies which are significantly higher (tested via a t-test) when com-pared to the full feature set (p-value < 0.01) and the randomly-selected featuresubset (p-value < 0.01). Thus, it appears that genetic feature selection (GFS)improves the accuracy of the model, on average, (79.33%) as it outperformsrandomly selected features (73.54%) and all features (74.95%) considered.The best-feature set (c(z) = 0.63) supports a model that outperforms thecorrelation coefficient of the TGB metric. This model predicts 81.86% of thepairwise fairness reports correctly relying on five features selected by GFS: theinitial average satisfaction value for the blue group (µ0blue); the average satisfac-tion of the red group after the second delivery (µ2red); the average satisfactionof the blue group after the second and third delivery (µ2blue and µ3blue, respec-tively); and the satisfaction provided at the third delivery (v3j ). The selectedfeature subset suggests that particular resource deliveries to particular groupsare of key importance for determining and approximating fairness.7 DiscussionThe TGB, NH, GC and FI ad-hoc metrics manage to represent the notion offairness well, as the cross-validation analysis performed with the data gatheredfrom the crowdsourcing experiment showed high consistency and strong statisti-cal significance. The question of how to quantitatively model fairness precisely, inorder to subsequently infer the presence of social preferences, collaboration andglobal patterns such as group identities has been answered, though only in part.The key findings of the paper can evidently contribute to further investigationsfor addressing the aforementioned question.The difference in performance between TGB and the NH, GC and FI met-rics suggests that the context-based, expert-driven metric TGB, might haveintroduced some bias over-fitting to the examined scenario. It seems thereforeintuitive that, prior to considering TGB as a universal metric for one-to-manyinteraction scenarios, similarly to NH, GC and FI, more studies should be con-ducted. For instance, with respect to the scenario’s formal definition (Eq. 1),studies based on a higher number of agents, groups, resources, and resource al-locations, could be made. On the other hand, NH, GC and FI showed goodefficacy with respect to modelling fairness, even in the one-to-many scenario.Finally, SD showed a low correlation with the perceived notion of fairness; thisis explained by the nature of the metric, which describes the dispersion of thedata based on a reference mean value. This suggests that fairness is an abso-lute notion, rather than being relative to a reference satisfaction value. As aconsequence, it is likely that similar measures of fairness, e.g. the coefficient ofvariation [29], would show similar performances.By following our assumption that fairness is a feature of interactions whichcan help with the identification of preferred individuals in the population, hencegroup structures, we have been investigating methods to use fairness as a featurefor collaboration learning in order to detect the formation and consolidation ofgroup identities in complex artificial societies of believable, human-like artificialagents [23, 24]. These agents manifested reciprocal and altruistic social prefer-ences, interacting with each other, iteratively, by means of the ultimatum game.The interaction scenario was interpreted as a sequence of one-to-many interac-tions between one provider agent and many receiver agents, and NH was usedto calculate the fairness of the providers’ offers. The results obtained showedthat NH can help with the detection of existing group structures and is robustacross different population sizes, group structure typologies, and in presence ofdiverse locality of interactions among the agents.Future work would intuitively focus on the investigation of other metrics offairness. We hereby suggest either the definition of new metrics, or the identi-fication of existing ones which would put an emphasis on the sequence of theresources being distributed, which is only partly achieved by TGB. Moreover,fairness can also be associated with a number of other complex notions, such asbalance [38] and asymmetry [41]. Finally, due to the positive correlation coeffi-cients scored by the Fairness Index (FI), future studies will aim to investigatehow well other FI-related metrics [43] are linked to our scenario and how wellthey would correlate to the crowdsourced self-reports.While the SVM approach yielded high-performing fairness models (modelaccuracy > 80%) that surpass the correlation of ad-hoc metrics with the crowd-sourced data, the generalisability of the model to other settings is likely to belower as it is built on data and features from a particular environment. Neverthe-less, as the accuracy is evaluated on data unseen during training, it is expectedto maintain its superiority within similar settings. Furthermore, the expressiv-ity of the metrics over the black-box Gaussian SVM model provides a key ad-vantage for their use. On that basis, more preference learning algorithms willbe tested and compared: possible candidates for learning the mapping betweenpairwise preferences and social dynamics in the game include bayesian [8] andneuro-evolutionary preference learning [39]. Towards the data-driven approachto modelling fairness, more experimental data will be required from diverse anddissimilar game scenarios containing variant numbers of agents, groups of agentsand initial conditions.The self-reports and some of the extra comments filled by the participantssuggest that, particularly for occasional and non-gamers, the 3D game-based im-plementation of the one-to-many resource allocation scenario, with an emphasison how to represent the levels of satisfaction of the agents, might add a bottleneckwith respect to the perception of fairness. This could also be the reason why theparticipants are more confident to report clear preferences (A is more fair thanB or B is more fair than A) in scenarios with smaller populations. This drawbackcould be reduced by allowing the participants to have a more active role, ratherthan just following the provider agent and observing its allocation strategy. Forinstance, future work could be focused on letting the participants play the roleof the provider agent, distribute resources, and subsequently describe the strate-gies they adopted. Although this approach might introduce challenges on thequantification of the strategy descriptions, it could on the other hand allow forthe discovery of alternative, highly complex distribution strategies.The introduction of group identities in the population was motivated by theintention to represent the existence of social preferences under the perspectiveof the provider agent. The differences of group identities are to be found, solely,on the colour of the body of the receiver agents. Moreover, the provider agent,as depicted in both Figure 1 and Figure 2, does not explicitly belong neitherto the red nor to the blue group. Although there is a vast corpus of studiessuggesting that group behaviours and identities can be observed independentlyon how arbitrarily the groups are instantiated (see [1, 5, 6, 9] among others),the game design we adopted might not represent real-life, global structures, e.g.ethnicity or friendship well and might explain why NH, GC and FI — which aregroup-independent — correlate well with the self-reported data. Further workon the enrichment of the graphical representation of the group identities wouldbe considered.Although some of the motivations which led us to consider only two groupswere driven by the need to represent the dichotomy in-group vs. out-group [9](see Section 3.2), it might be possible that some of the metrics, especially TGB,might not be able to scale well in presence of more complex scenarios. On theother hand, more complex scenarios would lead to the increase of the numberof features describing the distribution strategies. As a consequence, it might bepossible that those features extracted via GFS for rank SVM would becomemore generic, as opposed to those used by the best performing rank SVM forthe current two-group scenario (see Section 6.2). Given that we cannot clearlyforesee the changes in the consistency of NH, GC and FI — since more complexscenarios would lead to a wider plethora of group-based distribution strategies,and hence their human perception — future work based on scenarios with morethan two will be considered.The proposed crowdsourcing approach for metric design proves that it ispossible to design accurate measures of fairness. Beyond our resource allocationscenario, the proposed crowdsourcing approach can be used as a validation toolto explain the discrepancies between the results obtained in evolutionary games(i.e. based on artificial societies) and those found in nature [25]. Preliminaryresults, based on artificial societies [23, 24], suggest that fairness is a feature ofinteractions which would expose the preference of individuals. Thus, the metricsTGB,NH,GC and FI (or any other metrics which correlate well to those) canbe used to detect unfair treatments which may lead to social conflicts [7, 61].Similarly, fairness metrics can be used to extract student profiles in collaborativeeducational games [21, 61].8 ConclusionsThis paper addressed the problem of quantitatively measuring fairness, underthe perspective of one individual who interacts with multiple other individuals(i.e. one-to-many interaction scenario). Given that fairness is an abstract andambiguous term with fuzzy boundaries, we have relied on crowdsourced dataobtained via pairwise preference self-reports, and used it to cross validate sixmetrics of fairness. The first four metrics are well-established metrics of thedispersion of data, namely standard deviation, normalised entropy, the Gini co-efficient, and the Fairness Index. The fifth metric, called temporal group-basedfairness (TGB), is a new metric proposed by the authors, is ad-hoc designedfor the one-to-many interaction scenario, and takes into consideration context-based aspects of the distribution task, such as the sequence of distribution andthe presence of group structures within the receiver agents. Finally, the sixthmetric is machine learned on the preference data via ranking Support VectorMachines (SVM).The results obtained show that all metrics are highly consistent (though withdifferent degrees of consistency) with the perception of fairness of hundreds ofour survey participants. It seems, however, that the temporal group-based metricis expressive enough and captures fairness more accurately than the other ad-hoc metrics. Even though the SVM model yields the most accurate fairnessmeasure, the TGB metric is far more expressive and usable. The normalisedentropy and fairness index metrics, however, appear to be the most appropriatefor context-free and generic use, as the TGB metric is based on (and tightenedto) the context of the one-to-many resource allocations scenario. Preliminaryresults have shown the efficacy of NH in capturing fairness and collaboration inartificial societies of agents that play the social ultimatum game [23, 24].The fairness metrics proposed can be used in both simulated scenarios of ar-tificial agent societies to investigate global phenomena, such as collaboration andthe emergence of group structures [23, 24], or in educational collaborative virtualenvironments, in which human-controlled avatars interact with each other [21,61].Acknowledgments. This work has been supported, in part, by the FP7 ICTprojects SIREN (project no: 258453) and ILearnRW (project no: 318803). Theauthors would like to thank all participants of the crowdsourcing experiment.Special thanks to Yana Knight for proofreading.References1. Akerlof, G.A., Kranton, R.E.: Economics and Identity. The Quarterly Journal ofEconomics 115(3), 715–753 (2000)2. Axelrod, R., Hamilton, W.D.: The Evolution of Cooperation (1981)3. Bolton, G.E., Katok, E., Zwick, R.: Dictator Game Giving: Rules of Fairness VersusActs of Kindness. International Journal of Game Theory 27, 269–299 (1998)4. Charness, G., Rabin, M.: Understanding Social Preferences with Simple Tests. TheQuarterly Journal of Economics 117(3), 817–869 (2002)5. Charness, G., Rigotti, L., Rustichini, A.: Individual Behavior and Group Member-ship. Available at SSRN 894685 (2006)6. Chen, Y., Li, S.X.: Group Identity and Social Preferences. The American EconomicReview pp. 431–457 (2009)7. Cheong, Y.G., Khaled, R., Grappiolo, C., Campos, J., Martinho, C., Ingram,G.P.D., Paiva, A., Yannakakis, G.N.: A Computational Approach Towards ConflictResolution for Serious Games. In: Proceedings of the Sixth International Confer-ence on the Foundations of Digital Games. ACM (2010)8. Chu, W., Ghahramani, Z.: Preference Learning with Gaussian Processes. In: Pro-ceedings of the 22nd International Conference on Machine learning. ACM (2005)9. Dawes, R.M., Messick, D.M.: Social Dilemmas. International Journal of Psychology2(35), 111–116 (2000)10. De Jong, S., Tuyls, K., Verbeeck, K.: Artificial Agents Learning Human Fairness.In: Proceedings of the 7th International Joint Conference on Autonomous Agentsand Multiagent Systems. pp. 863–870 (2008)11. Dianati, M., Shen, X., Naik, S.: A New Fairness Index for Radio Resource Alloca-tion in Wireless Networks. In: Wireless Communications and Networking Confer-ence. vol. 2, pp. 712–717 (2005)12. Ducheneaut, N., Yee, N., Nickell, E., Moore, R.J.: Alone Together? Exploring theSocial Dynamics of Massively Multiplayer Online Games. In: Proceedings of theSIGCHI Conference on Human Factors in Computing Systems. pp. 407–416. ACM(2006)13. Eagle, N., Pentland, A.S., Lazer, D.: Inferring Friendship Network Structure by Us-ing Mobile Phone Data. Proceedings of the National Academy of Sciences 106(36),15274–15278 (2009)14. Epstein, J.M., Axtell, R.L.: Growing Artificial Societies: Social Science from theBottom Up (Complex Adaptive Systems). The MIT Press (1996)15. Fehr, E., Fischbacher, U.: Why Social Preferences Matter — The Impact of Non-Selfish Motives on Competition, Cooperation and Incentives. Economic Journal112, 1–33 (2002)16. Fehr, E., Schmidt, K.M.: A Theory Of Fairness, Competition, And Cooperation.The Quarterly Journal of Economics 114(3), 817–868 (August 1999)17. Forsythe, R.: Fairness in Simple Bargaining Experiments. Games and EconomicBehavior 6(3), 347–369 (1994)18. Gal, Y., Grosz, B.J., Kraus, S., Pfeffer, A., Shieber, S.: Colored Trails: a Formalismfor Investigating Decision-making in Strategic Environments. In: Proceedings of the2005 IJCAI Workshop on Reasoning, Representation, and Learning in ComputerGames. pp. 25–30 (2005)19. Gini, C.: Measurement of Inequality of Incomes. The Economic Journal 31(121),124–126 (March 1921)20. Girvan, M., Newman, M.E.: Community structure in social and biological networks.Proceedings of the National Academy of Sciences 99(12), 7821–7826 (2002)21. Grappiolo, C., Cheong, Y.G., Khaled, R., Yannakakis, G.N.: Modelling GlobalPattern Formation for Collaborative Learning Environments. In: Proceedings ofthe IEEE International Conference on Advanced Learning Technologies (2012)22. Grappiolo, C., Cheong, Y.G., Togelius, J., Khaled, R., Yannakakis, G.N.: TowardsPlayer Adaptivity in a Serious Game for Conflict Resolution. In: Proceedings ofthe 3rd IEEE International Conference in Games and Virtual Worlds for SeriousApplications. pp. 192–198 (2011)23. Grappiolo, C., Togelius, J., Yannakakis, G.N.: Interaction-based Group IdentityDetection via Reinforcement Learning and Artificial Evolution. In: Proceedings ofthe Evolutionary Computation and Multi-agent Systems and Simulation workshop,Genetic and Evolutionary Computation Conference. pp. 1423–1430. ACM (2013)24. Grappiolo, C., Yannakakis, G.N.: Towards Detecting Group Identities in ComplexArtificial Societies. In: Proceedings of the Simulation of Adaptive Behaviour Con-ference. pp. 421–430 (2012)25. Greenwood, G.W., Ashlock, D.: Evolutionary Games and the Study of Coopera-tion: Why Has So Little Progress Been Made? In: Proceedings of the IEEE WorldCongress on Computational Intelligence (2012)26. Hammond, R.A., Axelrod, R.: The Evolution of Ethnocentrism. Journal of ConflictResolution 50(6), 926–936 (2006)27. Herbrich, R., Graepel, T., Obermayer, K.: Support Vector Learning for OrdinalRegression. In: Proceedings of the International Conference on Artificial NeuralNetworks. vol. 1, pp. 97 –102 (1999)28. Huberman, B.A., Glance, N.S.: Evolutionary Games and Computer Simulations.Proceedings National Academy of Science 90(16), 7716–7718 (1993)29. Jain, R., Chiu, D.M., Hawe, W.R.: A Quantitative Measure of Fairness and Dis-crimination for Resource Allocation in Shared Computer System. Eastern ResearchLaboratory, Digital Equipment Corporation (1984)30. Joachims, T.: Learning to Classify Text Using Support Vector Machines — Meth-ods, Theory, and Algorithms. Kluwer/Springer (2002)31. Joachims, T.: Optimizing Search Engines Using Clickthrough Data. In: Proceedingsof the 8th SIGKDD International Conference on Knowledge Discovery and DataMining. pp. 133–142. ACM (2002)32. Joe-Wong, C., Sen, S., Lan, T., Chiang, M.: Multi-resource Allocation: Fairness-efficiency Tradeoffs in a Unifying Framework. In: Proceedings of the IEEE Inter-national Conference on Computer Communications. pp. 1206–1214. IEEE (2012)33. Kagel, J.H., Kim, C., Moser, D.: Fairness in Ultimatum Games with AsymmetricInformation and Asymmetric Payoffs. Games and Economic Behavior 13(1), 100–110 (1996)34. Kim, J.H.: The Role of Identity in Intra-and Inter-Group Bargaining in the Ulti-matum Game. Undergraduate Economic Review 4(1), 6 (2008)35. Kranton, R., Pease, M., Sanders, S., Huettel, S.: Identity, Group Conflict, andSocial Preferences. Working Paper (2012)36. Lancichinetti, A., Fortunato, S.: Limits of Modularity Maximization in CommunityDetection. Physical Review E 84(6), 066122 (2011)37. Lansing, S.J.: Complex Adaptive Systems. Annual Review of Anthropology 32,183–204 (2003)38. Mahlmann, T., Togelius, J., Yannakakis, G.N.: Modelling and Evaluation of Com-plex Scenarios with the Strategy Game Description Language. In: Proceedings ofthe IEEE Conference for Computational Intelligence and Games. Seoul, KR (2011)39. Mart´ınez, H.P., Yannakakis, G.N.: Mining multimodal sequential patterns: a casestudy on affect detection. In: Proceedings of International Conference on Multi-modal Interfaces (ICMI). pp. 3–10. ACM (2011)40. Mart´ınez, H., Yannakakis, G.: Genetic Search Feature Selection for Affective Mod-eling: a Case Study on Reported Preferences. In: Proceedings of the 3rd Inter-national Workshop on Affective Interaction in Natural Environments. pp. 15–20.ACM (2010)41. Martinez, R., Kay, J., Wallace, J., Yacef, K.: Modelling Symmetry of Activity asan Indicator of Collocated Group Collaboration. In: User Modeling, Adaption andPersonalization, vol. 6787, pp. 207–218. Springer Berlin / Heidelberg (2011)42. Marzo, F., Grosz, B.J., Pfeffer, A.: Social preferences in Relational Contexts. In:In Fourth Conference in Collective Intentionality (2005)43. Montuno, K., Zhacfi, Y.: Fairness of Resource Allocation in Cellular Networks: ASurvey. Resource Allocation in Next Generation Wireless Networks pp. 249–266(2006)44. Nowak, M.A.: Five Rules for the Evolution of Cooperation. Science 314(5805),1560–1563 (2006)45. Palla, G., Baraba´si, A.L., Vicsek, T.: Quantifying Social Group Evolution. Nature446(7136), 664–667 (2007)46. Pandremmenou, K., Kondi, L.P., Parsopoulos, K.E.: Fairness Issues in Resource Al-location Schemes for Wireless Visual Sensor Networks. In: IS&T/SPIE ElectronicImaging. pp. 866601–866601. International Society for Optics and Photonics (2013)47. Prada, R., Paiva, A.: Teaming Up Humans with Autonomous synthetic Characters.Artificial Intelligence 173(1), 80–103 (2009)48. Rabin, M.: Incorporating Fairness into Game Theory and Economics. The Ameri-can Economic Review pp. 1281–1302 (1993)49. Rocha, J.B., Mascarenhas, S., Prada, R.: Game Mechanics for Cooperative Games,pp. 73–80. Universidade do Minho (2008)50. Seif El-Nasr, M., Aghabeigi, B., Milam, D., Erfani, M., Lameman, B., Maygoli,H., Mah, S.: Understanding and Evaluating Cooperative Games. In: Proceedingsof the 28th International Conference on Human Factors in Computing Systems.pp. 253–262. ACM (2010)51. Shaker, N., Yannakakis, G., Togelius, J.: Crowd-Sourcing the Aesthetics of Plat-form Games. IEEE Transactions on Computational Intelligence and AI in Games(2012)52. Shi, H., Prasad, R.V., Rao, V.S., Niemegeers, I.: A Fairness Model for ResourceAllocation in Wireless Networks. In: Networking Workshops. pp. 1–9. Springer(2012)53. Sonntagbauer, P., Aizstrauts, A., Ginters, E., Aizstrauta, D.: Policy Simulationand E-Governance. In: IADIS International Conference e-Society (2012)54. Szell, M., Thurner, S.: Measuring Social Dynamics in a Massive Multiplayer OnlineGame. Social Networks 32(4), 313–329 (2010)55. Tan, G., Guttag, J.V.: Time-based Fairness Improves Performance in Multi-RateWLANs. In: USENIX Annual Technical Conference, General Track. pp. 269–282(2004)56. Xianyu, B.: Social Preference, Incomplete Information, and the Evolution of Ulti-matum Game in the Small World Networks: An Agent-Based Approach. Journalof Artificial Societies and Social Simulation 13(2), 7 (2010)57. Yannakakis, G.N., Hallam, J.: Towards Optimizing Entertainment in ComputerGames. Applied Artificial Intelligence 21(10), 933–971 (2007)58. Yannakakis, G.N., Hallam, J.: Rating vs. Preference: A Comparative Study ofSelf-reporting. In: Springer (ed.) Proceedings of the 2011 Affective Computing andIntelligent Interaction Conference. Springer (2011)59. Yannakakis, G.N., Martnez, H.P., Jhala, A.: Towards Affective Camera Control inGames. User Modeling and User-Adapted Interaction 20, 313–340 (2010)60. Yannakakis, G.N., Togelius, J.: Experience-Driven Procedural Content Generation.IEEE Transactions on Affective Computing 2, 147–161 (2011)61. Yannakakis, G.N., Togelius, J., Khaled, R., Jhala, A., Karpouzis, K., Paiva, A.,Vasalou, A.: Siren: Towards Adaptive Serious Games for Teaching Conflict Resolu-tion. In: Proceedings European Conference on Games-Based Learning (ECGBL).pp. 412–417. Copenhagen (2010)View publication stats",
    "Link": "https://core.ac.uk/download/157728207.pdf"
}