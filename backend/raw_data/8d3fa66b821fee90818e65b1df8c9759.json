{
    "Title": "Algorithm Evolution Using Large Language Model",
    "Authors": "Liu, Fei, Tong, Xialiang, Yuan, Mingxuan, Zhang, Qingfu",
    "Year": "No year available",
    "Abstract": "Optimization can be found in many real-life applications. Designing an\neffective algorithm for a specific optimization problem typically requires a\ntedious amount of effort from human experts with domain knowledge and algorithm\ndesign skills. In this paper, we propose a novel approach called Algorithm\nEvolution using Large Language Model (AEL). It utilizes a large language model\n(LLM) to automatically generate optimization algorithms via an evolutionary\nframework. AEL does algorithm-level evolution without model training. Human\neffort and requirements for domain knowledge can be significantly reduced. We\ntake constructive methods for the salesman traveling problem as a test example,\nwe show that the constructive algorithm obtained by AEL outperforms simple\nhand-crafted and LLM-generated heuristics. Compared with other domain deep\nlearning model-based algorithms, these methods exhibit excellent scalability\nacross different problem sizes. AEL is also very different from previous\nattempts that utilize LLMs as search operators in algorithms",
    "Keywords": "No keywords available",
    "Publisher": "",
    "Publication Date": "No publication date available",
    "Journal": "No journal available",
    "Citation Count": 0,
    "Full Text": "IEEE JOURNAL 1Algorithm Evolution Using Large Language ModelFei Liu, Xialiang Tong, Mingxuan Yuan and Qingfu Zhang, Fellow, IEEEAbstract—Optimization can be found in many real-life applica-tions. Designing an effective algorithm for a specific optimizationproblem typically requires a tedious amount of effort from humanexperts with domain knowledge and algorithm design skills.In this paper, we propose a novel approach called AlgorithmEvolution using Large Language Model (AEL). It utilizes a largelanguage model (LLM) to automatically generate optimizationalgorithms via an evolutionary framework. AEL does algorithm-level evolution without model training. Human effort and require-ments for domain knowledge can be significantly reduced. Wetake constructive methods for the traveling salesman problem as atest example, we show that the constructive algorithm obtainedby AEL outperforms simple hand-crafted and LLM-generatedheuristics. Compared with other domain deep learning model-based algorithms, these methods exhibit excellent scalabilityacross different problem sizes. AEL is also very different fromprevious attempts that utilize LLMs as search operators inalgorithms.Index Terms—Algorithm evolution, Large language model,Combinatorial optimization, Evolutionary optimization, Heuris-tic.I. INTRODUCTIONOPTIMIZATION is everywhere. It plays a crucial rolein production, planning, decision making, and resourcemanagement. Numerous research works have been carriedout to develop efficient and powerful optimization algorithms.While these algorithms have proven to be valuable tools inmany practical scenarios, designing them usually requiresextensive manual crafting with domain knowledge [1]–[3].To overcome these limitations, researchers have made mucheffort to automate the algorithm design process. Learning tooptimize [4] involves automatically designing optimizationmethods based on their performance on a training set ofproblems. In deep learning, AutoML [5] offers promisingsolutions for constructing a deep learning system withouthuman intervention. In the context of heuristic design, this iscommonly referred to as hyperheuristics [6], [7] or automaticdesign of heuristics [8]. Moreover, reinforcement learning [9]–[12], supervised learning [13], [14], transfer learning [15]–[17]and meta-learning [18], [19] have also been widely employedto enhance optimization efficiency, promote algorithm per-formance, and generate new algorithms. Furthermore, recentworks have explored the use of end-to-end neural solversfor both continuous optimization [20]–[24] and combinatorialoptimization [25]–[29]. While these progresses have signifi-cantly advanced the field of automatic algorithm design, theyFei Liu and Qingfu Zhang are with the Department of ComputerScience, City University of Hong Kong, Hong Kong (e-mail: fliu36-c@my.cityu.edu.hk; qingfu.zhang@cityu.edu.hk).Xialiang Tong and Mingxuan Yuan are with Huawei Noah’s Ark Lab (e-mail: tongxialiang@huawei.com; yuan.mingxuan@huawei.com).ProblemAlgorithmProblemAlgorithmProblemAlgorithmAlgorithmAlgorithmDataLLMEvolutionTrainingTrial & Error(a) Human (b) Domain Model (c) AEL20 100 200 500 1000Problem Size0102030405060GapHumanDomain ModelLLM (GPT-3.5-turbo)LLM (GPT-4)AEL (GPT-3.5-turbo)AEL (GPT-4)Fig. 1. A comparison of three different algorithm design approaches (a)Human, (b) Domain Model, and (c) AEL, and the their results on TSP.The x-axis represents the problem size. The y-axis represents the gap (%) tothe baseline. All results are averaged on 64 randomly generated instances.(a) Human (Greedy): an algorithm designed by humans with trial anderror (a greedy algorithm). (b) Domain Model: an algorithm learned by aspecific deep neural network trained on TSP50. (c) AEL: algorithms createdby our proposed AEL evolved on TSP50. We also compare the algorithmsdirectly generated by instructing LLM (LLM). The used LLMs are denotedin brackets. Refer to the experimental section for more details.usually require an underlying algorithm framework or a time-consuming domain model crafting and training.In the past three years, large language models (LLMs)have demonstrated remarkable capabilities in various researchdomains [30], [31], such as natural language processing [32],programming [33], medicine [34]–[36], chemistry [37], chipdesign [38], [39], and optimization [40]–[43]. Recently, severalworks have adopted LLMs as pre-trained black-box optimizersfor optimization [21], [44]–[47]. However, these works useLLMs to generate new solutions at the operator level. Itsperformance declines considerably when applied to large-scaleproblems, mainly due to the longer solution representation andlarge search space [44], [47], [48].In this paper, we propose a novel approach for practicalautomatic algorithm design called Algorithm Evolution usingLarge Language Model (AEL). AEL distinguishes itself fromarXiv:2311.15249v1  [cs.NE]  26 Nov 2023IEEE JOURNAL 2algorithm design by humans and through training domainmodels. It creates and modifies algorithms by interacting withlarge language models within an evolutionary framework. Wedemonstrate the effectiveness of AEL on the constructivemethod for the traveling salesman problem (TSP), highlightingits ability to generate novel and scalable algorithms. Thecontributions of this paper are summarized as follows:• We introduce AEL, which treats each algorithm as an in-dividual and utilizes an evolutionary framework to evolvenew algorithms. Our approach integrates large languagemodels at the algorithm design level, allowing for thecreation and modification of existing search strategieswith minimal expert knowledge and no domain modeltraining.• We demonstrate AEL on designing the constructiveheuristic for TSP, a well-known combinatorial optimiza-tion problem. The individual representation and promptengineering strategies for TSP are designed.• We compare three algorithm design approaches (a) agreedy algorithm designed by humans (Human), (b) analgorithm learned by a specific model through time-consuming training (Domain Model), and (c) algorithmsdesigned automatically by our proposed AEL (AEL).The comparison of these three approaches and a sum-mary of results on TSP with different problem sizes areillustrated in Fig. 1. The results demonstrate that AELoutperforms the manually designed greedy heuristic forall problem sizes. Furthermore, AEL exhibits better gen-eralization performance compared to training a domainmodel. We also highlight the superiority of AEL overdirectly instructing LLM (LLM) to generate algorithms.AEL benefits from the use of more advanced languagemodels, such as GPT-4.The rest of this paper is structured as follows: In Section II,we provide an overview of related work in automatic algorithmdesign and the use of large language models in optimization.Section III presents the framework and methodology of ourproposed AEL. In Section IV, we present the demonstrationand experimental results on TSP and a discussion of findingsfollowed by some suggested future directions. Section VIconcludes the paper.II. RELATED WORKSA. Automatic Algorithm Design (AAD)Automatic algorithm design (AAD) is an active and rapidlygrowing research area in heuristic design [49]. It is com-monly referred to as hyper-heuristics [6], [7] or automaticdesign of heuristics [8]. A number of effective toolboxesand frameworks have been proposed, such as GGA [50],ParamILS [51], MO-ParamILS [52], irace [53], SMAC [54],and Optuna [55], which significantly facilitate researchers inthe field. From the algorithm perspective, AAD can be brieflycategorized into three main approaches: automatic algorithmconfiguration, automatic algorithm selection, and automaticalgorithm composition [56]. Many recent research works inAAD focus on automatically generating improved algorithmsusing general heuristic components [8]. For example, Au-toEMOA for multi-objective evolutionary optimization [57]and AutoGCOP for general-purpose optimization [56]. Despitethese advancements, these approaches still require a backbonedomain algorithm framework or a set of manually craftedalgorithm components, and the designing process can be time-consuming.B. Machine Learning for OptimizationOver the past few decades, much effort has been madeon the integration of machine learning techniques for opti-mization [4], [5], [58], [59]. Reinforcement learning tech-niques have been used to learn optimal algorithm configu-rations [9], policy for operator selection [10], [11], solutionselection [12], and construction of the partial solution [60].[13], [14], [61], [62] adopt supervised learning for solutionprediction to boost heuristics and mathematical programming.Transfer learning [15], [16] and meta-learning [18], [19] havealso been employed to transfer and extract knowledge fromdifferent tasks or solutions to improve optimization efficiency.Other popular directions include using surrogate models toapproximate the objective functions or relations, which havebeen successfully applied in expensive optimization in variousdomains [63]–[67], and learning through genetic program-ming [68], [69], which is explainable and well-suited forstructure representation.Furthermore, recent works have explored the use of end-to-end neural solvers for both continuous optimization [20]–[24]and combinatorial optimization [25]–[29]. Some of them havebeen applied for EC. For example, [20]–[23] train deep neuralnetworks to approximate mutation, crossover, and evolutionarystrategies for black-box optimization. [24] enhances evolution-ary algorithms through learning from historically successfulexperiences. However, in spite of the promising results, theyoften require significant effort in designing and training thedomain models.C. Large Language Model (LLM)In the last three years, large language models (LLMs) havegained increasing power due to their exponentially growingmodel sizes and the availability of large training datasets.LLMs have shown remarkable performance in various re-search domains including natural language processing [32],programming [33], medicine [34]–[36], chemistry [37], chipdesign [38], [39], and optimization [40]–[42]. These LLMsexcel at performing diverse tasks in a zero-shot manner [30],[31]. Despite these advancements, the practical utilization ofLLMs for designing optimization algorithms is still in its earlystages.D. LLMs for Algorithm DesignRecently, several works have demonstrated the potential ofoptimization solely through prompting LLM [44], [70]. [48]proposes a decomposition-based framework that integratesLLM as a black-box operator for multiobjective evolutionaryoptimization. In the context of single-objective evolutionaryIEEE JOURNAL 3AlgorithmParent AlgorithmOffspring AlgorithmAlgorithmAlgorithmParent AlgorithmParent AlgorithmOffspring AlgorithmAlgorithmExample Algorithm CrossoverExample Algorithm MutationParent Algorithm 1• Description: Select the next unvisited nodethat is nearest to the current node• Code:Parent Algorithm 2• Description: Select the next unvisited nodethat is farthest to the destination node• Code:Offspring Algorithm…Algorithm Mutation Prompt EngineeringAlgorithm Crossover Prompt Engineeringdef name (input1, …, inputI)parent code 1return outputdef name (input1, …, inputI)parent code 2return output• Description: Select the next unvisitednode that has the smallest distance to thecurrent node, subtracting the distance tothe destination node.• Code: def name (input1, …, inputI)offspring codereturn outputOffspringAlgorithm • Description: Select the next unvisitednode that has the smallest distance to thecurrent node, subtracting the distance tothe destination node.• Code: def name (input1, …, inputI)parent codereturn outputParentAlgorithm • Description: Select the next unvisitednode that with the smallest ratio of thedistance to the current node divided bythe distance to the destination node• Code: def name (input1, …, inputI)offspring codereturn outputOffspringAlgorithm Crossover using LLMMutation using LLMSelectionPopulationOffspring AlgorithmEvaluationOn InstancesPopulationManagementFig. 2. An illustration of the AEL framework. The left-hand side flowchart adopts a standard evolutionary framework, comprising prompt engineering of LLMfor initialization, crossover, and mutation to create/evolve new algorithms. On the right-hand side, there are two examples demonstrating algorithm crossoverand algorithm mutation, specifically in their application to selecting the next node in a route.algorithms, [44], [71], [72] adopt LLM for the selection,crossover, and mutation processes. LLM has also been inte-grated into neural architecture design [46], [73], [74], MonteCarlo Tree Search [43] and graph-based combinatorial opti-mization [47]. The applications of LLM for genetic program-ming and open-ended tasks are discussed in [45], [75].However, most of these works directly use LLM as opti-mizers, which suffers from poor generalization performanceon large-scale problems. The longer solution representationand large search space, especially on combinatorial optimiza-tion problems [44], [47], [72], pose significant challengesto zero-shot generalization and in-context learning for LLM.[48] proposes to use an explainable lightweight operator toapproximate the results of LLMs for better generalization incontinuous optimization, which is not suitable for addressingcombinatorial optimization problems.III. ALGORITHM EVOLUTION USING LARGE LANGUAGEMODELA. AEL FrameworkThe proposed Algorithm Evolutionary using Large Lan-guage Model (AEL) framework embraces the common frame-work utilized in evolutionary computing (EC). It evolves apopulation of individuals and comprises fundamental com-ponents, including initialization, selection, crossover, muta-tion, and population management. In spite of the generalevolution framework, AEL differs significantly from existingapproaches.• Firstly, unlike major algorithms in EC, where individualsrepresent feasible solutions, each individual within ourAEL framework represents an algorithm designed explic-itly for a given problem. AEL evolves algorithms capableof generating novel and competitive search strategies fora target problem, rather than seeking improved solutionsfor specific instances.• Furthermore, AEL distinguishes itself from other auto-matic algorithm design methods. By integrating LLMsinto an evolutionary framework, the creation and refine-ment of algorithms occur automatically, eliminating theneed for training new models or utilizing baseline algo-rithms. In contrast, existing automatic algorithm designmethods often require expensive searches for improvedalgorithms or rely on specific model training.Fig. 2 illustrates the AEL flowchart and examples of al-gorithm crossover and algorithm mutation. AEL begins withan initialization step, where a population of N individuals(algorithms), denoted as P = {a1, . . . , aN}, is created andevaluated. The creation of algorithms in the initializations canbe either using existing algorithms or letting LLM generatealgorithms. Each individual aj is evaluated using a fitnessfunction, resulting in the fitness value f(aj). The fitness isevaluated on a branch of evaluation instances instead of onone instance.The framework then proceeds with a series of iterations,for a total of Ng generations with N iterations for eachgeneration. In each iteration, a subset of l individuals pj ={a1, . . . , al} is selected from the population using a selectionmethod (we select each individual with equal probability inthe experiments). The selected individuals are then subjectedto a crossover operation with a probability θ1, resulting in anew set of s individuals oj = {a1, . . . , as} created by LLM.IEEE JOURNAL 4The crossover operation ensures the exploration of differentgenetic information from the input subset pj .For each individual ak in the set oj , a mutation operationis applied with a probability θ2. This operation modifies theinput algorithm, potentially introducing a new algorithm oran algorithm with different parameters into the population.Subsequently, the fitness of each mutated individual ak isevaluated.To maintain a constant population size during the evolu-tion process, population management is performed. The newindividuals oj are added to the population P . Afterward, thepopulation P is managed to reduce its size from (s+1)×Nto N by deleting the worst ones.Ultimately, the AEL Framework aims to find the bestalgorithm within the given population, denoted as a∗. Byiteratively applying selection, crossover, mutation, and pop-ulation management, AEL stimulates LLM to evolve a betteralgorithm for the optimization problem at hand.Algorithm 1: AEL FrameworkInput: The number of population: Ng; Population sizeN ; Probability of crossover σ1; Probability ofmutation σ2; The number of parents l forcrossover; The number of new individuals s forcrossover; A given LLM.Output: Best algorithm a∗.Initialization:for j = 1, . . . , N doAlgorithm Creation: create new individual ajgiven the target problem using LLM; Evaluate ajand get fitness value f(aj);Construct initial population P = {a1, . . . , aN};for i = 1, . . . , Ng dofor j = 1, . . . , N doSelection: select a subset of input individualspj = {a1, . . . , al};Algorithm Crossover with probability θ1:create individual oj = {a1, ..., as} using LLMgiven the target problem and input subset pj ;for k = 1, . . . , s doAlgorithm Mutation with probability θ2:modify individual ak using LLM;Evaluate ak and get fitness value f(ak);Population management: P = P ∪ {o1, ..., oN},manage population P to reduce the size from(s+ 1)Ṅ to N .B. Individual RepresentationUnlike previous works, our proposed AEL approach repre-sents each individual as an algorithm tailored to the specificproblem. Each individual consists of three components: 1) adescription of the algorithm in natural language, 2) a codeblock in a pre-defined format, and 3) a fitness value.The algorithm description comprises a few sentences innatural language that can be easily processed by LLM. Thecode block should follow a predefined format so that it canbe identified and seamlessly integrated into our AEL frame-work. We introduce the four basic components that should beincluded in the prompt engineering to format the code block:• Name of class or function: The name of the class or func-tion must be standardized to ensure easy identification bythe main program.• Input: The number and names of input variables need tobe provided, along with their types and their charactersin the program. This information helps LLM understandthe available information and design a viable algorithmbased on it.• Output: The number and names of output variables shouldalso be defined, along with their types and their utiliza-tion.• Other hints: we expect the response to be innovative, andwant to avoid too many explanations and code comments,which might lead to failure identification and increase theresponse time and cost. Any other problem-specific hintsshould also be included in the prompt.The evaluation of individuals in AEL involves running thealgorithms on an evaluation instance set of the target problem.This evaluation process differs from traditional evolutionarycomputing, which typically evaluates the objective functionfor a single instance, but is closer to AAD methods [51], [53],[54].C. InitilizationThe initial population can be either constructed by usingexisting manually crafted algorithms or created using LLM.In our experiments, we choose to let LLM create all theinitial algorithms to eliminate the use of expert knowledge.We provide the following guidelines for prompt engineeringfor algorithm creation using LLMs. The prompt should includethe following three parts:• A description of the task: A description of the opti-mization task. The description should be a concise butcomprehensive introduction to the target problem.• An expected output: A description of the expectedresponses that we want. We desire both a description ofthe new algorithm and a corresponding code block withpre-defined inputs and outputs. The responses should beprovided in a specific format.• Initialization-specific hints: We prioritize the inclusionof diverse algorithms during the initialization process,thus emphasizing the development of a novel algorithmthat distinguishes itself from those in the literature. Wemay also encourage more randomness and diversity byexplicitly instructing the LLM to be creative.We run the prompting procedure for N times to generate Ninitial algorithms.D. SelectionWe simply select input l algorithms randomly from thepopulation P . This selection strategy aligns with the con-ventional EC. The difference is that The number of selectedIEEE JOURNAL 5individuals in our framework is scalable, as the LLM takesprompt in a flexible manner. This scalability is only limitedby the maximum input token size depending on the adoptedLLM.E. CrossoverFor the j-th iteration, the input of crossover consists of aset of l selected individuals, denoted as pj = {a1, . . . , al},and the output is a new set of s individuals, denoted asoj = {a1, . . . , as}. The process of prompt engineering forcrossover involves using the target problem and the selectedindividuals to generate a prompt for LLM, which in turncreates new algorithms. The prompt itself is a combinationof natural language and code and is structured into four parts:• A description of the task: It is identical to that usedduring initialization.• Parent algorithms: It comprises a set of l input parentindividuals. For each individual, both the algorithm de-scription and code are provided.• An expected output: It includes a description of thedesired responses in a specific format.• Crossover-specific hints: It emphasizes the need forthe new algorithm to draw motivation from the parentalgorithms while still being distinct from them.F. MutationIn mutation, the input algorithm is modified using LLM tocreate a new algorithm. The engineering approach for mutationinvolves using the target problem and one input individual togenerate a prompt that allows for the modification of the inputalgorithm with LLM. The prompt consists of a combinationof natural language and code, and it includes the followingfour components:• A description of the task: It is identical to that usedduring initialization.• A parent algorithm: Only one input parent individual.Both the algorithm description and code are provided.• An expected output: A description of the expectedresponses we want. The responses should be given ina specific format.• Mutation-specific hints: It emphasizes that the newalgorithm should be a revision of the input algorithm.G. Population ManagementIn population management, we remove the worst individualsin terms of fitness value to reduce the population size from(s+ 1)N to N .IV. DEMONSTRATION ON TSPThe traveling salesman problem (TSP) is one of the mostimportant combinatorial optimization problems. The problemis to find the shortest route to visit all the given locations onceand return to the starting location. It is recognized as NP-hard and is usually solved using heuristic algorithms. Amongdifferent heuristics [76], constructive heuristics are flexible andeasy to implement. In constructive heuristics, the solution isconstructed step-by-step by choosing the next node given thecurrent node and the destination node. This autoregressivemanner is also used by many recent works on learning adomain neural model for combinatorial optimization [25],[77].We adopt the same constructive framework to iterativelychoose the next node. The task for AEL in this case is tocreate a novel and competitive algorithm to choose the nextnode.A. AEL ImplementationAEL is a general framework for algorithm design. Fora target problem like TSP, we only need to implement theproblem-specific parts. i.e., the individual representation andthe prompting engineering for initialization, crossover, andmutation.1) Individual Representation: The objective of AEL is toevolve an algorithm that identifies the next node based onproblem information and the current state. As mentionedpreviously, each individual in AEL comprises three compo-nents: 1) an algorithm description, 2) a code block, and 3)a fitness value. Fig 3 presents an example of the individualrepresentation of the greedy algorithm, which selects the nextnode that is the nearest one to the current node.The algorithm description is presented in a natural languageformat. To avoid a noisy long response, we explicitly informthe LLM that the algorithm description should not exceed twosentences. It is important to note that, in more complex tasks,a longer sentence limitation can be adopted. In addition to it,we pose no additional limitations.The code is a Python function named ”select next node”,which takes inputs including the current node, destinationnode, unvisited nodes, and distance matrix, and outputs thenext selected node.Algorithm Description:The algorithm selects the next nearest unvisited node based on the current node,destination node, unvisited nodes, and distances between them. It iterates through eachunvisited node and calculates the distance between the current node and each unvisitednode. The node with the shortest distance is chosen as the next node.Code Block:def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):shortest_distance = float('inf')next_node = Nonefor node in unvisited_nodes:distance = distance_matrix[current_node][node]if distance < shortest_distance:shortest_distance = distancenext_node = nodereturn next_nodeFig. 3. An example of individual representation of the greedy algorithm.Algorithm Description is a brief algorithm description in two sentences.Code Block includes a Python function named ”select next node” with apre-defined input and output. The fitness value is a real number, which is notdepicted.The fitness value is evaluated using a set of 64 randomlygenerated TSP instances of size 50. The fitness is calculatedas the average gap to the commercial solver Gurobi. Smallervalues indicate better fitness.IEEE JOURNAL 62) Prompt Engineering for Initialization, Crossover, andMutation: The details are illustrated in Fig. 4. The fivedifferent colors represent five different components includingA description of task, Parent algorithm(s), Prompt-specifichints, An expected output, and Other hints.The task involves developing a new strategy for selectingthe next node at each step, which remains consistent acrossall three prompts. Only crossover and mutation include parentalgorithms in the prompts. Regarding prompt-specific hints,we instruct the LLM to create a completely new algorithmduring initialization, while in crossover and mutation, thealgorithm should be inspired by and modified from the par-ent algorithm(s). This description aligns with the respectivefunctions of each component in the evolutionary framework:the desire for diverse algorithms in the initial population andthe expectation that newly created algorithms during evolutionwill inherit certain aspects from their parents. The formatof the expected output remains almost identical for all threeprompts. We explicitly define the name, input, and output ofthe code block for easy identification by the AEL framework.Additionally, we include other hints to emphasize innovationand discourage the need for extra explanations for efficiencyand robustness.B. Experiments1) Experimental Settings: The experiments are carried outon 64 randomly generated TSP50 instances, i.e., each algo-rithm is evaluated on 64 TSP50 instances and the fitness valueis the average gap to the optimal solution generated by Gurobi.The experimental settings for AEL are as follows:• Population size N : 10• Number of population Ng: 10• Probability for crossover σ1: 1.0• Probability for mutation σ2: 0.2• Number of parent individuals l: 2• Number of offspring individuals s: 1• LLM: GPT-3.5-turbo and GPT-4We compared our AEL method to three kinds of existingalgorithm design approaches. Note that there are countlessworks using other frameworks. We compare the methods thatfollow the same step-by-step constructive framework as thatused for AEL. We are able to further promote the performanceby applying AEL in other advanced frameworks.The three compared approaches as well as the methods are:• Algorithm design by humans: Greedy search (Greedy),which selects the nearest node as the next node.• Algorithm design using domain model: Neural com-binatorial optimization (Domain model), which trains aneural network to learn the heuristic for selecting thenext node. In this study, we adopt POMO [77], a widelyemployed neural solver baseline. We train it on TSP50using exactly the same settings as in the original paper[77]. The training costs about four days.• Algorithm design using LLM: LLM with prompt engi-neering (LLM). We directly generate a novel algorithmby instructing LLM. The prompt is the same as that usedin the initialization stage of AEL.• AEL: Our proposed AEL.Initialization Prompt for TSP:Task: Given a set of nodes with their coordinates, you need tofind the shortest route that visits each node once and returns tothe starting node. The task can be solved step-by-step by startingfrom the current node and iteratively choosing the next node.You should create a totally new strategy for me (different fromthe heuristics in the literature) to select the next node in each step,using information including the current node, destination node,unvisited nodes, and distances between them.Provide a brief description of the new algorithm and itscorresponding code. The description must start with ‘<start>’ andend with ‘<end>’. The code function must called'select_next_node' that takes inputs 'current_node','destination_node', 'unvisited_nodes', and 'distance_matrix', andoutputs the 'next_node', where 'current_node', 'destination_node','next_node', and 'unvisited_nodes' are node id.Be creative and do not give additional explanation.Crossover Prompt for TSP:Task: Given a set of nodes with their coordinates, you need to findthe shortest route that visits each node once and returns to thestarting node. The task can be solved step-by-step by starting fromthe current node and iteratively choosing the next node.I have <l> algorithms with their code to select the next node in eachstep.The first algorithm and the corresponding code is:<Algorithm description>: …<Code>: …The second algorithm and the corresponding code is<Algorithm description>: …<Code>: …(more …)Please help me create a new algorithm that motivated by the givenalgorithms. Please provide a brief description of the new algorithmand its corresponding code. The description must start with ‘<start>’and end with ‘<end>’. The code function must called'select_next_node' that takes inputs 'current_node', 'destination_node','unvisited_nodes', and 'distance_matrix', and outputs the 'next_node',where 'current_node', 'destination_node', 'next_node', and'unvisited_nodes' are node id.Be creative and do not give additional explanation.Mutation Prompt for TSP:Task: Given a set of nodes with their coordinates, you need to findthe shortest route that visits each node once and returns to thestarting node. The task can be solved step-by-step by starting fromthe current node and iteratively choosing the next node.I have an algorithm with its code to select the next node in each step.The algorithm and the corresponding code is:<Algorithm description>: …<Code>: …Please assist me in creating a modified version of the algorithmprovided. Please provide a brief description of the new algorithm andits corresponding code. The description must start with ‘<start>’ andend with ‘<end>’. The code function must called 'select_next_node'that takes inputs 'current_node', 'destination_node', 'unvisited_nodes',and 'distance_matrix', and outputs the 'next_node', where'current_node', 'destination_node', 'next_node', and 'unvisited_nodes'are node id.Be creative and do not give additional explanation.Crossover Prompt for TSP:Task: Given a set of nodes with their coordinates, you need to findth shortest route that visits each node once and retu ns to thstarting node. The task can be solved step-by-step by starting fromthe current node and iteratively choosing the next node.I have <l> algorithms with their code to select the next node in eachstep.The first algorithm and the corresponding code is:<Algorithm description>: …<Code>: …The second algorithm and the corresponding code is<Algorithm description>: …<Code>: …(more …)Please help me create a new algorithm that motivated by the givenalgorithms. Please provide a brief description of the new algorithmand its corresponding code. The description must start with ‘<start>’and end with ‘<end>’. The code function must called'select_next_node' that takes inputs 'current_node', 'destination_node','unvisited_nodes', and 'distance_matrix', and outputs the 'next_node',where 'current_node', 'destination_node', 'next_node', and'unvisited_nodes' are node id.Be creative and do not give additional explanation.Mutation Prompt for TSP:Task: Given a set of nodes with their coordinates, you need to findthe shortest route that visits each node once and returns to thestarting node. The task can be solved step-by-step by starting fromthe current node and iteratively choosing the next node.I have an algorithm with its code to select the next node in each step.The algorithm and the corresponding code is:<Algorithm description>: …<Code>: …Please assist me in creating a modified version of the algorithmprovided. Please provide a brief description of the new algorithm andits corresponding code. The description must start with ‘<start>’ andend with ‘<end>’. The code function must called 'select_next_node'that takes inputs 'current_node', 'destination_node', 'unvisited_nodes',and 'distance_matrix', and outputs the 'next_node', where'current_node', 'destination_node', 'next_node', and 'unvisited_nodes'are node id.Be creative and do not give additional explanation.Fig. 4. Prompts used in the initialization, crossover, and mutation of AELfor TSP: A description of task, Parent algorithm(s), Prompt-specific hints, Anexpected output, and Other hints.IEEE JOURNAL 71 2 3 4 5 6 7 8 9 10Number of Generations020406080100120140GapMeanBestHuman (Greedy)AlgorithmsFig. 5. The convergence curve of AEL using GPT-4 on TSP50, where eachsample represents an algorithm created in the evolution. The orange and redlines represent the mean and best objective values and the dotted black linerepresents the greedy algorithm.2) Experimental Results: Fig 5 illustrates the convergenceprocess of the proposed AEL using GPT-4 on the TSP50dataset. The y-axis represents the gap (%) to the optimalsolution and the x-axis represents the number of generations.Each blue data point represents an algorithm created by AELduring the evolution. The orange and red lines depict theconvergence curves of the mean and best objective values,respectively, in each population. The black line represents thegreedy algorithm designed by humans.It can be observed that there is a clear convergence in termsof both the mean and best objective values as the evolutionprogresses. AEL nearly converges in 10 generations, and theoptimal gap is reduced from 20% to around 12%. The bestalgorithm generated by GPT-4 in the first population is closeto the greedy algorithm, while AEL clearly beats the greedyalgorithm towards the end of evolution.As illustrated in Fig. 6, the best algorithm created by AELis significantly more complicated than the greedy algorithm.It selects the next node considering various factors such as itsdistance to other unvisited nodes, mean distance, and standarddeviation of these distances. The algorithm assigns a higherweight to close clusters of nodes by incorporating the standarddeviation into the scoring system. Additionally, the algorithmincludes a conditional statement that ensures nodes far fromthe rest are not chosen prematurely by selecting the closestnode when the minimum calculated score exceeds a speci-fied threshold. The created Python code block employs theNumPy library for calculations. The code starts with definingthe select next node function, which takes the current node,destination node, unvisited nodes, distance matrix, and anoptional threshold parameter. Inside the function, a dictionarycalled scores is created to store the scores for each unvisitednode. The algorithm iterates through each node in the unvis-ited nodes list and calculates the score based on the providedformula. The minimum score is then compared to the specifiedthreshold, and based on the result, the next node is deter-mined. Finally, the function returns the selected next node.The automatically designed best algorithm by AEL presentsa sophisticated strategy incorporating an additional thresholdAlgorithm Description:This enhanced algorithm considers the current node's distance to the other unvisitednodes and the mean distance, but also incorporates the standard deviation of thesedistances into the scoring system, giving a higher weight to close clusters of nodes. It alsoincludes a conditional statement that chooses the closest node when the minimumcalculated score exceeds a specified threshold, ensuring that nodes far from the rest arenot chosen prematurely.Code Block:import numpy as npdef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix, threshold=0.7):scores = {}for node in unvisited_nodes:all_distances = [distance_matrix[node][i] for i in unvisited_nodes if i != node]average_distance_to_unvisited = np.mean(all_distances)std_dev_distance_to_unvisited = np.std(all_distances)score = 0.4 * distance_matrix[current_node][node] - 0.3 * average_distance_to_unvisited + 0.2 * std_dev_distance_to_unvisited - 0.1 * distance_matrix[destination_node][node]scores[node] = scoreif min(scores.values()) > threshold:next_node = min(unvisited_nodes, key=lambda node: distance_matrix[current_node][node])else:next_node = min(scores, key=scores.get)return next_nodeFig. 6. The best algorithm created by AEL using GPT-4. AlgorithmDescription is a brief algorithm description in two sentences. Code Blockincludes a Python function named ”select next node” with a pre-defined inputand output.parameter (not explicitly given in the prompt) and a complexscoring function. The scoring function integrates multiplefactors along with four hyperparameters, which presents achallenge, even for an expert, without substantial trial-and-error testing. In contrast, AEL automatically develops the al-gorithm through an iterative process involving 100 interactionswith LLM.3) Evaluation of Optimized Algorithm: We evaluate thebest algorithm designed by AEL on various TSP instanceswith multiple problem sizes and compared the results to otheralgorithm design approaches. Table I shows the performanceof algorithms designed using different approaches on TSP20 toTSP1000. The results are averaged on 64 randomly generatedinstances. Apart from the total distance, we also measured theaverage gap in relation to the baseline solver LKH3. Fig. 1provides a more intuitive comparison of the average gap vs.the problem size of different algorithm design approaches.• AEL outperforms the simple Greedy algorithm designedby humans in all problem sizes. The average gap isreduced by half from 17.0% to 6.2% and from 25.2%to 12.8% for TSP20 and TSP1000, respectively.• AEL demonstrates significantly better generalization per-formance across various problem sizes when comparedto the domain model. The domain model is trained andoverfitted on TSP50, whereas AEL presents a much morerobust solution. Although the domain model surpassesAEL in problem sizes close to the training data, itsperformance rapidly deteriorates on large-scale problems.The average gap increases dramatically from less than 1%to over 50%.• AEL also outperforms directly instructing LLM to designalgorithms. LLM (Average) and LLM (Best) represent theIEEE JOURNAL 8TABLE IEVALUATION OF ALGORITHMS DESIGNED BY DIFFERENT APPROACHES ON TSP20-TSP1000.Algorithms20 50 100 200 500 1000Dis. Gap. Dis. Gap. Dis. Gap. Dis. Gap. Dis. Gap. Dis. Gap.Baseline (SOTA Solver LKH3) 3.84 / 5.69 / 7.77 / 10.73 / 16.56 / 23.08 /Human (Greedy) 4.49 17.0% 7.01 23.1% 9.84 26.6% 13.50 25.8% 20.87 26.0% 28.90 25.2%Domain Model 3.86 0.6% 5.71 0.4% 8.01 3.0% 13.02 21.3% 24.34 47.0% 36.53 58.3%LLM (Average) GPT-3.5-turbo 5.04 31.3% 7.56 32.8% 10.62 36.7% 14.35 33.7% 22.04 33.1% 30.05 30.2%GPT-4 7.45 94.2% 14.97 162.9% 24.87 220.1% 37.36 248.0% 61.73 272.8% 86.26 273.8%LLM (Best) GPT-3.5-turbo 4.61 20.3% 6.71 17.9% 10.01 28.9% 13.31 24.0% 20.83 25.8% 28.98 25.6%GPT-4 4.36 13.6% 6.82 19.7% 9.95 28.1% 13.94 29.9% 22.07 33.3% 30.36 31.6%AEL (Ours) GPT-3.5-turbo 4.26 11.2% 6.65 16.8% 9.32 20.0% 13.07 21.8% 20.38 23.1% 28.34 22.8%AEL (Ours) GPT-4 4.07 6.2% 6.33 11.1% 8.58 10.5% 11.94 11.2% 18.67 12.8% 26.03 12.8%0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate 123456 78910111213141516 171819202122 2324 2526272829303132333435363738394041424344454647 484950515253545556575859 6061626364 656667 68697071727374757677787980818283848568788 8990919293949596979899100(a) TSP100, Greedy0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate 123456 78910111213141516171819202122232425262728293031323334 3536373839404142 43 444546474849 5051 525354 55565758596061 6263646566676869707172737475767778798081828384858687 888990919293949596 979899100(b) TSP100, AEL (GTP-3.5-turbo)0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate 12345678910111213141516171819202122232425262728 2930313233343536373839404142434445464748 4950515253545556575859 606162636465666768697071727374 7576777879808182838485868788 899091 9293949596 97989100(c) TSP100, AEL (GTP-4)0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate 12 3456789101112131415161718 19202122232425262728293031323334 3536373839404142 434445464748495051 525354 5556 575859 606162636465666768697071727374757677 78798081 828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131 132133134135136137138139140141142143144145146 147148 149150151152153 154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207 208209210211212213 2142152162172182192202212222232242252 622728229230231 232233234235236237238239240 241242243244 2452462472482492502512522534255256 257258259260261262263264265266 267268269270271 272273274275276277278279 280281282283284285286 287288289290291292293294295296297298299300301302303304 305306307308309310311312313 314315316317318 319320321322323324325326327328329330331332333334 3353363373383393403412343344345346347348349350351 352 3533543553563573583593603612363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401 402 403404405406407408409410411412413414415416417418419420421422423 424425426427428 429430431432433434435 436437438439440441442 443444445446447448449450 451452453454455456457458459460461462463 464465466467468469470471472473474475476477478479 480481482483484 485486487488489490491492493494495496497498499500(d) TSP500, Greedy0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate 12 3456 7891011121314151617181920212223242526272829303132 33343536373839 40 41424344454647484950515253 54555657585960616263 6465 6667 68697071727374757677787980818283848586878889 90 9192 93949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125 126127128 1291301311321331341351361371381391401411421431441456147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195 196197198199200201 202203204205206207208209210211212213214215216217218219 220221222223224225 226227228229230231232233234235236237238239240 241242243244245 246247248249250251252253 254255256257258259260261262263264 265266267268269270271 272273274275276277278279280 281282283284285 286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328 329330331332333334335336337338339340 341342343344345346347348349350351352353354 355356357358359360361362363364365366367368 369370371372373 374375376377378 379380381382383384385386387388389390391 392393394395396397398399 400401402403404405406407408409410411412413414415416 417418419420421422423424 4254264278429430431432 433434 435436437438439 440441442443444 4454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834845486487488489490491492 493494495496497498 499500(e) TSP500, AEL (GPT-3.5-turbo)0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate 12 3456 7891011121314151617181920 2122232425262728 29303132333435363738394041 4243444546474849 505152 5354 5556 57585960616263646566676869707172737475767778 79 80818283848586 878889 90919293949596979899100101102103104105106107108109110111112113 114115116117118119120121122123124125 126127128129130131132133134135136 137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202 203204205206207208209210211212213214215216217218219220221222223224225226227 228229230231232233234235236237238239240241242243244245246247248249250251 252253254255256257258 25926026126226326426526626726826927027127227327427527627278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320 321 3223233243253263273283293 03 1332333334335336337338339340341342343344345346347 348349350351352353354355356357358359360361362363364365366367368369370371372373374 375376377378379380381382383384385386387388389390391392393394 395396397398399400401402403404405406407408409 410411412413414415416417418419 420421422423424425426427428429430431432433434435436 437438439440441442 443444445446447448449450451 452 453454 455456457458459460461462463 46446546646746846947047147247347447547647747847980481482483484485 486487488489490 4914924934495496497498499500(f) TSP500, AEL (GPT-4)0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate12345678910 111213141516 17181920 212223 24252627282930313233 34356373839404142434445464748495051 5253545565758596061626364 656667686970717273 74 7576777879808182838485868788899091929394959697899100101102103104105106107108109 110111112113114115116117118119120121122123124125126127128129301312133134135136137138139140141 142143144145146 1471489150151152153154155156157158159160161162163 164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222 22322422562722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127273274275276277278279280281282283284285286287288289290291292293294295296297 298299300301 3023033043053063073083093103113123133143153163173183193203213223233243253263273283293301332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388 389 390391392393394 395396397398399 400401402403404405406407 408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438 439440441442443444445446447448449450 451452 453454455456457458459460461462463464465466467 468469470471472473474475476477478479480481482483484485486487488489490491492493 4944956497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529 530531532533534535536537538539540541542543544545546547854955055155255355455565 75585595605612563564565566 567568569570571572573574575576577 578579 5805815825835845855865875858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763896406416426436446456466476486496506516526536546556567 658659660661662663664665666667668669670671672673674675676 677 678 679 680681682683 684685686687688689 690691692693694695696697698699700701702703 704705706707708 709710 711712713714715716717718719720721 7227237247257267277287297307317327337347357367738739740741742743744745746747748 7497507517527537547557567577587597607617627637647657667677687697707717727737747757767778779780781782783784785786787788789790791792793794795796797798799 80080180280380480580680780880981081812813814815816817818819820821822823824 825826 827828829830831 8328338348358368378388398408418428438445846847848849850851852853854855856857858859860861862863864865866867 868869870871872873874875 876877878 87980881 882883884885886887888 889890891892893894895896897 898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981 9829839845986987988 9899 0991992993 9949959969979989991000(g) TSP1000, Greedy0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate12345678910111213141516171819202122 2324 2526272829303132334353637383940414243444546 4748495051525354555657585960616263646566676869 70 7172737475 767778 79 80818283 84858687888990 919293 94 9596 979899100101102103104105106107108109110111112113114115116117 118119120121122123124125126127128129130131 132133 134135136137138139 140141142143144145146147148149150151152153154155156157158159160161162163164 165166167168169170171172173174175176 177178179180181182183184185186187188189190191192193194195196197198199 200201202203204 205206 207208209210211212213214215216217 21821922022122222322422522622722822923023123232342352362372382392402412422432442452462472482492502512253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306 307308309310311312313314315316317318319320321322323324325326327328329330331332333433533633733833934034134234334434534634734834935035135235335435535635735835960361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393 394 3953963978399400401402403404405406407408409410411412413414 415416417418419 420 42142242342442542642742842943043143243343443543643743843944044144244344444544644744849450451452453454455456457458459460461462463464654664674684694704712473474475476477847948048148248348448548648748848949049149249344954964974984995005015025035045055065075089510511512513514515516517518 519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551 552553455555655755855956056156256356456556656756856970571572573 574575576577578579 580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630 6316326336346356366376386394064164264364464564664764864950651652653654655656657658659660661662663664665666667668669670671672673674 67567667767867968068168268368468568676886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337 4735736737738739740 741742743744745746747748749750 751752753754755756757758759760761762763764765766767768769770771772773774775776777778779 78078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981811812813814815816817818819820821822823824825826827 82882983083183283834835836837838839840841842843844845 846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876 877878879880881882883884885886887888889890891892893 89489568978988999009019029039049059069079089910911912913914915916 917918919 920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952 9534 955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987 98898999099199299394995996997998999 1000(h) TSP1000, AEL (GPT-3.5-turbo)0.0 0.2 0.4 0.6 0.8 1.0X coordinate0.00.20.40.60.81.0Y coordinate12345678910111213141516 17181920 212223 242526 2728293031323334353637383940414243444546474849505152 5354555657585960616263 6465666768 69701727374756 777879 808182838485868788899091 92 93949596979899100101102103104105106107108109110111112113114115116 117118119120121122123124125126127128129 130131132133134135136 137 138139140141 142143 144145146147148149150151152153154155156 1571581591601611621631641651661671681691701711721731741756177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206 2072082091211212213214215216217218219220221222223224225226227228229230231232233 234235236237238239240241242243244 245246 247248249250251252532542556257258259260261262263264265266267268269270271272273274275276277278279280281282283284 285286287288 289290291292293294295296 297298299300 301302303304305 3063073083093103113123133143153163173183193201322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362 363364 365366367368369370371372373 374375376377378379380381382383384385386387388389390391392393394 395396397398399400401 402403404 4054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484 9450451452453454554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530 531 5325335345355365375385395405415425435445455465475485495505515525535545556557558559560561562 5634565566567568569570571572573574575576577578579580581582583584585586587588589 590591 592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626 6278629630631632633634635636637638639640641642643644645646647 648649650651652653654655656 6576586596606616626636 4665666667668669670671672673674675676677678679680681682683684685686687688689690691 692693694695696697698699700701702703704 7057067078709710711712713714715716717718 719720721722723724725726727728729730 73173273373473573673738739740741742743474574674774874975075175275375475575675775875976076176237647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118 28138148158168178188198208218228238248256827828829830831832833834835836837838839840841842843 844845846847848849850851852853854855 8568578588598608618628638648658668 7868869870871872 873 874875876 877878879880881882883884885886887888889089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292349259269279289930931 932933 934935936937938994094194294394494594694794894995095195295395495595695795895996096196296396496596679689699701972973974975976977978979980981982983984985986987988989990991992993 9949959969979989991000(i) TSP1000, AEL (GPT-4)Fig. 7. A comparison of the greedy algorithm and algorithms developed by AEL, utilizing GPT-3.5-turbo and GPT-4, for solving TSP100, TSP500, andTSP1000 instances. The nodes in the scatter plot represent locations, while the blue lines represent routes generated by the various algorithms. The numbersdisplayed above the scatter plot indicate the sequence in which the locations appear in the route. The starting and ending locations are denoted by red nodes.IEEE JOURNAL 9average and best of ten algorithms directly generated byinstructing LLM. The best LLM algorithm is competitiveto the greedy algorithm but evidently inferior to AEL. In-terestingly, the best gap achieved by LLM with GPT-4 isinferior to GPT-3.5-turbo. An explanation for this is thatGPT-4 is more powerful but can also be overly innovativewith excessive randomness. Consequently, the algorithmsdirectly generated by GPT-4 could be considerably worse.• We also want to note that the demonstration is conductedbased on a basic constructive heuristic framework. Ourcomparison involves the algorithm created by AEL, agreedy algorithm, and a domain model, all using the samestep-by-step constructive framework. However, there arenumerous other complex algorithms capable of generat-ing near-optimal solutions for TSP [78]. Additionally,recent neural solvers specifically designed for large-scale TSP have also demonstrated good generalizationperformance [27], [28], [79]. Advanced frameworks canbe integrated to promote performance in the future.Fig 7 compares the routes generated using the greedyalgorithm and algorithms developed by AEL, utilizing GPT-3.5-turbo and GPT-4, on TSP100, TSP500, and TSP1000instances. The scatter plot nodes represent locations, withthe blue lines indicating the routes generated by differentalgorithms. The numbers displayed above the scatter plotindicate the sequence in which the locations appear in theroute. The starting and ending locations are marked in red. Theresults demonstrate that the algorithms designed by AEL pro-duce superior routes with fewer intersections than the greedyalgorithm, resulting in shorter total distances. Additionally, thestarting and ending nodes are closer together compared to thegreedy algorithm. AEL using GPT-4 outperforms AEL usingGPT-3.5-turbo.C. Created Algorithms or Spliced AlgorithmsIt is debatable whether the LLM can genuinely comprehendand generate new knowledge or if it simply searches andcombines various existing information [80]. As the TSP isa well-studied combinatorial optimization problem with nu-merous publicly available resources and research papers, itis possible that the LLM merely selects or splices existingalgorithms [81]. However, the majority of the algorithmscreated in our AEL framework cannot be found on the webor in publications. The comparison between AEL algorithmsand LLM algorithms also demonstrates that AEL stimulatesthe creation of novel algorithms to a noteworthy extent bycombining evolutionary computing and LLM.D. Less/No Expert KnowledgeAEL requires minimal expert knowledge about the targetproblem. For designers using our AEL framework, the primaryworkload lies in designing the prompt engineering for eachcomponent for the target problem. The prompt engineering ispresented in a natural language format, making it accessibleto algorithm designers from diverse backgrounds.V. FUTURE WORKS• AEL with tools: Equipping LLMs with external toolssignificantly enhances the capabilities of the model [82]–[84]. There are numerous well-crafted existing optimiza-tion algorithms, which can be integrated as effectivetools. This approach provides a more flexible and robustframework as opposed to relying solely on LLM foralgorithm evolution. We can also integrate other heuristicframeworks into AEL. For example, landscape updatingfor guided local search [85], improve large neighborhoodsearch [86], and Tabu search [87].• AEL with additional information: Another interestingdirection is to provide additional information as the inputfor LLM during the optimization process. The informa-tion can be in the form of history search trajectories,external archives, and rewards obtained during optimiza-tion [88], [89]. With more available information, AEL isable to evolve more powerful algorithms.• AEL for complex optimization problems: Complexproblems pose challenges for AEL as they are difficultfor LLMs to comprehend, which is even challenging forhumans. In such cases, it is possible to decompose theproblem into simpler tasks and adopt LLMs for eachtask [90]. A possible solution is to separate the algorithmdescription and coding and evolve in a hierarchical way,i.e., evolve on the algorithm and then generate code foreach algorithm. Refinement techniques [91]–[93] can beapplied to reduce the failure rate.• Multi-objective AEL: The current focus of AEL ismainly on single-objective optimization problems. How-ever, many real-world problems are multi-objective in na-ture, where multiple conflicting objectives need to be si-multaneously considered. As AEL is algorithm-agnostic,we can easily extend AEL to handle multi-objectiveoptimization problems using multi-objective optimiza-tion algorithms [94]. Multi-objective AEL finds trade-off algorithms that satisfy multiple objectives, whichcan be particularly useful in real-world decision-makingscenarios [57].VI. CONCLUSIONThis paper introduces a novel approach called AlgorithmEvolution with Large Language Model (AEL) for automaticalgorithm design. By utilizing a large language model (LLM),AEL automates the generation of optimization algorithmsusing an evolutionary framework. It significantly reduces theneed for expertise knowledge and domain model training.We have demonstrated the effectiveness of AEL on theconstructive method for TSP. Results on TSP instances withproblem sizes ranging from 20 to 1000 show that the algorithmgenerated by AEL outperforms the simple hand-crafted greedyalgorithm and the algorithms generated by directly instructingLLMs. It also exhibits excellent scalability across differentproblem sizes compared to training a domain neural model.Future works on the integration of AEL with more advancedalgorithm frameworks could lead to even more powerfulalgorithms.IEEE JOURNAL 10REFERENCES[1] J. Nocedal and S. J. Wright, Numerical optimization. Springer, 1999.[2] F. W. Glover and G. A. Kochenberger, Handbook of metaheuristics.Springer Science & Business Media, 2006, vol. 57.[3] K. Deb, Optimization for engineering design: Algorithms and examples.PHI Learning Pvt. Ltd., 2012.[4] T. Chen, X. Chen, W. Chen, Z. Wang, H. Heaton, J. Liu, and W. Yin,“Learning to optimize: A primer and a benchmark,” The Journal ofMachine Learning Research, vol. 23, no. 1, pp. 8562–8620, 2022.[5] X. He, K. Zhao, and X. Chu, “Automl: A survey of the state-of-the-art,”Knowledge-Based Systems, vol. 212, p. 106622, 2021.[6] E. K. Burke, M. Gendreau, M. Hyde, G. Kendall, G. Ochoa, E. Özcan,and R. Qu, “Hyper-heuristics: A survey of the state of the art,” Journalof the Operational Research Society, vol. 64, pp. 1695–1724, 2013.[7] E. K. Burke, M. R. Hyde, G. Kendall, G. Ochoa, E. Özcan, and J. R.Woodward, “A classification of hyper-heuristic approaches: revisited,”Handbook of metaheuristics, pp. 453–477, 2019.[8] T. Stützle and M. López-Ibáñez, “Automated design of metaheuristicalgorithms,” Handbook of metaheuristics, pp. 541–579, 2019.[9] L. Ma, N. Li, Y. Guo, X. Wang, S. Yang, M. Huang, and H. Zhang,“Learning to optimize: reference vector reinforcement learning adaptionto constrained many-objective optimization of industrial copper burden-ing system,” IEEE Transactions on Cybernetics, 2021.[10] Y. Tian, X. Li, H. Ma, X. Zhang, K. C. Tan, and Y. Jin, “Deepreinforcement learning based adaptive operator selection for evolutionarymulti-objective optimization,” IEEE Transactions on Emerging Topics inComputational Intelligence, 2022.[11] Z. Zhang, Q. Tang, M. Chica, and Z. Li, “Reinforcement learning-basedmultiobjective evolutionary algorithm for mixed-model multimannedassembly line balancing under uncertain demand,” IEEE Transactionson Cybernetics, 2023.[12] Y. Wu, W. Song, Z. Cao, J. Zhang, and A. Lim, “Learning improvementheuristics for solving routing problems,” IEEE transactions on neuralnetworks and learning systems, vol. 33, no. 9, pp. 5057–5069, 2021.[13] Y. Shen, Y. Sun, X. Li, A. Eberhard, and A. Ernst, “Adaptive solutionprediction for combinatorial optimization,” European Journal of Oper-ational Research, vol. 309, no. 3, pp. 1392–1408, 2023.[14] Y. Sun, S. Wang, Y. Shen, X. Li, A. T. Ernst, and M. Kirley, “Boostingant colony optimization via solution prediction and machine learning,”Computers & Operations Research, vol. 143, p. 105769, 2022.[15] K. C. Tan, L. Feng, and M. Jiang, “Evolutionary transfer optimization-anew frontier in evolutionary computation research,” IEEE ComputationalIntelligence Magazine, vol. 16, no. 1, pp. 22–33, 2021.[16] L. Zhou, L. Feng, K. C. Tan, J. Zhong, Z. Zhu, K. Liu, and C. Chen,“Toward adaptive knowledge transfer in multifactorial evolutionarycomputation,” IEEE transactions on cybernetics, vol. 51, no. 5, pp.2563–2576, 2020.[17] K. Li, R. Chen, and X. Yao, “A data-driven evolutionary transferoptimization for expensive problems in dynamic environments,” IEEETransactions on Evolutionary Computation, 2023.[18] F.-Y. Liu and C. Qian, “Prediction guided meta-learning for multi-objective reinforcement learning,” in 2021 IEEE Congress on Evolu-tionary Computation (CEC). IEEE, 2021, pp. 2171–2178.[19] Z. Zhang, Z. Wu, H. Zhang, and J. Wang, “Meta-learning-based deepreinforcement learning for multiobjective optimization problems,” IEEETransactions on Neural Networks and Learning Systems, 2022.[20] Y. Cao, T. Chen, Z. Wang, and Y. Shen, “Learning to optimize inswarms,” Advances in neural information processing systems, vol. 32,2019.[21] R. Lange, T. Schaul, Y. Chen, T. Zahavy, V. Dalibard, C. Lu, S. Singh,and S. Flennerhag, “Discovering evolution strategies via meta-black-boxoptimization,” in Proceedings of the Companion Conference on Geneticand Evolutionary Computation, 2023, pp. 29–30.[22] L. Penghui, K. Wu, and J. Liu, “Decn: Evolution inspired deep convo-lution network for black-box optimization,” 2022.[23] X. Li, K. Wu, X. Zhang, H. Wang, and J. Liu, “Optformer: Beyondtransformer for black-box optimization,” 2022.[24] Y. Jiang, Z.-H. Zhan, K. C. Tan, and J. Zhang, “Knowledge learning forevolutionary computation,” IEEE Transactions on Evolutionary Compu-tation, 2023.[25] W. Kool, H. Van Hoof, and M. Welling, “Attention, learn to solve routingproblems!” arXiv preprint arXiv:1803.08475, 2018.[26] X. Lin, Z. Yang, and Q. Zhang, “Pareto set learning for neural multi-objective combinatorial optimization,” 2022.[27] J. Zhou, Y. Wu, W. Song, Z. Cao, and J. Zhang, “Towards omni-generalizable neural methods for vehicle routing problems,” arXivpreprint arXiv:2305.19587, 2023.[28] F. Luo, X. Lin, F. Liu, Q. Zhang, and Z. Wang, “Neural combinatorialoptimization with heavy decoder: Toward large scale generalization,”arXiv preprint arXiv:2310.07985, 2023.[29] Z. Wang, S. Yao, G. Li, and Q. Zhang, “Multiobjective combinatorialoptimization using a single deep reinforcement learning model,” IEEETransactions on Cybernetics, 2023.[30] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,J. Zhang, Z. Dong et al., “A survey of large language models,” arXivpreprint arXiv:2303.18223, 2023.[31] E. Kasneci, K. Seßler, S. Küchemann, M. Bannert, D. Dementieva,F. Fischer, U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier et al.,“Chatgpt for good? on opportunities and challenges of large languagemodels for education,” Learning and individual differences, vol. 103, p.102274, 2023.[32] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz,E. Agirre, I. Heintz, and D. Roth, “Recent advances in natural languageprocessing via large pre-trained language models: A survey,” ACMComputing Surveys, 2021.[33] H. Tian, W. Lu, T. O. Li, X. Tang, S.-C. Cheung, J. Klein, and T. F.Bissyandé, “Is chatgpt the ultimate programming assistant–how far isit?” arXiv preprint arXiv:2304.11938, 2023.[34] P. Lee, S. Bubeck, and J. Petro, “Benefits, limits, and risks of gpt-4as an ai chatbot for medicine,” New England Journal of Medicine, vol.388, no. 13, pp. 1233–1239, 2023.[35] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz,“Capabilities of gpt-4 on medical challenge problems,” arXiv preprintarXiv:2303.13375, 2023.[36] K. Cheng, Q. Guo, Y. He, Y. Lu, S. Gu, and H. Wu, “Exploring thepotential of gpt-4 in biomedical engineering: the dawn of a new era,”Annals of Biomedical Engineering, pp. 1–9, 2023.[37] K. M. Jablonka, P. Schwaller, A. Ortega-Guerrero, and B. Smit, “Is gpt-3all you need for low-data discovery in chemistry?” 2023.[38] J. Blocklove, S. Garg, R. Karri, and H. Pearce, “Chip-chat: Challengesand opportunities in conversational hardware design,” arXiv preprintarXiv:2305.13243, 2023.[39] Z. He, H. Wu, X. Zhang, X. Yao, S. Zheng, H. Zheng, and B. Yu,“Chateda: A large language model powered autonomous agent for eda,”arXiv preprint arXiv:2308.10204, 2023.[40] C. Yu, X. Liu, C. Tang, W. Feng, and J. Lv, “Gpt-nas: Neural archi-tecture search with the generative pre-trained model,” arXiv preprintarXiv:2305.05351, 2023.[41] M. Zheng, X. Su, S. You, F. Wang, C. Qian, C. Xu, and S. Al-banie, “Can gpt-4 perform neural architecture search?” arXiv preprintarXiv:2304.10970, 2023.[42] S. Zhang, C. Gong, L. Wu, X. Liu, and M. Zhou, “Automl-gpt:Automatic machine learning with gpt,” arXiv preprint arXiv:2305.02499,2023.[43] Z. Zhao, W. S. Lee, and D. Hsu, “Large language models as com-monsense knowledge for large-scale task planning,” arXiv preprintarXiv:2305.14078, 2023.[44] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, andX. Chen, “Large language models as optimizers,” arXiv preprintarXiv:2309.03409, 2023.[45] E. Meyerson, M. J. Nelson, H. Bradley, A. Moradi, A. K. Hoover,and J. Lehman, “Language model crossover: Variation through few-shotprompting,” arXiv preprint arXiv:2302.12170, 2023.[46] A. Chen, D. M. Dohan, and D. R. So, “Evoprompting: Languagemodels for code-level neural architecture search,” arXiv preprintarXiv:2302.14838, 2023.[47] H. Wang, S. Feng, T. He, Z. Tan, X. Han, and Y. Tsvetkov, “Canlanguage models solve graph problems in natural language?” arXivpreprint arXiv:2305.10037, 2023.[48] F. Liu, X. Lin, Z. Wang, S. Yao, X. Tong, M. Yuan, and Q. Zhang,“Large language model for multi-objective evolutionary optimization,”arXiv preprint arXiv:2310.12541, 2023.[49] M. Gendreau, J.-Y. Potvin et al., Handbook of metaheuristics. Springer,2010, vol. 2.[50] C. Ansótegui, M. Sellmann, and K. Tierney, “A gender-based geneticalgorithm for the automatic configuration of algorithms,” in InternationalConference on Principles and Practice of Constraint Programming.Springer, 2009, pp. 142–157.[51] F. Hutter, H. H. Hoos, K. Leyton-Brown, and T. Stützle, “Paramils:an automatic algorithm configuration framework,” Journal of artificialintelligence research, vol. 36, pp. 267–306, 2009.IEEE JOURNAL 11[52] A. Blot, H. H. Hoos, L. Jourdan, M.-É. Kessaci-Marmion, and H. Traut-mann, “Mo-paramils: A multi-objective automatic algorithm config-uration framework,” in Learning and Intelligent Optimization: 10thInternational Conference, LION 10, Ischia, Italy, May 29–June 1, 2016,Revised Selected Papers 10. Springer, 2016, pp. 32–47.[53] M. López-Ibáñez, J. Dubois-Lacoste, L. P. Cáceres, M. Birattari, andT. Stützle, “The irace package: Iterated racing for automatic algorithmconfiguration,” Operations Research Perspectives, vol. 3, pp. 43–58,2016.[54] F. Hutter, H. H. Hoos, and K. Leyton-Brown, “Sequential model-based optimization for general algorithm configuration,” in Learning andIntelligent Optimization: 5th International Conference, LION 5, Rome,Italy, January 17-21, 2011. Selected Papers 5. Springer, 2011, pp.507–523.[55] T. Akiba, S. Sano, T. Yanase, T. Ohta, and M. Koyama, “Optuna: A next-generation hyperparameter optimization framework,” in Proceedingsof the 25th ACM SIGKDD international conference on knowledgediscovery & data mining, 2019, pp. 2623–2631.[56] W. Meng and R. Qu, “Automated design of search algorithms: Learningon algorithmic components,” Expert Systems with Applications, vol. 185,p. 115493, 2021.[57] L. C. Bezerra, M. López-Ibánez, and T. Stützle, “Automatic component-wise design of multiobjective evolutionary algorithms,” IEEE Transac-tions on Evolutionary Computation, vol. 20, no. 3, pp. 403–417, 2015.[58] Y. Bengio, A. Lodi, and A. Prouvost, “Machine learning for combinato-rial optimization: a methodological tour d’horizon,” European Journalof Operational Research, vol. 290, no. 2, pp. 405–421, 2021.[59] N. Li, L. Ma, G. Yu, B. Xue, M. Zhang, and Y. Jin, “Survey onevolutionary deep learning: Principles, algorithms, applications, andopen issues,” ACM Computing Surveys, vol. 56, no. 2, pp. 1–34, 2023.[60] W. Liu, R. Wang, T. Zhang, K. Li, W. Li, and H. Ishibuchi, “Hybridiza-tion of evolutionary algorithm and deep reinforcement learning for multi-objective orienteering optimization,” IEEE Transactions on EvolutionaryComputation, 2022.[61] W. Dong and M. Zhou, “A supervised learning and control method toimprove particle swarm optimization algorithms,” IEEE Transactions onSystems, Man, and Cybernetics: Systems, vol. 47, no. 7, pp. 1135–1148,2016.[62] Y. Sun, A. T. Ernst, X. Li, and J. Weiner, “Learning to generate columnswith application to vertex coloring,” in The Eleventh InternationalConference on Learning Representations, 2022.[63] B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, and N. De Freitas,“Taking the human out of the loop: A review of bayesian optimization,”Proceedings of the IEEE, vol. 104, no. 1, pp. 148–175, 2015.[64] Q. Zhang, W. Liu, E. Tsang, and B. Virginas, “Expensive multiobjectiveoptimization by MOEA/D with gaussian process model,” IEEE Transac-tions on Evolutionary Computation, vol. 14, no. 3, pp. 456–474, 2009.[65] Y. Jin, H. Wang, T. Chugh, D. Guo, and K. Miettinen, “Data-drivenevolutionary optimization: An overview and case studies,” IEEE Trans-actions on Evolutionary Computation, vol. 23, no. 3, pp. 442–458, 2018.[66] Z. Song, H. Wang, C. He, and Y. Jin, “A kriging-assisted two-archiveevolutionary algorithm for expensive many-objective optimization,”IEEE Transactions on Evolutionary Computation, vol. 25, no. 6, pp.1013–1027, 2021.[67] H. Hao, A. Zhou, H. Qian, and H. Zhang, “Expensive multiobjectiveoptimization by relation learning and prediction,” IEEE Transactions onEvolutionary Computation, vol. 26, no. 5, pp. 1157–1170, 2022.[68] Y. Mei, Q. Chen, A. Lensen, B. Xue, and M. Zhang, “Explainable artifi-cial intelligence by genetic programming: A survey,” IEEE Transactionson Evolutionary Computation, 2022.[69] Y.-H. Jia, Y. Mei, and M. Zhang, “Learning heuristics with different rep-resentations for stochastic routing,” IEEE Transactions on Cybernetics,2022.[70] P.-F. Guo, Y.-H. Chen, Y.-D. Tsai, and S.-D. Lin, “Towards optimizingwith large language models,” arXiv preprint arXiv:2310.05204, 2023.[71] A. E. Brownlee, J. Callan, K. Even-Mendoza, A. Geiger, C. Hanna,J. Petke, F. Sarro, and D. Sobania, “Enhancing genetic improvement mu-tations using large language models,” arXiv preprint arXiv:2310.19813,2023.[72] S. Liu, C. Chen, X. Qu, K. Tang, and Y.-S. Ong, “Large language modelsas evolutionary optimizers,” arXiv preprint arXiv:2310.19046, 2023.[73] M. U. Nasir, S. Earle, J. Togelius, S. James, and C. Cleghorn, “Llmatic:Neural architecture search via large language models and quality-diversity optimization,” arXiv preprint arXiv:2306.01102, 2023.[74] G. Jawahar, M. Abdul-Mageed, L. V. Lakshmanan, and D. Ding, “Llmperformance predictors are good initializers for architecture search,”arXiv preprint arXiv:2310.16712, 2023.[75] J. Lehman, J. Gordon, S. Jain, K. Ndousse, C. Yeh, and K. O.Stanley, “Evolution through large models,” in Handbook of EvolutionaryMachine Learning. Springer, 2023, pp. 331–366.[76] G. Reinelt, The traveling salesman: computational solutions for TSPapplications. Springer, 2003, vol. 840.[77] Y.-D. Kwon, J. Choo, B. Kim, I. Yoon, Y. Gwon, and S. Min,“Pomo: Policy optimization with multiple optima for reinforcementlearning,” Advances in Neural Information Processing Systems, vol. 33,pp. 21 188–21 198, 2020.[78] X. Pan, Y. Jin, Y. Ding, M. Feng, L. Zhao, L. Song, and J. Bian, “H-tsp: Hierarchically solving the large-scale travelling salesman problem,”arXiv preprint arXiv:2304.09395, 2023.[79] H. Cheng, H. Zheng, Y. Cong, W. Jiang, and S. Pu, “Select and optimize:Learning to aolve large-scale tsp instances,” in International Conferenceon Artificial Intelligence and Statistics. PMLR, 2023, pp. 1219–1231.[80] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Ka-mar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg et al., “Sparks of artificialgeneral intelligence: Early experiments with gpt-4,” arXiv preprintarXiv:2303.12712, 2023.[81] W. J. Cook, D. L. Applegate, R. E. Bixby, and V. Chvatal, The travelingsalesman problem: a computational study. Princeton university press,2011.[82] G. Mialon, R. Dessı̀, M. Lomeli, C. Nalmpantis, R. Pasunuru,R. Raileanu, B. Rozière, T. Schick, J. Dwivedi-Yu, A. Celikyil-maz et al., “Augmented language models: a survey,” arXiv preprintarXiv:2302.07842, 2023.[83] T. Schick, J. Dwivedi-Yu, R. Dessı̀, R. Raileanu, M. Lomeli, L. Zettle-moyer, N. Cancedda, and T. Scialom, “Toolformer: Language modelscan teach themselves to use tools,” arXiv preprint arXiv:2302.04761,2023.[84] B. Paranjape, S. Lundberg, S. Singh, H. Hajishirzi, L. Zettlemoyer, andM. T. Ribeiro, “Art: Automatic multi-step reasoning and tool-use forlarge language models,” arXiv preprint arXiv:2303.09014, 2023.[85] B. Hudson, Q. Li, M. Malencia, and A. Prorok, “Graph neural net-work guided local search for the traveling salesperson problem,” arXivpreprint arXiv:2110.05291, 2021.[86] A. Hottung and K. Tierney, “Neural large neighborhood search for thecapacitated vehicle routing problem,” arXiv preprint arXiv:1911.09539,2019.[87] N. T. Nguyen and K. Lee, “Deep learning-aided tabu search detection forlarge mimo systems,” IEEE Transactions on Wireless Communications,vol. 19, no. 6, pp. 4262–4275, 2020.[88] S. Jiang, J. Zou, S. Yang, and X. Yao, “Evolutionary dynamic multi-objective optimisation: A survey,” ACM Computing Surveys, vol. 55,no. 4, pp. 1–47, 2022.[89] H. Ishibuchi, L. M. Pang, and K. Shang, “A new framework of evolu-tionary multi-objective algorithms with an unbounded external archive,”Authorea Preprints, 2023.[90] T. Khot, H. Trivedi, M. Finlayson, Y. Fu, K. Richardson, P. Clark,and A. Sabharwal, “Decomposed prompting: A modular approach forsolving complex tasks,” arXiv preprint arXiv:2210.02406, 2022.[91] X. Chen, M. Lin, N. Schärli, and D. Zhou, “Teaching large languagemodels to self-debug,” arXiv preprint arXiv:2304.05128, 2023.[92] O. Press, M. Zhang, S. Min, L. Schmidt, N. A. Smith, and M. Lewis,“Measuring and narrowing the compositionality gap in language mod-els,” arXiv preprint arXiv:2210.03350, 2022.[93] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdh-ery, and D. Zhou, “Self-consistency improves chain of thought reasoningin language models,” arXiv preprint arXiv:2203.11171, 2022.[94] A. Zhou, B.-Y. Qu, H. Li, S.-Z. Zhao, P. N. Suganthan, and Q. Zhang,“Multiobjective evolutionary algorithms: A survey of the state of theart,” Swarm and evolutionary computation, vol. 1, no. 1, pp. 32–49,2011.",
    "Link": "http://arxiv.org/abs/2311.15249"
}