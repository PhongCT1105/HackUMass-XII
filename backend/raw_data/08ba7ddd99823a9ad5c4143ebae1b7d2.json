{
    "Title": "Large Language Model Distilling Medication Recommendation Model",
    "Authors": "Liu, Qidong, Tian, Feng, Wu, Xian, Zhang, Zijian, Zhao, Xiangyu, Zheng, Yefeng, Zhu, Yuanshao",
    "Year": "No year available",
    "Abstract": "The recommendation of medication is a vital aspect of intelligent healthcare\nsystems, as it involves prescribing the most suitable drugs based on a\npatient's specific health needs. Unfortunately, many sophisticated models\ncurrently in use tend to overlook the nuanced semantics of medical data, while\nonly relying heavily on identities. Furthermore, these models face significant\nchallenges in handling cases involving patients who are visiting the hospital\nfor the first time, as they lack prior prescription histories to draw upon. To\ntackle these issues, we harness the powerful semantic comprehension and\ninput-agnostic characteristics of Large Language Models (LLMs). Our research\naims to transform existing medication recommendation methodologies using LLMs.\nIn this paper, we introduce a novel approach called Large Language Model\nDistilling Medication Recommendation (LEADER). We begin by creating appropriate\nprompt templates that enable LLMs to suggest medications effectively. However,\nthe straightforward integration of LLMs into recommender systems leads to an\nout-of-corpus issue specific to drugs. We handle it by adapting the LLMs with a\nnovel output layer and a refined tuning loss function. Although LLM-based\nmodels exhibit remarkable capabilities, they are plagued by high computational\ncosts during inference, which is impractical for the healthcare sector. To\nmitigate this, we have developed a feature-level knowledge distillation\ntechnique, which transfers the LLM's proficiency to a more compact model.\nExtensive experiments conducted on two real-world datasets, MIMIC-III and\nMIMIC-IV, demonstrate that our proposed model not only delivers effective\nresults but also is efficient. To ease the reproducibility of our experiments,\nwe release the implementation code online",
    "Keywords": "No keywords available",
    "Publisher": "",
    "Publication Date": "No publication date available",
    "Journal": "No journal available",
    "Citation Count": 0,
    "Full Text": "Large Language Model Distilling MedicationRecommendation ModelQidong LiuXi’an Jiaotong UniversityCity University of Hong KongXi’an, Chinaliuqidong@stu.xjtu.edu.cnXian Wu BJarvis Research Center, Tencent YouTu LabShenzhen, Chinakevinxwu@tencent.comXiangyu Zhao BCity University of Hong KongHong Kong, Chinaxianzhao@cityu.edu.hkYuanshao ZhuSouthern University of Science and TechnologyCity University of Hong KongShenzhen, Chinazhuys2019@mail.sustech.edu.cnFeng Tian BXia’an Jiaotong UniversityXi’an, Chinafengtian@mail.xjtu.edu.cnZijian ZhangJilin UniversityCity University of Hong KongChangchun, Chinazhangzj2114@mails.jlu.edu.cnYefeng ZhengJarvis Research Center, Tencent YouTu LabShenzhen, Chinayefengzheng@tencent.comAbstract—The recommendation of medication is a vital aspectof intelligent healthcare systems, as it involves prescribing themost suitable drugs based on a patient’s specific health needs.Unfortunately, many sophisticated models currently in use tendto overlook the nuanced semantics of medical data, while onlyrelying heavily on identities. Furthermore, these models facesignificant challenges in handling cases involving patients whoare visiting the hospital for the first time, as they lack priorprescription histories to draw upon. To tackle these issues,we harness the powerful semantic comprehension and input-agnostic characteristics of Large Language Models (LLMs). Ourresearch aims to transform existing medication recommendationmethodologies using LLMs. In this paper, we introduce a novelapproach called LargE languAge moDel distilling mEdicationRecommendation (LEADER). We begin by creating appropriateprompt templates that enable LLMs to suggest medicationseffectively. However, the straightforward integration of LLMsinto recommender systems leads to an out-of-corpus issue specificto drugs. We handle it by adapting the LLMs with a novel outputlayer and a refined tuning loss function. Although LLM-basedmodels exhibit remarkable capabilities, they are plagued by highcomputational costs during inference, which is impractical for thehealthcare sector. To mitigate this, we have developed a feature-level knowledge distillation technique, which transfers the LLM’sproficiency to a more compact model. Extensive experimentsconducted on two real-world datasets, MIMIC-III and MIMIC-IV, demonstrate that our proposed model not only deliverseffective results but also is efficient. To ease the reproducibilityof our experiments, we release the implementation code online 1.Index Terms—Medication Recommendation; Large LanguageModel; Knowledge Distillation;B Corresponding Authors1https://github.com/liuqidong07/LEADER-pytorchTABLE I: The investigation of current medication recommen-dation models. “ ” means the type of input necessary orability for inference. “#” means no such type of input orinability for inference. “H#” means the type of input alternative.Model Input InferenceDiagnosis Procedure Medication Single-visit Multi-visitRETAIN [1]   #   G-Bert [2]  #  #  GAMENet [3]   H#   SafeDrug [4]   #   MICRON [5]    #  COGNet [6]    #  REFINE [7]    #  LEADER (Ours)      I. INTRODUCTIONPrescription, as a crucial aspect of patient treatment, islabor-intensive and requires specialized expertise [8]. Auto-mated medication recommender systems offer potential relieffor overburdened healthcare professionals, by providing deci-sion support [9]. Contemporary medication recommendationmodels primarily focus on generating drug recommendationsbased on patients’ diagnostic and procedural data. Whilesignificant advancements have been achieved, two primarychallenges persist: (i) Lack of Semantic Understanding: Ex-isting models [1]–[4] predominantly capture the collaborativeinformation among medications, diagnoses, and procedures bytheir identity data. However, the importance of semantic un-derstanding, especially in medical contexts [10], is frequentlyoverlooked in medication recommendation. (ii) Challengeswith Single-Visit Patients: Prescription history is a criticalarXiv:2402.02803v1  [cs.IR]  5 Feb 2024factor in current prescription practices, as indicated by recentstudies [5]–[7]. As shown in Table I, models like MICRON [5],COGNet [6] and REFINE [7] incorporate historical medicationrecords as their input for enhanced performance. However,this reliance on historical data poses a significant challenge inrecommending for first-time hospital visitors, termed single-visit patients. Excluding single-visit patients is unacceptablein real-world healthcare systems, indicating a crucial area forimprovement.The advent of large language models [11] presents anopportunity to enhance existing medication recommender sys-tems. On the one hand, extensive studies have confirmedthe robust semantic understanding capabilities of large lan-guage models [12]. This enables the refinement of medicationrecommendations from a medical semantics perspective. Onthe other hand, LLMs process natural language as input,making them inherently agnostic to the types and numberof input variables [13]. Consequently, unlike some existingmedication recommendation models, LLM-based medicationrecommenders can incorporate any conceivable variables, in-cluding patients’ profiles and historical prescriptions, into themodel. This flexibility allows them to cater to all patients,irrespective of whether a patient has a documented medicalhistory. Addressing the two challenges mentioned before,the application of large language models to the medicationrecommendation task emerges as a compelling and attractivesolution.Several pioneering works [14], [15] have taken the initialsteps to integrate large language models with recommendersystems. However, their direct application to the medicationrecommendation task is hindered by two significant prob-lems: (i) Out-of-corpus Problem. Numerous studies [16]–[18] have explored the creation of input prompts to engageLLMs. Nevertheless, the incompatibility between the naturallanguage output and the required in-corpus drugs persists.This challenge may result in recommendations from LLM-based recommender systems that are not part of the drugset, potentially compromising recommendation performance.For instance, an LLM might generate a medication name thatcannot be verified in the drug bank, leading to a failed recom-mendation. (ii) High Inference Cost Problem. LLMs oftensuffer from high inference latency and memory issues [19],given their billions of parameters. While general applicationscan leverage cloud computing to meet real-time requirementsfor LLM-based services, the deployment of medical serviceswithin healthcare institutions, such as hospitals, is commondue to privacy concerns [20]. Besides, equipping each medicalcenter with a high-performance computing platform poses alogistical challenge. Therefore, a more efficient solution forLLM-based medication recommendation is imperative.To address the aforementioned challenges, we intro-duce the LargE LAnguage MoDel Enhanced MedicationRecommendation by Distillation (LEADER). In our approach,to adapting LLMs for medication recommendation, we firstdevelop appropriate prompt templates to activate the LLM’ssemantic understanding ability. Specifically, for the out-of-TABLE II: Notions used in LEADER. “med.”, “diag.” and“proc.” are the abbreviations of medication, diagnosis andprocedure.Notation DescriptionX (z) The EHR records of the patient zP(z) The lingual prompt of patient’s EHR recordP The profile features of one patientTz The number of hospital visits for patient zMi, Di, Pi The set of med., diag., and proc. codesEm, Ed, Ep Embedding matrices for med., diag. and proc. codesEDiag , EProc, EMed The encoder for med., diag. and proc. setsEp The profile feature encoderEV isit The medical record visit encoderh The hidden state from last transformer layer of LLMWCLS The classification output layer for LLMWproj The linear projection layer for distillationŷ The predicted probability for each med.y Labels of recommended med.corpus issue, we enhance the LLM by introducing a newoutput layer with a corresponding training loss. Followingsupervised fine-tuning, the LLM gains the capability for medi-cation recommendation and exhibits exceptional performance.However, the application of the LLM-based model is hinderedby high inference costs. To address this issue, we delve intotransferring the formidable capabilities of the LLM to a smallmodel. In detail, a feature-level distillation method is devisedto augment the small medication recommendation model basedon the adapted LLM. The contributions of this paper are asfollows:• We validate the robust capability of LLMs for the med-ication recommendation task through the modification ofthe output layer and fine-tuning loss specific to LLMs.To the best of our knowledge, we are the first to explorethe integration of medication recommendation and largelanguage models.• We introduce a feature-level knowledge distillation methodto enhance the small model using LLMs, resulting in ahighly efficient and effective medication recommendationmodel.• Extensive experiments are conducted on two public datasets,namely MIMIC-III and MIMIC-IV. The experimental resultsconsistently demonstrate that the proposed LEADER modeloutperforms current baselines.II. PRELIMINARYElectronic Health Records (EHR) is one essence of anintelligent healthcare system, which collects patients’ detailedand procedural medical data. In EHR, the patient’s data canbe handled by their hospital visits. Assume, there are Npatients in the database, then the records of the patient z arerepresented as X (z) = [X (z)1 , ...,X(z)i , ...,X(z)Tz], where Tz isvisit number of this patient. For simplicity, the patient stamp(z) is omitted in the following. Since diagnosis and proceduresare vital for prescription in the real world [3], [4], these twoelements with medications are included in each visit record.In the visit i, the record is denoted as Xi = {Mi,Di,Pi}....LoRA        Large Language ModelPrompt: The patient has 2 times ICU visits. In the1 visit, the patient had diagnosis: Aortic valvedisorder, ...; procedures: refus 4-8 vertevrace, ....;The patients was prescribed drugs: calcium, .... Inthis visit, he has diagnosis: Aortic valve disorder,...procedures: extracorporeal circulat.... Then, thepatient should be prescribed:  Linear & SigmoidTeacher Student... ...LinearLinear.........Fig. 1: The framework overview of the proposed LEADER, which consists of two training stages. The first stage is to supervisedfine-tune the Teacher medication recommendation model, i.e., large language model. In the second stage, we train the designedStudent medication recommendation by knowledge distillation. For high efficiency, only the student model is used for inference.A patient may take several drugs and get multiple diagnosesand procedures, so let Mi = {m1, ...,mj , ...,m|M|}, Di ={d1, ..., dj , ..., d|D|}, Pi = {p1, ..., pj , ..., p|P|} denote the setof medication, diagnosis and procedure, respectively. |M|,|D| and |P| represent the totals of them. Some demographiccharacteristics of patients, such as age, gender, etc., are alsovital, which are marked as P . We list out the importantnotations of this paper in Table II.Medication recommendation aims to give out the propermedication set MT given all possible medical data of thispatient. As mentioned before, many existing methods adoptthe patient’s historical prescriptions for a more accurate rec-ommendation, which requires the patient to have multiplevisits, i.e., T > 1. However, they cannot handle the single-visit patient with T = 1. In this paper, we explore to derivethe model for both types of patients. Therefore, we definethe problem respectively. For single-visit patients, recommendMT given {DT ,PT , P}. For multi-visit patients, give outMT based on {X1, ...,XT−1,DT ,PT , P}.III. METHODIn this section, the details of the proposed LEADER areintroduced. At first, we will present the overview in Sec-tion III-A. Then, the modification of the LLM for med-ication recommendation is illustrated in Section III-B. InSection III-C, we will illustrate the distillation method fortransferring the powerful semantic understanding ability of theLLM to a small model. At last, the procedures of optimizationand inference are detailed in Section III-D.A. OverviewThe overview of the proposed LEADER is shown in Fig-ure 1. To utilize the LLM, we design the prompt template toformat the electronic health record of the patient into naturallanguage. Then, the output and fine-tuning loss function aremodified to better fit the medication recommendation task,which can be considered as a multi-class classification prob-lem. Though the LLMs have been proven to have brilliantability [21]–[23] recently, they face the problem of highinference cost, which is hardly accepted by the healthcaresystem. Thus, we explore transferring the powerful abilityfrom LLM to the designed small model by the proposedknowledge distillation method. In the diagram, the LLM-basedmodel and small model are represented as “Teacher” and“Student”, respectively. We will train the student model fromscratch with the ground-truth label and knowledge distillationloss from the well-fine-tuned teacher model.B. LLM for Medication RecommendationThe input and output of the large language model are bothnatural languages, while they are non-semantic identities inconventional medication recommendation models [3], [4], [6],such as “Medication ID: 2”. Thus, to apply the LLMs tomedication recommendation, we have to fill such a gap. On theone hand, we design the proper prompt templates to formatthe electronic health records into natural language, whichcan be input to LLMs directly. On the other hand, lingualoutput for recommendation by LLMs faces the out-of-corpuschallenge [17], [24], so we substitute the original languagehead with a classification output layer. Correspondingly, theobjective for fine-tuning LLMs is modified. Next, we willdetail the prompt templates and output layer in the followingparts.1) Prompt Templates: We design the prompt template Tto derive the lingual representation P(z) of the patient’s EHR,which can instruct the LLM to understand the health conditionof the patient. The devised template is as follows:Input Prompt TemplateThe patient has <VISIT NUM> times ICU visits.In the 1 visit, the patient had diagnosis:<DIAG NAME>, ..., <DIAG NAME>; procedures:<PROC NAME>, ..., <PROC NAME>; Thepatient was prescribed drugs: <MED NAME>, ...,<MED NAME>. In the 2 visit, ....In this visit, the patient has diagnosis:<DIAG NAME>, ..., <DIAG NAME>; procedures:<PROC NAME>, ..., <PROC NAME>. Then, thepatient should be prescribed:In the template, the places underlined will be filled in withEHR data. “<VISIT NUM>” is the number of hospital visitsfor one patient. The part in blue represents the historicalrecords {X1, ...,XT−1} of the patient. However, we haveargued that the patients who first visit the hospital are eitherimportant. For these single-visit patients, they do not havethis part in the prompt. Besides, the diagnosis, procedure andmedication are represented by their name to utilize the seman-tic understanding ability of LLMs. Thus, “<DIAG NAME>”,“<PROC NAME>” and “<MED NAME>” are all standardmedical terms in the prompt. After the prompt construction,the LLMs can conduct an understanding for medication rec-ommendation from the lingual input.2) Output Layer: Most existing LLM-based recommendersystems [25], [26] output the name or identity of the rec-ommendations in natural language but face the out-of-corpuschallenge. To tackle this problem, we substitute the pre-trainedword token generation layer with a linear layer accompaniedby a sigmoid. Then, the outputs from the modified LLM arethe probability of every medication.ŷ = σ(WCLS · h) (1)where ŷ ∈ R|M|×1 and h ∈ Rdh×1 are the predictedprobability of medication and the hidden states from the lasttransformer layer in LLMs. WCLS ∈ R|M|×dh is a learnableweight matrix and σ(·) represents the sigmoid function. Forthe final recommendation, a threshold γ will be set. Whenyk > γ, the medication k will be included in the prescribedmedication set.3) Optimization: Since we renew the output layer ofthe LLM, supervised fine-tuning (SFT) is necessary. At thesame time, SFT can benefit the LLMs to complete specifictasks [10], [27]. However, the conditional language modelingobjective [21], [22] is unsuitable for the modified LLM,because the output layer is for classification. To better fitthe medication recommendation task and the output layer, wemodify the loss function of SFT as follows:LSFT = −N∑i=1y(i)log(ŷ(i)) + (1− y(i))log(1− ŷ(i)) (2)In the equation, y is the ground-truth medication labels. Itis worth noting that fine-tuning all parameters of the LLMis extremely costly. Therefore, we adopt LoRA [28] fine-tuning in this paper, which only updates sets of low-rankmatrices while freezing the pre-tained weights of the LLM.Let {Ai,Bi}Li=1 denotes the sets of trainable matrices, whereL is the number of layers accompanied by LoRA layer. Then,during the SFT, only the parameters WCLS and {Ai,Bi}Li=1are trainable and initialized by normal distribution.C. Enhancement by DistillationThough the LLMs possess powerful semantic understandingabilities, they require high inference memory and latency.It is unacceptable to the healthcare system, so we aim totransfer the abilities of LLMs to a relatively small model. Theknowledge distillation [29] is a promising way, but the studentmodel architecture and specific distillation method still needto be addressed.1) Student Model Design: Considering the efficiency issue,the identities, instead of the semantic terms, are adopted in thestudent model. As mentioned in Section II, the input variablescan be written as {D1, ...,DT ;P1, ...,PT ;M1, ...,MT−1;P},where D, P and M are sets of diagnosis, procedure andmedications.To capture collaborative information from each type of set,we design three homogeneous encoders for them, denoted asEDiag, EProc and EMed, respectively. For brevity, we only takethe EDiag for illustration. We first derive an embedding tableEd ∈ R|D|×de , where each row refers to the unique code ofdiagnosis. de represents the dimension of the embedding table.Then, the set of diagnosis codes Di are transformed into aset of vectors by Ed, denoted as D̄i = [d1, ...,d|Di|]. Next,we propose to adopt a transformer architecture to encode theinter-relationship contained in each set. The pair of multi-headattention and feed-forward networks consist of one transformerlayer, which can be written as:M = LayerNorm(D̄i,MultiHead(D̄i, D̄i, D̄i)) (3)where LayerNorm(·) and MultiHead(·) represents the layernormalization and multi-head attention, respectively. The othercomponent of the transformer layer is the feed-forward net-work accompanied by a residual connection, which can beformulated as follows:D̂(1) = LayerNorm(M,FNN(M)) (4)where FNN(·) is one trainable linear layer. The output ofthe first transformer layer is denoted as D̂(1), which is asequence of vectors. Then, we impose the average poolingto the output from the last transformer layer of EDiag and getthe representation of the diagnosis set, i.e., Di ∈ Rdt .Di = Avg pool(D̂(Ld)) (5)where Ld denotes the number of transformer layer inEDiag. By the diagnosis encoder, the input diagnosisrecords {D1, ...,DT } are converted to a set of vectors, i.e.,[D1, ...,DT ]. Similarly, we can get the representation ofprocedure and medication sets by EProc and EMed with thesame structure as EDiag.Then, we devise a visit encoder EV isit to capture thehistorical health conditions of the patients. In specific, EV isitis also stacked by several transformer layers, which is thesame as EDiag. Thus, EV isit will encode the sequence ofdiagnosis records into one embedding D̃, which can be writtenas follows:D̃ = EV isit([D1, ...,DT ]) (6)In the same way, we can get the representation of historicalprocedure and medication records, denoted as P̃ and M̃. Itis worth noting that the three types of records share the visitencoder EV isit, because such a design can not only shrink thenumber of parameters but also help learn the shared medicalknowledge [2].Another challenge for the student model is the difficulty forsingle-visit patients because the input of medication recordsto EV isit is empty when T = 1. Here, we propose using theprofile information as a pseudo medication record since theprofile can reflect the patient’s health condition. In detail, theprofile feature, such as age, is discretized and then encoded byembedding matrices. All representations of profile features areconcatenated and then projected to an dt dimensional vector,marked as P. The profile vector will be inserted into thesequence of medication records, so the medication input toEV isit are changed to [M1, ...,MT−1,P].Finally, we concatenate the D̃, P̃ and M̃, and adopt twolinear layers for final medication recommendation.ŷ = σ(W2(W1 · [D̃||P̃||M̃] + b1) + b2) (7)where W1 ∈ R3dt×dt , W2 ∈ Rdt×|M|, b2 ∈ R1×dt andb2 ∈ R1×|M| are trainable parameters. Then, the loss functionfor the ground-truth label is written as:Lbce = −N∑i=1y(i)log(ŷ(i)) + (1− y(i))log(1− ŷ(i)) (8)2) Knowledge Distillation: In order to transfer the powerfulability of the LLM-based model to the student model, wepropose a feature-level knowledge distillation. Since LLMsare skilled in memorizing [30], [31], they can predict thesamples in the training set with relatively high accuracy. Thiswill cause the prediction of the training set from LLMs tobe similar to the ground-truth label, which is not suitable fordistillation. Therefore, we propose to distill the student modelby the hidden state from LLMs.The hidden state h is the representation from the lasttransformer layer of LLMs. In the conventional pre-trainedLLMs, this hidden state is used to generate the word tokenvia a linear layer, so it contains comprehensive semanticinformation. In the modified LLMs, since h can output theprobabilities of medications accompanied by a classificationlayer, it is also suitable to guide the student model consideringthe task similarity.However, the representation in the student model is still ina different space of h, because there is no semantic input tothe student model. Therefore, we design a trainable projectorto transform the hidden state into the representation space ofLLM. Then, the loss for knowledge distillation can be writtenas:LKD =1NN∑i=1| hi−Wproj ·(W1·[D̃i||P̃i||M̃i]+b1) |2 (9)where Wproj ∈ Rdt×dh is weight of projection layer. Notethat all the parameters of the student model and Wproj areupdated during the distillation, while the parameters of LLMare frozen.3) Profile Alignment: Due to the design of the profilefeatures as a pseudo medication record, our model can recom-mend for single-visit patients. However, the representations ofthe profile and medication set are actually in different spaces,which causes difficulty in training. As a result, to align thetwo different types of representations, we design a profilealignment method.Inspired by the contrastive learning for modality alignmentin multimodal research [32], [33], we propose a contrastiveloss to align profile and medication sets. For better perfor-mance [34], we first project the representation of profile Pand the target medication set MT to a new space:ZP = WPproj ·PZM = WMproj ·MT(10)where WPproj ∈ Rdt×dt and WMproj ∈ Rdt×dt are theprojection matrices. Let [Z1P , ...,ZBP ] and [Z1M , ...,ZBM ] denoteone batch of profile and medication representations, where Bis the batch size. We consider ZiP and ZjM as a positive pair,when i = j. Then, the contrastive loss for the profile can bedefined as:LPM = −1BB∑i=1logexp(sim(ZiP ,ZiM )/τ)∑Bj=1 I[i̸=j] exp(sim(ZiP ,ZjM )/τ)(11)where I[i ̸=j] represents an indicator function. τ denotes thetemperature parameter in the loss. In the same way, we canalso derive the contrastive loss LMP for medication. Thus, thealignment loss is the sum of these two losses:Lalign =∑NLPM + LMP (12)D. Train and InferenceThe proposed LEADER needs two-stage optimization. Inthe first stage, we need to optimize the modified LLM byEquation (2). The fine-tuned LLM will act as the teacherAlgorithm 1 Train and Inference Process of LEADER1: Indicate the prompt template T .2: Construct the lingual input P according to X .3: Indicate the hyper-parameters α, β and τ .Train Stage 14: Substitute the language generation head with theclassification head. Freeze all the pre-trained parametersΘLLM of the LLM.5: for a batch of samples Bp in P do6: Input Bp to the LLM and get the hidden state h.7: Output the probability of each medication byEquation (1).8: Fine-tune WCLS and {Ai,Bi}Li=1 by Equation (2).9: end for10: Get the teacher model LEADER(T).Train Stage 211: for a batch of samples Bp, Bx in P , X do12: Input Bx to student model and get the BCE loss byEquation (8).13: Input Bp to LEADER(T) to get the hidden state h,and calculate the loss for distillation by Equation (9).14: Update the parameters of the student model Θstuand Wproj by the Equation (13).15: end for16: Get the student model LEADER(S).Inference17: Transform the patient’s EHR X (z) to P(z) by T .18: Input X (z) to LEADER(S) and get the recommendation.19: Input P(z) to LEADER(T) and get the recommendation.model, dubbed LEADER(T). In the second stage, the studentmodel denoted as LEADER(S), is trained from scratch by thecombination of loss from the ground-truth label, knowledgedistillation and profile alignment, i.e.,L = Lbce + α · LKD + β · Lalign (13)where α and β are the hyper-parameters to adjust the scaleof distillation and alignment. After the optimization, bothLEADER(T) and LEADER(S) can complete the medicationrecommendation task, but have distinct input formats. To showthe process of training and inference more clearly, we concludethe Algorithm 1.Firstly, we indicate some necessary hyper-parameters andconstruct the natural language input for LLM (line 1-3).Then, at the first stage, the modified LLM is supervised fine-tuned by the derived lingual dataset (line 4-10). The fine-tuned modified LLM can be used for both distillation ormedication recommendation directly. At the second trainingstage, the EHR formatted in natural language and identityare absorbed by the teacher and student model, respectively(line 11-13). Then, we update the student model by thecombination of BCE, distillation and alignment loss (line 14-16). In terms of inference, we can either adopt the LEADER(S)or LEADER(T) for the final recommendation (line 17-19).TABLE III: The statistics of the preprocessed datasetsItem MIMIC-III MIMIC-IV# of single-visit patients 908 2,877# of multi-visit patients 5,442 6,029diag. / proc. / med. space size 1,958 / 1,430 / 112 1,998 / 1,001 / 125avg. / max of diag. per visit 10.51 / 128 8.41 / 220avg. / max of proc. per visit 3.84 / 50 2.11 / 49avg. / max of med. per visit 11.64 / 64 7.02 / 72IV. EXPERIMENTIn this section, we will analyze the proposed LEADER bycomprehensive experiments on two real-world datasets. Weexplore the following Research Questions (RQ) to illustratethe findings:• RQ1: How the proposed LEADER perform compared withcurrent state-of-the-art medication recommendation models?• RQ2: Do all designs for LEADER take effect?• RQ3: How do the designed knowledge distillation andprofile alignment affect the performance of LEADER?• RQ4: Can the proposed student model conduct medicationrecommendation with a high efficiency?A. Experimental Settings1) Dataset: The datasets used in the experiments are fromMedical Information Mart for Intensive Care (MIMIC) 2.There are two versions available currently, i.e., MIMIC-IIIand MIMIC-IV. MIMIC-III collects data from 2001 to 2012,while MIMIC-IV contains records from 2008 to 2019. For thepreprocessing, we transform the NDC code of the medicationsto ATC level codes to get the drug-drug interaction (DDI)graph and molecule connection graph for the implementationof the baselines. Besides, we only retain the prescriptionsduring the first 24 hours of a visit, as previous works [3],[4] did. We filter out the medications that cannot be mappedto ATC codes and the visits that have void input set. At last,we split the data into train/validation/test by the ratio of 8:1:1.The statistics of the preprocessed data are shown in Table III.2) Baselines: In the experiments, we compare ourLEADER with several state-of-the-art medication recommen-dation models:• RETAIN [1]. RETAIN designs a two-level attention modelto enhance the accuracy and interpretability of clinicalvariable prediction. We implement it by adding the repre-sentation of diagnosis and procedure for each visit.• G-Bert [2]. G-Bert utilizes all the data to pre-train diagnosisand medication encoders, but needs historical medicationrecords in fine-tuning stage.• GAMENet [3]. GAMENet adopts the memory bank tointegrate global medication interaction and drug-drug in-teraction knowledge. For the implementation, we substitutethe retrieval representation from patient history with the onefrom patient similarity for those single-visit patients.• SafeDrug [4]. SafeDrug utilizes drug molecule structure toencode the medications and add direct drug-drug interactioncontrol during the training process.2https://mimic.mit.edu/TABLE IV: The overall results of competing baselines and LEADER on MIMIC-III. The boldface refers to the highest scoreand the underline indicates the best result of the models. “*” indicates the statistically significant improvements (i.e., two-sided t-test with p < 0.05) over the best baseline. “-” represents the model cannot acquire the corresponding results due to theinability to the single-visit patients.Model Overall Multi-visit Single-visitPRAUC Jaccard F1 PRAUC Jaccard F1 PRAUC Jaccard F1RETAIN 0.7513 ± 0.0025 0.4943 ± 0.0023 0.6516 ± 0.0022 0.7580 ± 0.0020 0.5106 ± 0.0023 0.6674 ± 0.0022 0.7337 ± 0.0067 0.4811 ± 0.0053 0.6403 ± 0.0049G-Bert - - - 0.6904 ± 0.0017 0.4578 ± 0.0019 0.6186 ± 0.0018 - - -GAMENet 0.7605 ± 0.0011 0.5024 ± 0.0010 0.6595 ± 0.0008 0.7638 ± 0.0023 0.5070 ± 0.0028 0.6635 ± 0.0025 0.7451 ± 0.0053 0.4840 ± 0.0038 0.6442 ± 0.0036SafeDrug 0.7582 ± 0.0020 0.5054 ± 0.0024 0.6621 ± 0.0021 0.7623 ± 0.0029 0.5095 ± 0.0027 0.6658 ± 0.0024 0.7416 ± 0.0044 0.4900 ± 0.0043 0.6481 ± 0.0042MICRON - - - 0.7651 ± 0.0027 0.5110 ± 0.0025 0.6741 ± 0.0023 - - -COGNet - - - 0.7771 ± 0.0019 0.5275 ± 0.0021 0.6805 ± 0.0019 - - -REFINE - - - 0.7791 ± 0.0017 0.5235 ± 0.0018 0.6794 ± 0.0017 - - -LEADER(T) 0.7816 ± 0.0015* 0.5391 ± 0.0015* 0.6921 ± 0.0014* 0.7854 ± 0.0015* 0.5450 ± 0.0021* 0.6971 ± 0.0018* 0.7590 ± 0.0046* 0.5090 ± 0.0044* 0.6668 ± 0.0041*LEADER(S) 0.7795 ± 0.0025* 0.5175 ± 0.0022* 0.6737 ± 0.0019* 0.7830 ± 0.0019 0.5208 ± 0.0020 0.6768 ± 0.0017 0.7631 ± 0.0056* 0.5038 ± 0.0062* 0.6614 ± 0.0057*• MICRON [5]. MICRON finds that there is little distinctionbetween the prescription in two successive visits and thuscaptures the change for the final recommendation. For theinput, the medication set taken on the last visit is compul-sory.• COGNet [6]. COGNet copies the ever-prescribed drugs tothe current visit, so the previous medication records arenecessary.• REFINE [7]. REFINE proposes to model the severity ofthe drug-drug interaction and the fine-grained medicationdosage. For a fair comparison, we implement it by inputtingthe diagnosis rather than lab test responses to the model.Since REFINE also takes the historical medication recordsas input, it cannot infer for single-visit patients.To verify the ability of the LLM for medication recommenda-tion, we compare the modified LLM proposed in Section III-B,which is denoted as LEADER(T). Also, the distilled studentmodel is marked as LEADER(S) in the following experi-ments.3) Implementation Details: All experiments in this pa-per are conducted on the Intel Xeon Gold 6133 platformwith Tesla V100 32G GPUs. The code is based on Python3.6.5 and PyTorch 1.12.0. As for the LLM-based medicationrecommendation, i.e., LEADER(T), we adopt the LlaMA-7B 3 [22] as the foundation model in this paper. Duringthe fine-tuning, the LoRA layers are accompanied by thelayers identified as “q proj”, “k proj”, “v proj”, “o proj”,“down proj”, “up proj” and “gate proj” in LLM. Other con-figurations include LoRA rank of 8, batch size of 32, learningrate of 2e − 4 and maximum input length of 2, 048. Due todifferent data scales, the maximum training steps are set to3,000 and 4,000 for MIMIC-III and MIMIC-IV, respectively.In terms of the distillation for the student model LEADER(S),we set the dimension de and dt to 64, the number of trans-former layers of all encoders E to 1 and τ to 1. We adoptAdam optimizer [35] and set the learning rate to 5e− 4. Thebatch size is fixed at 4 for MIMIC-III and 16 for MIMIC-IV.The best hyper-parameters are chosen by the PRAUC metricon the validation set. Specifically, α is tuned from 0.1 to 0.9,while β is searched from {0.1, 0.05, 0.01, 0.005, 0.001}. To3https://github.com/facebookresearch/llama/tree/llama v1facilitate the reproduction of our model, we release the codeonline 4.4) Evaluation Metrics: Following the previous works [3],[4], [6], [7], we apply three common metrics to evaluatethe proposed model, i.e., Precision-Recall AUC (PRAUC ↑),Jaccard Similarity Score (Jaccard ↑) and Average F1 Score(F1 ↑). To guarantee the robustness of the experimental results,we adopt bootstrapping sampling during the test process. Indetail, we randomly sample 80% samples in each round andthe metrics shown below are the averaged on 10-round tests.B. Overall Performance (RQ1)To respond to the research question (RQ1), we reveal theperformance comparison between the proposed method andcompetitors in Table IV and Table V. Then, we address theanalysis of the results.Overall, LEADER(T) performs a strong lead compared withall of the other models on two datasets, which indicates thesemantic understanding ability of the LLM. At the same time,the distilled student model, marked as LEADER(S), also out-performs existing state-of-the-art medication recommendationmodels. This phenomenon shows the success of the designeddistillation enhancement.Then, we probe the performance comparison according todifferent patient groups. As mentioned before, some recentbaselines, e.g., G-Bert, MICRON, COGNet and REFINE, con-sider the historical medication records as one of the necessaryinputs, so they do not have the results for single-visit patients.We first observe the multi-visit patient group. G-Bert performsthe worst, because it does not take patient’s procedures intoconsideration. Then, we can find that the three baselines(MICRON, COGNet and REFINE), which model the historicalprescriptions explicitly, can outperform the other competitorsin the multi-visit group. Such comparison illustrates utilizingprevious drug records can actually benefit the recommendationfor the current visit. The proposed LEADER(T) can surpass allmodels consistently due to the powerful ability of the LLM. Asfor the designed LEADER(S), it can outperform others on thePRAUC metric, but is worse than COGNet on Jaccard and F1.We think the reason lies in that COGNet adopts beam search4https://github.com/liuqidong07/LEADER-pytorchTABLE V: The overall results of competing baselines and LEADER on MIMIC-IV. The boldface refers to the highest score andthe underline indicates the best result of the models. “*” indicates the statistically significant improvements (i.e., two-sidedt-test with p < 0.05) over the best baseline. “-” represents the model cannot acquire the corresponding results due to theinability to the single-visit patients.Model Overall Multi-visit Single-visitPRAUC Jaccard F1 PRAUC Jaccard F1 PRAUC Jaccard F1RETAIN 0.6574 ± 0.0055 0.4152 ± 0.0044 0.5688 ± 0.0043 0.6576 ± 0.0044 0.4161 ± 0.0038 0.5693 ± 0.0040 0.6588 ± 0.0055 0.4165 ± 0.0035 0.5707 ± 0.0042G-Bert - - - 0.6237 ± 0.0028 0.3727 ± 0.0021 0.5169 ± 0.0022 - - -GAMENet 0.6720 ± 0.0030 0.4336 ± 0.0032 0.5871 ± 0.0030 0.6731 ± 0.0030 0.4339 ± 0.0020 0.5877 ± 0.0021 0.6671 ± 0.0049 0.4292 ± 0.0041 0.5819 ± 0.0040SafeDrug 0.6706 ± 0.0025 0.4295 ± 0.0027 0.5820 ± 0.0024 0.6752 ± 0.0031 0.4331 ± 0.0018 0.5860 ± 0.0017 0.6641 ± 0.0072 0.4214 ± 0.0073 0.5749 ± 0.0073MICRON - - - 0.6660 ± 0.0041 0.4414 ± 0.0027 0.5951 ± 0.0027 - - -COGNet - - - 0.6873 ± 0.0034 0.4638 ± 0.0028 0.6119 ± 0.0026 - - -REFINE - - - 0.6977 ± 0.0042 0.4538 ± 0.0047 0.6063 ± 0.0044 - - -LEADER(T) 0.7120 ± 0.0024* 0.4779 ± 0.0021* 0.6296 ± 0.0020* 0.7238 ± 0.0031* 0.4895 ± 0.0033* 0.6400 ± 0.0032* 0.6881 ± 0.0039* 0.4539 ± 0.0026* 0.6071 ± 0.0026*LEADER(S) 0.7020 ± 0.0022* 0.4483 ± 0.0025* 0.6005 ± 0.0026* 0.6994 ± 0.0037 0.4500 ± 0.0031 0.6023 ± 0.0029 0.7033 ± 0.0041* 0.4420 ± 0.0039* 0.5946 ± 0.0039*TABLE VI: The ablation study on two datasets. Due to limited space, only PRAUC scores are shown in the table.Model MIMIC-III MIMIC-IVOverall Multi-visit Single-visit Overall Multi-visit Single-visitLEADER(S) 0.7795 ± 0.0025 0.7830 ± 0.0019 0.7631 ± 0.0056 0.7020 ± 0.0022 0.6994 ± 0.0037 0.7033 ± 0.0041w/o KD 0.7673 ± 0.0026 0.7720 ± 0.0034 0.7464 ± 0.0052 0.6840 ± 0.0031 0.6853 ± 0.0044 0.6768 ± 0.0062w/o feature-KD 0.7672 ± 0.0024 0.7730 ± 0.0034 0.7448 ± 0.0058 0.6846 ± 0.0023 0.6865 ± 0.0028 0.6792 ± 0.0047w/o align 0.7774 ± 0.0017 0.7836 ± 0.0031 0.7579 ± 0.0054 0.6967 ± 0.0026 0.6987 ± 0.0039 0.6939 ± 0.0026w/o shared EV isit 0.7781 ± 0.0010 0.7830 ± 0.0022 0.7613 ± 0.0050 0.6985 ± 0.0021 0.7001 ± 0.0035 0.6923 ± 0.0045to generate the final recommendations, but it faces efficiencyissues.In terms of the performance in single-visit and overallgroups, GAMENet and SafeDrug are better than RETAIN,because they model the relations between medications morecarefully by EHR graph and molecule graph. However, theystill underperform the two variants of the proposed LEADERconsistently. On the one hand, LEADER can utilize thehistorical information and surpass baselines in the multi-visitgroup largely, which contributes to the overall scores. On theother hand, due to the semantic understanding ability of LLMs,LEADER(T) and LEADER(S) both surpass competitors in thesingle-visit group on two datasets. It is worth noting that thedistilled LEADER(S) is even better than LEADER(T) in thesingle-visit group under the PRAUC metric. This phenomenonindicates the benefits of the combination of collaborativesignals from the student model and semantic information fromLLMs.From the analysis, we conclude that the proposed LLM-based medication recommendation model shows a greatersemantic understanding ability and single-visit ability thanconventional models. Besides, the designed distillation methodcan actually enhance the derived student model.C. Ablation Study (RQ2)To verify the effectiveness of each proposed componentfor LEADER, we conduct ablation experiments. The resultsare shown in Table VI. Firstly, we aim to validate how thedesigned feature-level knowledge distillation has an effect onthe student model. w/o KD represents we remove the KD lossdirectly during the training of LEADER(S), while w/o feature-KD denotes using the KL-divergence of output probabilitybetween student and teacher model as the KD loss [36].From the results, we can find that these two variants bothunderperform the proposed LEADER(S) by a large margin.The drastic performance drop indicates that the feature-levelknowledge distillation can actually enhance the collaborativestudent model. Also, the designed feature-level KD is moresuitable for knowledge transfer from LLMs than traditionaloutput-level KD.Then, we seek to explore whether our design for thestudent model is reasonable. In Table VI, w/o align meansthat we leave out the profile alignment module proposedin Section III-C3. The experimental results illustrate thatthe alignment benefits the single-visit group more, whichcontributes to the overall performance elevation. The reasonmay be that the alignment can refine the representation ofthe profile, which is considered the only medication recordfor single-visit patients. w/o shared EV isit represents thatthe designed student model adopts a split visit encoder fordiagnosis, procedure and medication. This variant is worsethan LEADER(S), which shows that the shared encoder canhelp learn more general medical knowledge. As the responseto RQ2, we can conclude that the designed feature-level KDand other components in the student model are all beneficialto LEADER(S).D. Hyper-parameter Analysis (RQ3)To answer the RQ3, we adjust the strength of knowledgedistillation and profile alignment during the training. TheFigure 2 and Figure 3 show the performance change accordingto α and β, respectively. We observe that the performance ofLEADER(S) rises when α increases in a certain range. Thisphenomenon indicates that the knowledge transfer from theFig. 2: The results of experiments for the weight of knowledgedistillation loss α on two datasets.Fig. 3: The results of experiments for the weight of alignmentloss β on two datasets.LLM-based teacher model can benefit the collaborative model.However, too large scale of KD loss will confuse the modeltraining towards the ground-truth labels, so the PRAUC scoredrops with the continual increase of α. The best values of αfor MIMIC-III and MIMIC-IV are 0.4 and 0.8, respectively.In terms of profile alignment, the figure shows the generalperformance trend is up at first and then down with β changefrom 0.1 to 0. The reason why PRAUC increases at first isthat too large strength of contrastive loss will be harmful tothe model convergence. In contrast, since the alignment canhelp refine the representation of the profile, the PRAUC dropswhen β then decreases to 0. As a result, the best β for MIMIC-III and MIMIC-IV are 5e−3 and 1e−2, respectively.E. Efficiency Analysis (RQ4)As mentioned before, inference efficiency is an impor-tant issue in medical applications. Thus, we compare theefficiency between the LLM-based model and collaborativestudent model to respond RQ4. We apply the latency and GPUmemory to measure the efficiency. In detail, the latency iscalculated by averaging the total inference time of the test seton the number of test samples. Thus, the latency representsthe average waiting time to complete the recommendationfor one patient. The memory is the minimum GPU memoryrequirement for inference. The performance and efficiencycomparisons are shown in Figure 4. In the figure, LLMdenotes the general LLM, which outputs the medication nameas the final recommendation. It is worth noting that, for afair comparison, we adopt the same fine-tuning method (i.e.,LoRA) and foundation model (i.e., LlaMA-7b) for LLM andLRADER(T) in the experiments.LLM LEADER(T) LEADER(S)Fig. 4: The performance and inference cost comparison be-tween LLMs and distilled small model. The performance isevaluated by (a) Jaccard and (b) F1 score. The inference costis measured by (c) averaged inference time per sample and (d)necessary GPU memory.Observing the performance comparison, LLM underper-forms the LLM-based LEADER(T) with a large gap and iseven worse than LEADER(S). The results illustrate that thegeneral LLM for recommendation faces the out-of-corpuschallenge introduced in Section I. In contrast, our modifiedLLM can better inspire the semantic understanding ability ofLLM to complete the medication recommendation task. Asfor the efficiency comparison, we can find that LEADER(T)has a shorter latency than general LLM. It is caused bythe beam search during the word token generation, whilethe modified LLM can give out the probability in one run.In a word, the proposed modification of LLM can elevateeffectiveness and efficiency simultaneously. However, bothLLM-based medication recommendation models still posethe high inference costs problem. From the results, theproposed LEADER(S) can implement 25× ∼ 30× inferenceacceleration and only requires about 1/15 GPU memorycompared with the LEDAER(T). In summary, the designedLLM-distilled medication recommendation model can get abetter trade-off between performance and efficiency.V. RELATED WORKSA. Large Language Model for RecommendationRecently, the utilization of a large language model hasbeen a hotspot in the recommender system community [15],[37], [38]. There are two main lines of work in the field oflarge language model for recommendation (LLM4Rec). One istunable LLM4Rec, which often conducts fine-tuning to adaptthe LLMs to the recommendation task better. P5 [25] firstlyformulates the recommendation into a language generationtask and then integrates various recommendation tasks intoa unified language model. It fine-tunes a T5 [39] modelto equip it with the ability to generate recommendations.Then, the applications of larger models, such as LlaMA andChatGLM, bring more performance elevation. TALLRec [26]designs proper instructions integrated with the user’s his-torical records and fine-tunes a LlaMA-7b to complete thesequential recommendation. It is worth noting that parameter-efficient fine-tuning [28], [40], [41] is often adopted becauseof efficiency issues. InstructRec [42] fabricates the preference,intention and task form to compose the prompt input. Tofurther understand the users and shrink the prompt length,PALR [43] inserts the summary of the user profile ratherthan raw features into the prompt. More specifically, someresearch focuses on highlighting the item identity, whichis vital for RS, in the prompt. Chu et al. [44] designs anovel mask mechanism and position embedding to distinguishthe items from the lingual input when fine-tuning a GLMmodel. Furthermore, E4SRec [45] proposes to use the IDembedding accompanied with a linear projection to representthe items in the prompt. RecInterpreter [16] and LLaRA [46]share a similar idea of E4SRec, while they apply a pre-trained sequential recommender to encode the item identities.The other line is non-tunable LLM4Rec, which is mainlydevoted to designing the process flow for hyperscale LLMs,such as ChatGPT and GPT-4. For instance, Chat-Rec [47]reformulates the recommendation task into a conversationalprocess, and thus can utilize the ChatGPT to give out properrecommendations. Hou et al. [48] propose a combination ofseveral types of prompts to improve the ranking performance.Though existing works have taken an early step to adaptLLMs to recommendation, they still face several challenges,such as high inference costs and out-of-corpus. In this paper,we propose a novel method to address these two issues.B. Medication RecommendationMedication recommendation have been highlighted in recentyears, because of their practical values. In the early stageof the research, some works aim to model the relationshipbetween the diagnosis and prescriptions in the current visitcarefully. For example, Leap [49] captures the mutual effectsbetween several diagnoses and models the recommendationas a sequential decision-making process. Later, 4SDrug [50]proposes to measure the similarity between symptom andmedication sets for the recommendation. Furthermore, Zhanget al. [51] fabricates graph-based architecture to embed therelations between symptoms and medications via the knowl-edge graph and attributes. Compared with the models onlyusing the information from the current visit, many otherworks target modeling the historical treatment records forbetter performance. RETAIN [1] firstly develops a time-seriesprediction model for healthcare specially. GAMENet [3] andSafeDrug [4] both utilize the historical diagnosis and proce-dure data for medication recommendation and consider theproblem of drug-drug interaction. G-Bert [2] introduces thepre-train technique to get a better diagnosis and medicationencoders for the final recommendation. Moreover, some worksfurther intake the prescription history, which is an importantreference to the recommendation at that time. For instance,MICRON [5] and COGNet [6] both consider copying thehistorical prescriptions to the current recommending drug setin a certain probability. REFINE [7] directly inputs the recordsinto a transformer encoder for modeling. However, the existingmodels only utilize the identities to obtain the collaborativeinformation, while ignoring the medical semantics containedin EHR. As far as we know, we are the first to combine theLLM with medication recommendation for acquiring semanticknowledge.VI. CONCLUSIONIn this paper, we propose a large language model enhancedmedication by distillation (LEADER). To adapt the largelanguage model to the medication recommendation task, wefirst design the proper prompt templates to derive the lingualinput for LLM. Then, we substitute the head layer of LLMto alleviate the out-of-corpus problem and adopt the BCEloss to fine-tune the modified LLM. However, the LLM-basedmodel faces the challenge of high inference costs. For higherefficiency, we devise a feature-level knowledge distillationmethod to transfer the powerful ability of LLM to a relativelysmall student model. Through extensive experiments on twopublic datasets, we have verified that the proposed LEADERcan achieve effective and efficient medication recommendationcompared with existing state-of-the-art models. In terms offuture work, we will consider the drug-drug interaction inLLM-based medication recommendation, which is related tothe safety of prescriptions.REFERENCES[1] E. Choi, M. T. Bahadori, J. Sun, J. Kulas, A. Schuetz, and W. Stewart,“Retain: An interpretable predictive model for healthcare using reversetime attention mechanism,” Advances in neural information processingsystems, vol. 29, 2016.[2] J. Shang, T. Ma, C. Xiao, and J. Sun, “Pre-training of graph aug-mented transformers for medication recommendation,” arXiv preprintarXiv:1906.00346, 2019.[3] J. Shang, C. Xiao, T. Ma, H. Li, and J. Sun, “Gamenet: Graph aug-mented memory networks for recommending medication combination,”in proceedings of the AAAI Conference on Artificial Intelligence, vol. 33,no. 01, 2019, pp. 1126–1133.[4] C. Yang, C. Xiao, F. Ma, L. Glass, and J. Sun, “Safedrug: Dual moleculargraph encoders for recommending effective and safe drug combinations,”arXiv preprint arXiv:2105.02711, 2021.[5] C. Yang, C. Xiao, L. Glass, and J. Sun, “Change matters: Medicationchange prediction with recurrent residual networks,” arXiv preprintarXiv:2105.01876, 2021.[6] R. Wu, Z. Qiu, J. Jiang, G. Qi, and X. Wu, “Conditional generationnet for medication recommendation,” in Proceedings of the ACM WebConference 2022, 2022, pp. 935–945.[7] S. Bhoi, M.-L. Lee, W. Hsu, and N. C. Tan, “Refine: A fine-grainedmedication recommendation system using deep learning and personal-ized drug interaction modeling,” in Thirty-seventh Conference on NeuralInformation Processing Systems, 2023.[8] I. Rahmawati and V. I. D. Prastika, “Physician knowledge and responsi-bility of prescription policy,” Jurnal Administrasi Kesehatan IndonesiaVolume, vol. 8, no. 1, 2020.[9] Z. Ali, Y. Huang, I. Ullah, J. Feng, C. Deng, N. Thierry, A. Khan,A. U. Jan, X. Shen, W. Rui et al., “Deep learning for medicationrecommendation: a systematic survey,” Data Intelligence, vol. 5, no. 2,pp. 303–354, 2023.[10] Y. Li, Z. Li, K. Zhang, R. Dan, and Y. Zhang, “Chatdoctor: Amedical chat model fine-tuned on llama model using medical domainknowledge,” arXiv e-prints, pp. arXiv–2303, 2023.[11] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,J. Zhang, Z. Dong et al., “A survey of large language models,” arXivpreprint arXiv:2303.18223, 2023.[12] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le,D. Zhou et al., “Chain-of-thought prompting elicits reasoning in largelanguage models,” Advances in Neural Information Processing Systems,vol. 35, pp. 24 824–24 837, 2022.[13] V. Borisov, K. Sessler, T. Leemann, M. Pawelczyk, and G. Kasneci,“Language models are realistic tabular data generators,” in The EleventhInternational Conference on Learning Representations, 2022.[14] J. Chen, Z. Liu, X. Huang, C. Wu, Q. Liu, G. Jiang, Y. Pu, Y. Lei,X. Chen, X. Wang et al., “When large language models meet person-alization: Perspectives of challenges and opportunities,” arXiv preprintarXiv:2307.16376, 2023.[15] L. Wu, Z. Zheng, Z. Qiu, H. Wang, H. Gu, T. Shen, C. Qin, C. Zhu,H. Zhu, Q. Liu et al., “A survey on large language models forrecommendation,” arXiv preprint arXiv:2305.19860, 2023.[16] Z. Yang, J. Wu, Y. Luo, J. Zhang, Y. Yuan, A. Zhang, X. Wang, andX. He, “Large language model can interpret latent space of sequentialrecommender,” arXiv preprint arXiv:2310.20487, 2023.[17] X. Lin, W. Wang, Y. Li, F. Feng, S.-K. Ng, and T.-S. Chua, “A multi-facet paradigm to bridge large language model and recommendation,”arXiv preprint arXiv:2310.06491, 2023.[18] Z. Zheng, Z. Qiu, X. Hu, L. Wu, H. Zhu, and H. Xiong, “Genera-tive job recommendations with large language model,” arXiv preprintarXiv:2307.02157, 2023.[19] Y. Zhou, X. Lin, X. Zhang, M. Wang, G. Jiang, H. Lu, Y. Wu, K. Zhang,Z. Yang, K. Wang et al., “On the opportunities of green computing: Asurvey,” arXiv preprint arXiv:2311.00447, 2023.[20] J. Gruendner, T. Schwachhofer, P. Sippl, N. Wolf, M. Erpenbeck,C. Gulden, L. A. Kapsner, J. Zierk, S. Mate, M. Stürzl et al., “Ketos:Clinical decision support and machine learning as a service–a trainingand deployment platform based on docker, omop-cdm, and fhir webservices,” PloS one, vol. 14, no. 10, p. e0223010, 2019.[21] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y. Xu,W. Zheng, X. Xia et al., “Glm-130b: An open bilingual pre-trainedmodel,” in The Eleventh International Conference on Learning Repre-sentations, 2022.[22] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez,A. Joulin, E. Grave, and G. Lample, “Llama: Open and efficientfoundation language models,” arXiv preprint arXiv:2302.13971, 2023.[23] OpenAI, “Gpt-4 technical report,” arXiv preprint arXiv:2303.08774,2023.[24] K. Bao, J. Zhang, W. Wang, Y. Zhang, Z. Yang, Y. Luo, F. Feng, X. He,and Q. Tian, “A bi-step grounding paradigm for large language modelsin recommendation systems,” arXiv preprint arXiv:2308.08434, 2023.[25] S. Geng, S. Liu, Z. Fu, Y. Ge, and Y. Zhang, “Recommendation aslanguage processing (rlp): A unified pretrain, personalized prompt &predict paradigm (p5),” in Proceedings of the 16th ACM Conference onRecommender Systems, 2022, pp. 299–315.[26] K. Bao, J. Zhang, Y. Zhang, W. Wang, F. Feng, and X. He, “Tallrec: Aneffective and efficient tuning framework to align large language modelwith recommendation,” arXiv preprint arXiv:2305.00447, 2023.[27] H. Wang, C. Liu, N. Xi, Z. Qiang, S. Zhao, B. Qin, and T. Liu, “Huatuo:Tuning llama model with chinese medical knowledge,” 2023.[28] E. J. Hu, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chenet al., “Lora: Low-rank adaptation of large language models,” in Inter-national Conference on Learning Representations, 2021.[29] J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge distillation: Asurvey,” International Journal of Computer Vision, vol. 129, pp. 1789–1819, 2021.[30] K. Tirumala, A. Markosyan, L. Zettlemoyer, and A. Aghajanyan, “Mem-orization without overfitting: Analyzing the training dynamics of largelanguage models,” Advances in Neural Information Processing Systems,vol. 35, pp. 38 274–38 290, 2022.[31] S. Biderman, U. S. Prashanth, L. Sutawika, H. Schoelkopf, Q. Anthony,S. Purohit, and E. Raf, “Emergent and predictable memorization in largelanguage models,” arXiv preprint arXiv:2304.11158, 2023.[32] J. Li, D. Li, C. Xiong, and S. Hoi, “Blip: Bootstrapping language-imagepre-training for unified vision-language understanding and generation,”in International Conference on Machine Learning. PMLR, 2022, pp.12 888–12 900.[33] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal,G. Sastry, A. Askell, P. Mishkin, J. Clark et al., “Learning transferablevisual models from natural language supervision,” in Internationalconference on machine learning. PMLR, 2021, pp. 8748–8763.[34] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, “A simple frameworkfor contrastive learning of visual representations,” in Internationalconference on machine learning. PMLR, 2020, pp. 1597–1607.[35] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”arXiv preprint arXiv:1412.6980, 2014.[36] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neuralnetwork,” arXiv preprint arXiv:1503.02531, 2015.[37] L. Li, Y. Zhang, D. Liu, and L. Chen, “Large language models forgenerative recommendation: A survey and visionary discussions,” arXivpreprint arXiv:2309.01157, 2023.[38] W. Fan, Z. Zhao, J. Li, Y. Liu, X. Mei, Y. Wang, J. Tang, and Q. Li,“Recommender systems in the era of large language models (llms),”arXiv preprint arXiv:2307.02046, 2023.[39] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,Y. Zhou, W. Li, and P. J. Liu, “Exploring the limits of transferlearning with a unified text-to-text transformer,” The Journal of MachineLearning Research, vol. 21, no. 1, pp. 5485–5551, 2020.[40] X. Liu, Y. Zheng, Z. Du, M. Ding, Y. Qian, Z. Yang, and J. Tang, “Gptunderstands, too,” AI Open, 2023.[41] Q. Liu, X. Wu, X. Zhao, Y. Zhu, D. Xu, F. Tian, and Y. Zheng, “Moelora:An moe-based parameter efficient fine-tuning method for multi-taskmedical applications,” arXiv preprint arXiv:2310.18339, 2023.[42] J. Zhang, R. Xie, Y. Hou, W. X. Zhao, L. Lin, and J.-R. Wen, “Recom-mendation as instruction following: A large language model empoweredrecommendation approach,” arXiv preprint arXiv:2305.07001, 2023.[43] Z. Chen, “Palr: Personalization aware llms for recommendation,” arXivpreprint arXiv:2305.07622, 2023.[44] Z. Chu, H. Hao, X. Ouyang, S. Wang, Y. Wang, Y. Shen, J. Gu, Q. Cui,L. Li, S. Xue et al., “Leveraging large language models for pre-trainedrecommender systems,” arXiv preprint arXiv:2308.10837, 2023.[45] X. Li, C. Chen, X. Zhao, Y. Zhang, and C. Xing, “E4srec: An eleganteffective efficient extensible solution of large language models forsequential recommendation,” arXiv preprint arXiv:2312.02443, 2023.[46] J. Liao, S. Li, Z. Yang, J. Wu, Y. Yuan, X. Wang, and X. He, “Llara:Aligning large language models with sequential recommenders,” arXivpreprint arXiv:2312.02445, 2023.[47] Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, “Chat-rec: Towards interactive and explainable llms-augmented recommendersystem,” arXiv preprint arXiv:2303.14524, 2023.[48] Y. Hou, J. Zhang, Z. Lin, H. Lu, R. Xie, J. McAuley, and W. X.Zhao, “Large language models are zero-shot rankers for recommendersystems,” arXiv preprint arXiv:2305.08845, 2023.[49] Y. Zhang, R. Chen, J. Tang, W. F. Stewart, and J. Sun, “Leap: learning toprescribe effective and safe treatment combinations for multimorbidity,”in proceedings of the 23rd ACM SIGKDD international conference onknowledge Discovery and data Mining, 2017, pp. 1315–1324.[50] Y. Tan, C. Kong, L. Yu, P. Li, C. Chen, X. Zheng, V. S. Hertzberg,and C. Yang, “4sdrug: Symptom-based set-to-set small and safe drugrecommendation,” in Proceedings of the 28th ACM SIGKDD Conferenceon Knowledge Discovery and Data Mining, 2022, pp. 3970–3980.[51] Y. Zhang, X. Wu, Q. Fang, S. Qian, and C. Xu, “Knowledge-enhancedattributed multi-task learning for medicine recommendation,” ACMTransactions on Information Systems, vol. 41, no. 1, pp. 1–24, 2023.",
    "Link": "http://arxiv.org/abs/2402.02803"
}