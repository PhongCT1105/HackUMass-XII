{
    "Title": "Python bindings for the open source electromagnetic simulator Meep",
    "Authors": "Bienstman, Peter, Bogaerts, Wim, Fiers, Martin, Johnson, Steven G, Lambert, Emmanuel, Nizamov, Shavkat, Tassaert, Martijn",
    "Year": "No year available",
    "Abstract": "Meep is a broadly used open source package for finite-difference time-domain electromagnetic simulations. Python bindings for Meep make it easier to use for researchers and open promising opportunities for integration with other packages in the Python ecosystem. As this project shows, implementing Python-Meep offers benefits for specific disciplines and for the wider research community",
    "Keywords": "No keywords available",
    "Publisher": "'Institute of Electrical and Electronics Engineers (IEEE)'",
    "Publication Date": "No publication date available",
    "Journal": "No journal available",
    "Citation Count": 0,
    "Full Text": "Python bindings for the open source electromagnetic simulator \nMEEP.  \n \nEmmanuel Lambert1, Martin Fiers1, Shavkat Nizamov2, Martijn Tassaert1, Steven G. Johnson3, \nPeter Bienstman1, Wim Bogaerts1  \n1  \nGhent University - IMEC, Department of Information Technology (INTEC), Photonics Research Group, Sint-Pietersnieuwstraat \n41, B-9000 Gent, Belgium  \n2  \nSamarkand State University, Physics Faculty, 140104, University blvd. 15, Samarkand, Uzbekistan  \n \n3 \nMassachusetts Institute of Technology, Department of Mathematics, Center for Material Science & Engineering, Research \nLaboratory of Electronics, Cambridge MA 02139, USA \n \nPart of this work was funded by the European Union in the framework of the FP7 integrated \nproject HELIOS. Martin Fiers and Martijn Tassaert acknowledge the UGent Special Research \nFund for a doctoral grant. Shavkat Nizamov acknowledges the RFBR grant 09-02-90205. Wim \nBogaerts acknowledges the Flemish Fund for Scientific Research (FWO) for a postdoctoral \ngrant.  \nArticle abstract:  \n \nMeep is a broadly used and acknowledged open-source package for FDTD electromagnetic \nsimulations. We describe how Python bindings for Meep leverage the tool. We outline new \nperspectives for integration of Meep with other libraries in the Python ecosystem. We show that \nPython bindings allow using Meep more effectively in a large scale parallel computing \narchitecture. We describe the technical implementation of Python-Meep with SWIG and \ndescribe different architectures for interfacing data with the Meep core engine. Some \napplications of Python-Meep in our photonics and plasmonics research are briefly touched. We \nillustrate generic benefits to the wider research and open-source community.  \nIntroduction  \nIn photonics and microwave design, it is essential to be able to simulate the \npropagation of electromagnetic waves through sub-wavelength-scale structures \nwith high accuracy. One of the common approaches for this purpose is the \nfinite-difference-time-domain (FDTD) method [1]. Because it models Maxwell's \nequations in a fully vectorial way, it is one of the most powerful and general, \nbut rather brute-force techniques. It is computationally intensive but well \nsuited for massive parallelism, making it scalable on large clusters or \nsupercomputers. While several commercial and open-source FDTD packages \nare commonly used, many researchers have appreciated the excellent open-\nsource package Meep. Developed at MIT [2], it has a wide community of users. \nIn this article we describe how Python bindings for Meep leverage the tool in \nseveral ways and how the research community benefits from this extension.  \nIn the current standard version of Meep, a simulation is by default defined as a \nscript written in the Scheme language. Scheme is a powerful and compact \nprogramming language, derived from LISP and belonging to the group of \nfunctional programming languages [3][4]. It is mostly popular for educational \npurposes. Newcomers can however experience a threshold in getting started \nwith the language. Scheme is not inherently more difficult, but it has a \nsomewhat different syntax, coding convention and execution strategy than \nmore mainstream languages (the so-called imperative languages). Quite a lot \nof researchers interested in Meep are not familiar with this programming \nparadigm. On the other hand, Python follows a more traditional approach. Like \nScheme, it offers the benefit of being a dynamically typed language and is thus \nwell suited for scripting and rapid prototyping. It has become widely adopted \nduring the past decade both in the industry (for example the Google Apps \nEngine platform) and in many open source projects. It is especially popular in \nscientific and academic communities: there are many Python libraries available \n(mostly open source), covering a wide spectrum of functionalities. Some of \nthem will be discussed later in this article. Therefore, if Meep can be scripted \nthrough Python, it lowers the threshold for many researchers to use Meep and \nit allows for seamless integration with other existing Python software.  \nThe use of Python in our research   \nIn our research on silicon photonics (UGent/IMEC) and plasmonics (SSU), we \nhave deployed Python for many uses over the years. At UGent/IMEC, we have \ndeveloped a litho mask design toolkit for silicon photonics in pure Python. Add-\non tools and libraries have been developed for electromagnetic modeling, \ndesign optimization [5] and process simulation [6]. The long-term goal is to \nfurther automate closed-loop optimization of photonic circuits [7].  A powerful \ntool like Meep enriches our modeling framework. It broadens our research \ncapabilities in design optimization because we can now leverage fully vectorial \n3D FDTD simulations from inside a Python-driven design optimization process.  \nLeveraging Meep with Python     \n \nWe see several generic benefits that Python bindings bring to the wider \ncommunity of Meep users. Firstly, they enable the integration of Meep with \nexisting Python open source libraries for scientific computing. The most \nacknowledged are Numpy and SciPy [8]. Numpy is an extension to the Python \nlanguage which adds support for large, multi-dimensional matrix operations \nand related mathematical functions [9]. SciPy is a higher level library with \nmathematical tools and algorithms. Suppose for example that we want to \nexplore a certain parameter space for the optimal configuration of a photonic \nwaveguide (i.e. we want to simulate the electromagnetic behaviour of this \nwaveguide with Meep for various parameter values). Optimization algorithms \nsuch as simulated annealing (provided by SciPy) or genetic algorithms \n(provided by PyGene), can now be used to explore this parameter space on a \nsupercomputer and optimize against a certain target function. Numerical \nalgorithms offered by Numpy can be used for processing of simulation results.  \nCombining these libraries with Meep is a promising option for many researchers \nalready familiar with them. \n \nVisualization of the electromagnetic fields relies on external tools in the \ncurrently deployed versions of Meep (with files for interchange of data) and it is \nlargely a manual process. With Meep now being Python-aware, we can develop \nvisualization functionality using popular Python libraries such as Matplotlib (for \n2D) [10] and Mayavi2 (for 3D) [11] and tightly integrate them with the \nsimulation script. We can automatically generate the visualization of the \nwaveguide, the position of the excitation source and the data-collecting flux \nplanes. This allows for rapid, visual verification of the Meep script before \nrunning it. At UGent, we have built such functionality on top of the standard \nPython-Meep, which we integrated with a more general simulation framework \nused by our research group (for this latter reason, it is currently kept as a \nproprietary extension, not included in the public release of Python-Meep). The \nfigure below illustrates a 2D-visualization made by this framework. Because the \nPython bindings provide direct access to core Meep functionality, we could even \nmake a live visualization of the fluxes or the electromagnetic fields as the \nsimulation progresses. The latter has however not yet been implemented. \nGenerally speaking, such automated and advanced visualization functionalities \nsave time and can save reiterations of failed or ill-conditioned simulations.  \nFigure 1 illustrates the automatic visualization of a 2D simulation landscape based on Python-\nMeep and Matplotlib : it shows a ring resonator with access waveguide in silicon (red), the \nposition of the source (yellow line), two fluxplanes (green line) and a probing point (blue \ncircle).  \n The standard version of Meep can be enabled for MPI-run, which means that \nthe computation is distributed over multiple computing cores (on one or more \nnodes). MPI is an industry standard which defines message passing between \nsoftware components executing in parallel [12]. An FDTD algorithm can easily \nbe parallelized using MPI. We can split up the simulation problem in cells: in a \ngiven time step, the calculation for one cell is only dependent of the previous \nstate(s) of the cell and the boundaries of the surrounding cells. Each computing \ncore processes one cell and exchanges boundary information with its \nneighbors. The Python-Meep bindings are fully compatible with the MPI-\ncapabilities of Meep. However, such an MPI-distribution does not scale \ninfinitely: adding cores increases communication and synchronization overhead, \nwhich at some point limits further scaling. Even if we have a massive amount \nof cores at our disposal (such as on a supercomputer or cluster), we cannot \nefficiently exploit the full capacity with one MPI-run alone.  \nAt UGent we are developing a generic photonic simulation framework based on \nIPython [13].  This is a Python environment which is enhanced for parallel \ncomputing. It largely abstracts the technical aspects of parallel computing from \nthe user and allows robust error handling. It allows submitting scripts to a \ncontroller, which in turn scatters the code to engines on several nodes for \nexecution.  Results and exceptions are gathered back and presented to the \nclient shell in a user friendly manner.  \nThe Python bindings for Meep enable the integration of Meep with this IPython \nframework. Such integration shows a clear benefit. We can now combine MPI-\nruns of Python-Meep with the scatter-gather capabilities of IPython. In this \narchitecture, we basically have a 2-dimensional space over which we can \nspread a large number of simulations (e.g. in a parametric scan), as illustrated \nin figure 2a. The first dimension is the number of computing cores to which we \ncan scale one simulation in an MPI-run. The other dimension is the number of \ndifferent simulations that we want to run simultaneously (with each simulation \nassigned a set of MPI-enabled IPython engines). In this scheme, we can use \nthe capacity of a cluster or supercomputer in an optimal way for a large set of \nsimultaneous Python-Meep simulations. A user interface allows to launch \nsimulations for a certain set of parameters and to view the progress of a \nspecific simulation (figure 2c).  \n \nFigure 2a shows a schematical representation of 100 simulations (each with different \nparameter set) on a supercomputer. Each simulation executes in an IPython engine and is \nscaled with MPI over 16 computing cores. \n \n \nSuppose for example that we have a computer cluster with 1600 cores at our \ndisposal and that we want to scan a parameter space with 150 combinations of \nparameters. Let's assume that each simulation can be efficiently scaled over 16 \ncores with MPI. Combining MPI and IPython, we can run 100 Python-Meep \nsimulations simultaneously, with each simulation consuming 16 cores. If each \nsimulation takes 30 minutes to complete, then we can execute the full \nparameter space in just one hour (30 minutes for 100 simultaneous simulations \non 16 cores per simulation, followed by another 30 minutes for the subsequent \n50 simultaneous simulations).  \nBoth dimensions are independent of one another and have different scaling \nproperties. The scaling behaviour of Python-Meep over the first dimension (the \nnumber of cores for MPI-run) is similar to the standard Meep: the Python layer \ndoes not interfere with the MPI-specific commands in the Meep core. Figure 2b \nshows the scaling of a benchmark 3-dimensional simulation with MPI. The total \ncalculation time is shown for different resolutions (i.e. sizes of the \ncomputational volume). This is compared with the scaling that we ideally \nexpect: i.e. when we double the number of nodes, we expect the calculation \ntime to halve. For a given resolution, there is an upper limit to the number of \ncores over which we can scale efficiently. For a 3-dimensional simulation, the \ncommunication and synchronization overhead increases with the 4th power of \nthe number of computing cores. At some point, the added benefit of extra \ncalculation power is smaller than the additional overhead that is created: in \nsuch a case, the total calculation times even increases. In figure 2b, we can see \nthat scaling performance is better for more complex, high resolution problems. \n \nFigure 2b illustrates the scaling of a 3D Python-Meep simulation with MPI. The actual \ncalculation times are show for different resolutions and compared with the calculation times \nthat we ideally expect. \n  \nFor the second dimensions (the IPython engines), there is no inherent scaling \nlimit as the different IPython engines are essentially separated programs \nrunning in parallel, with no intercommunication. \nFigure 2c below shows a graphical user interface that was built with PyQt [14] \non top of this IPython based framework: we can conveniently launch new \nPython-Meep simulations and inspect results of simulations that have \nterminated.  \nFigure 2c illustrates the graphical user interface of the photonic simulation framework of UGent. \nIt shows the parameters used in a range of Python-Meep simulations with the corresponding \nresult for each simulation, i.e. the transmission calculated from the fluxes. It offers the \npossibility to inspect results and subsequently launch new simulations (with different \nparameters) to a computing cluster. This high level of automation aids in the rapid design of \nnew components.  \n A taste of Python-Meep  \nIn figure 3a, we give a short example of a Python-Meep script, so that readers \ncan get a flavor of the coding conventions. In this example, we calculate the \n2D-electromagnatic field profile in response to a line source located at the left \nof a straight waveguide. The Ez component of the field is periodically written to \na HDF5 file, which can then be further processed by the user (HDF5 is a \nstandard file format for scientific datasets [15]).  In figure 3b we show an \nequivalent script implemented with Scheme. From these code samples, it can \nbe seen that the Scheme version defines the problem more in terms of higher \nlevel expressions. Functional languages like Scheme are inherently very \nexpressive [16][17] and this feature was fully exploited by the authors of Meep \nwhen they created the Scheme interface. That way, they overcame the fairly \nlow level style of the Meep C++ core. Additionally, the Scheme interface was \ncomplemented with user-friendly functionality which is not available in the \nunderlying Meep C++ core (and thus not by default in Python-Meep).  \nThe Python-bindings directly expose the low-level Meep C++ core and this is \nreflected in the coding style of the Python script. In Python-Meep, we are now \nalso adding similar high level helper functions to facilitate the writing of \nsimulation scripts and we will increase this effort in future versions. While such \nfunctions are useful, they are however not necessary to use the functionalities \nthat Meep offers.  \nUsers of the Scheme interface are limited to using the functionality offered at \nthat level while users of Python-Meep have more flexibility: they can use both \nthe low-level functionality of the Meep C++ core and the higher-level helper \nfunctions that are being added to the Python interface.    \nFigures 3a/3b : a basic Python-Meep simulation script (a) and it’s equivalent in Scheme (b). \nNote that the coordinate system is different in both versions. \n \n  \nTechnical implementation of the Python bindings \nIntegrating the Meep callback mechanism \n \nThe Meep core library (written in C++) provides a mechanism of callbacks for \nintegration with the simulation script: whenever the runtime engine needs \ninformation about specific properties of the simulation, a function defined by \nthe user is called. This mechanism is used intensively, for example in the \ndefinition of the material properties of the simulation volume or in the definition \nof a custom electromagnetic source.  \nThe Python-Meep bindings were developed using SWIG, an open source tool \nthat allows connecting programs written in C/C++ with a variety of high-level \nprogramming languages [18]. The flexibility of SWIG allows for an elegant \nintegration with this callback mechanism. Based on our experiences with \nperformance and ease of use for the end user, the actual implementation \ntechnique evolved in three phases (described below and illustrated in figure 4). \nFigure 4 illustrates the alternative architectures that were implemented for definition of the \nmaterial properties in the simulation volume. First architecture: using a pure Python class for \ncallback (a). In this case, the C++/Python boundary is crossed whenever callback occurs \n(potentially millions of times for material definition).  Second architecture: using inline C/C++ \nfor large simulation volumes with many grid points (b): the callback occurs completely in the \nC/C++ domain (great performance).  Third architecture: the user works in Python only, \ncreating a Numpy matrix with the material definition (c). Meep can directly access this matrix \nusing a pointer, while the user works in pure Python (also with great performance but with \nincreased memory consumption).  \n \n In a first straightforward implementation, Python-Meep provides an abstract \nCallback class, from which the user inherits in pure Python. In that class, the \nuser implements the required functionality, such as definition of the material \nproperties (see figure 3). For many complex simulations however (i.e. with \nhigh resolution), the performance of this pure Python callback was not \nsufficient : the callback function for definition of the materials is typically called \na million times or more. The overhead of swapping from C++ to Python, \nsubsequently running a piece of interpreted Python code and returning the \nresults back to C++ is small, but it becomes problematic when the callback is \nexecuted hundreds of thousands or millions of times.  \nInitially, this drawback was solved by allowing users to define a callback \nfunction in C or C++, with the rest of the simulation script in Python. In this \nscheme, the user’s C++ code is compiled at runtime and dynamically linked \nwith the Python-Meep bindings: the callback is then done completely inside the \nC++ domain. This solution provides the required performance. The Python \npackage “weave” allows for very elegant inclusion of inline C/C++. It largely \nabstracts the overhead for the user of mixing Python with C/C++. \nNevertheless, combining 2 languages remains a drawback for certain end \nusers, many of whom are not familiar with C/C++.  \nIn the original Scheme interface, the performance issue with this repeated \ncallback occurs less often: in this implementation, the standard callback \nmechanism is largely bypassed by the authors of Meep. A tighter integration of \nthe C++ core and definitions in Scheme is realized.  \nWe subseqently worked towards a similar solution that would allow a pure \nPython definition of even complex high-resolution simulations. The \nbreakthrough came by combining SWIG with Numpy matrices. Numpy is known \nfor its great performance, thanks to the fact that Numpy stores and processes \nits data in C and exposes only a thin interface to Python. Therefore, if we \ndefine a Numpy matrix in Python with the material properties of our simulation \nvolume, that matrix is directly accessible from Meep using C coding \nconventions (basically a pointer). The integration then comes down to writing a \nwrapper around the Meep callback functionality. This wrapper retrieves the \nactual values from the Numpy matrix and returns them to Meep. Figure 4 \nfurther illustrates this architecture in contrast with the other two. Code-wise, \nwe provide a user-friendly class CallbackMatrix from which the user inherits. In \nthe class, he creates a Numpy matrix with size corresponding to the discretized \nsimulation volume (or a multiple for better accuracy). This architecture offers \nexcellent performance, while allowing the user to work in pure Python. A \ndrawback is the increased memory consumption, as we have to store the \nNumpy matrix before it is interfaced to Meep. Figure 5 illustrates the technique \nfor the straight waveguide example of figure 3.  \nFigure 5 : use of the technique with Numpy matrix for describing the straight waveguide of \nfigure 3. The user inherits from CallbackMatrix2D and assigns the Numpy matrix to an \nattribute. \n As we see in the last line of the code snippet of figure 5, the Python-Meep \nfunction set_matrix_2D is used for interfacing the Numpy matrix with the \nunderlying C++ code. In the C++ code of the Python-Meep wrapper, the \nfunction signature is : \n void set_matrix_2D(double* matrix, int dimX, int dimY, ...)  \n \nSimilarly, for a 3D-simulation we have : \n \n void set_matrix_3D(double* matrix, int dimX, int dimY, int dimZ, ...)  \n \nThe first parameter is of type double* and is a pointer to the actual values in \nthe Numpy matrix. The following two or three int parameters indicate the \nmatrix dimensions. In Python the matrix is of type numpy.ndarray.   \nWe want to seamlessly pass the Numpy matrix as parameter to the functions \nset_matrix_2D and set_matrix_3D. It is therefore required to define some kind \nof translation between the Python type numpy.ndarray and an equivalent tuple \nof parameters double* and int in C++. In SWIG, the technique for such a \ntranslation is called a typemap. Normally, the definition of typemaps is a \ncomplicated and tedious task. Luckily, a range of typemaps for Numpy are \nalready available in the open source community (\"numpy.i\" [19]). They are \ncalled IN_ARRAY2 and IN_ARRAY3 for respectively 2- and 3-dimensional Numpy \narrays. \nIn our SWIG definition file, we have to link up the signature of the \nset_matrix_2D function with the typemap. This is done using the code below. \nWhen we pass a Numpy array to the function in Python, it is automatically \nexpanded in the three or four corresponding parameters of the C++ function.  \n//Include the Numy header file, so that Numpy types are known \n%{ \n#define SWIG_FILE_WITH_INIT \n#include <numpy/npy_common.h> \n%} \n \n//Include the Numpy typemaps \n%include \"numpy.i\" \n \n%init %{ \n  import_array(); \n%} \n \n%apply (double* IN_ARRAY2, int DIM1, int DIM2)  \n       {(double* matrix2, int dimX, int dimY)};                                                        \n \n%apply (double* IN_ARRAY3, int DIM1, int DIM2, int DIM3)  \n       {(double* matrix3, int dimX, int dimY, int dimZ)}; \n \nSimilarly, typemaps were needed for interfacing parameters that represent \ncomplex numbers. Both Python and C++ have seperate definitions of a complex \ntype and thus a mapping or translation is required for seamless integration. \nThe definition of these typemaps is quite complicated. Interested readers can \nconsult the file py_complex.i in the public Python-Meep distribution. \nAll three of the above techniques for defining material matrices are available to \nusers of Python-Meep. The approach with the Numpy matrix is the preferred \none for simulations of moderate size. For very large simulation volumes, using \na C/C++ callback function may currently be more appropriate, as it has lower \nmemory requirements. In future versions, we are planning to explore PyTables \n[20] as an approach for processing very large matrices: PyTables combines \nHDF5 and Numpy and allows storing huge matrices on disk, thus limiting the \nmemory consumption. \n \nThe choice for SWIG \nInitially we compared both “SWIG” [18] and “Boost.Python” [21] as alternative \napproaches for implementing our Python wrapper.  \nBoost is a well established and recognized set of open source C++ libraries \nwhich runs on almost any operating system. “Boost.Python” is a subset which \nsupports seamless interopability between Python and C++. We had very good \nexperiences with “Boost.Python” during our evaluation: a tutorial is available, \nthe semantics of the API are clear and the amount of code that we had to write \nwas limited. However, there was one important drawback: during the technical \nbuild process, our code needed to be linked to Boost-specific dynamic libraries \n(dll’s). While these libraries can be compiled from source, they have a large \nfootprint. This is a major dependency which poses an additional threshold for \ndeployment on third party systems like a supercomputer for example. We \npreferred to keep Python-Meep lightweight with as little dependencies as \npossible. Therefore, we decided to use SWIG. \nSWIG is a dedicated framework for connecting C/C++ programs with a large \nvariety of programming languages. One must write an interface file from which \nthe SWIG engine generates two additional files: one file with C code and one \nfile with Python code. There are no other dependencies. Once this code is \ngenerated, it can be transferred to any operating system and compiled there. \nThe footprint is thus limited and a SWIG installation is not needed on the host \nsystem. The SWIG documentation is very detailed but the semantics of various \nconstructs are not always easy to understand. The technical implementation \nwas rather complicated and we needed a lot of trial and error before the \nrequired behaviour was obtained. Especially the definition of typemaps was \nerror prone and hard to debug. These were serious drawbacks, but once up and \nrunning, the Python/C++ interface works without a flaw. \nInterfacing external data with a Python-Meep script \nA frequently asked question in FDTD mailing lists concerns the problem of \nspecifying \"external\" sources, i.e. electromagnetic sources that are defined by \nsome other software and exported in the form of a datafile. Python has \nextensive features for interchanging data which come in handy in such a case. \nOne example is the excitation of a specific mode of a photonic waveguide (a \nphotonic waveguide can typically guide waves with specific profiles, called \nmodes). In realistic simulations, it is often required that only one specific mode \nis excited at a time. The only solution then is to create a source with the exact \nspatial amplitude shape of the mode that we want to excite. This problem is \nconveniently addressed with Python-Meep. The commercial package Fimmwave \nis well known for calculation of such modes [22]. We can use Fimmwave to \ncalculate the spatial amplitude profile of the mode that we want to excite and \nexport the resulting matrix to a text file. In Python-Meep, we create a callback \nfunction that uses this matrix to calculate the exact amplitude profile of the \nsource. We then run the Python-Meep simulation with a custom source that \nmatches accurately with the physical properties of the waveguide. At UGent, \nwe have implemented such an integration scheme between Fimmwave and \nPython-Meep in a couple of simulations. During these efforts, the availability of \nthe Python library Numpy proved useful: the resolution of the matrix that is \nexported by Fimmwave may not necessarily be the same as the resolution that \nwe want to use later on in the Meep FDTD simulations. Using Numpy, we could \nconveniently interpolate values to get the field profile value at each wanted \nposition in the FDTD grid. \n \nFigure 6 illustrates the field profile without spatial shaping of the source (a), versus a field \nprofile when the source is shaped according to an amplitude matrix calculated by Fimmwave \nand imported by Python-Meep (b). A field profile that is useful for a realistic design should have \na constant spatial distribution of the power intensity over time for a given cross-section: in (a), \nwe see that there are major changes over time in the spatial distribution of the power intensity \nfor the chosen cross-section. In constrast, the profile in (b) shows a constant spatial \ndistribution of the power intensity over the full length of the waveguide.  \n  \nOpen source \nThe Python-Meep bindings are distributed by its authors under the terms of the \nGNU General Public License (v2). The source code is publicly available on \nLaunchpad [23] and the community is invited to further contribute to the \nproject's development.  \nConclusion \nWe conclude that the recently released Python bindings for Meep bring \ninteresting benefits for the wider research and open source community. First of \nall, Python is a convenient alternative for those researchers who want to use \nMeep but are not familiar with the Scheme programming language. The Python \nbindings enable the integration of Meep with other software libraries in the \nPython ecosystem (such as libraries for visualization and libraries with \nnumerical and scientific algorithms).  We can also leverage the parallel \ncomputing capabilities of Meep by combining MPI with the IPython framework. \nWe discussed the technical implementation of the Python-Meep bindings with \nSWIG and three different architectures for interfacing data with the Meep core \nengine. We have illustrated how we use Python-Meep in our silicon photonics \nand plasmonics research. Some options for improvement in future versions \nwere discussed. We have released the Python-Meep bindings as open source: \nin this way, the community of users can contribute to its further development.   \nReferences : \n[1] - Allen Taflove and Susan C. Hagness (2005). Computational Electrodynamics: The Finite-\nDifference Time-Domain Method, 3rd ed. Artech House Publishers. ISBN 1-58053-832-0. \nhttp://www.artechhouse.com/Detail.aspx?strBookId=1123.  \n[2] - Ardavan F. Oskooi, David Roundy, Mihai Ibanescu, Peter Bermel, J. D. Joannopoulos, and \nSteven G. Johnson, \"MEEP: A flexible free-software package for electromagnetic simulations by \nthe FDTD method,\" Computer Physics Communications, vol. 181, pp. 687-702 (2010).  \n[3] - Gerald Jay Sussman and Guy Lewis Steele, Jr. (December 1975), \"Scheme: An \nInterpreter for Extended Lambda Calculus\" (postscript or PDF), AI Memos (MIT AI Lab) AIM-\n349 \n[4] - IEEE Standard for the Scheme Programming Language, IEEE part number STDPD14209. \n[5] - D. Vermeulen, G. Roelkens, J. Brouckaert, D. Van Thourhout, R. Baets, R. Duijn, E. Pluk, \nG. Van den Hoven, \"Silicon-on-insulator nanophotonic waveguide circuit for fiber-to-the home \ntransceivers\", ECOC, Belgium, p.Tu.3.C.6 (2008)  \n[6] - P. Bienstman, L. Vanholme, W. Bogaerts, P. Dumon, P. Vandersteegen, \"Python in \nNanophotonics Research\", Computing in Science & Engineering, 9(3), p.46-47 (2007)  \n[7]-  W. Bogaerts, P. Bradt, L. Vanholme, P. Bienstman, R. Baets, \"Closed-loop modeling of \nsilicon nanophotonics from design to fabrication and back again\", Optical and Quantum \nElectronics, 01/2009 - 40(11) p.801-811  \n \n[8] – Numpy and SciPy project page : http://www.scipy.org  \n \n[9] - Travis E. Oliphant, “Python for Scientific Computing”, Comput. Sci. Eng. 9, 10 (2007). \nFrom the same author, the book “Guide to Numpy” (December 7, 2006) was released in the \npublic domain. It can be downloaded at http://www.tramy.us/numpybook.pdf \n[10] – Matplotlib is an open source Python library for 2D plotting. \nhttp://matplotlib.sourceforge.net/ \n \n[11] – Mayavi2 is a Python library for 3D Scientific Data Visualization and Plotting.  \nhttp://code.enthought.com/projects/mayavi/ \n \n[12] - Gropp, William; Lusk, Ewing; Skjellum, Anthony (1994). “Using MPI: portable parallel \nprogramming with the message-passing interface”. MIT Press In Scientific And Engineering \nComputation Series, Cambridge, MA, USA. 307 pp. ISBN 0-262-57104-8  \n[13] - Fernando Perez, Brian E. Granger, \"IPython: A System for Interactive Scientific \nComputing,\" Computing in Science and Engineering, vol. 9, no. 3, pp. 21-29, May/June 2007, \ndoi:10.1109/MCSE.2007.53.  \n[14] - PyQt are Python bindings for Nokia's Qt application framework. It runs Windows, \nMacOS/X, Linux. http://www.riverbankcomputing.co.uk/software/pyqt/intro \n[15] – HDF5 is a set of file formats and libraries designed to store and organize large amounts \nof numerical data. Originally developed at the National Center for Supercomputing Applications, \nand currently supported by HDF Group. http://www.hdfgroup.org \n [16] - John Hughes. “Why Functional Programming Matters”, in D. Turner, editor, Research \nTopics in Functional Programming. Addison Wesley, 1990. \n \n[17] - M. P. Atkinson,Peter Buneman,Ronald Morrison, “Data types and persistence”, par 4.2.1 \n \n[18] - David M. Beazley - \"Using SWIG to Control, Prototype, and Debug C Programs with \nPython\". 4th International Python Conference, Livermore, California, June, 1996.  \n[19] – Bill Spotz, Sandia National Laboratories, “numpy.i: a SWIG Interface File for NumPy”, \nDecmber 2007, document available in the Numpy distribution. \n \n[20] – PyTables is a package for managing hierarchical datasets designed to efficiently cope \nwith extremely large amounts of data. http://www.pytables.org \n[21] - Boost.Python, a C++ library which enables seamless interoperability between C++ and  \nPython. http://www.boost.org/doc/libs/1_43_0/libs/python/doc/index.html \n[22] - Fimmwave by Photon Desgin : http://www.photond.com/products/fimmwave.htm  \n[23] - Python-meep project page: https://launchpad.net/python-meep  \n \n",
    "Link": "https://core.ac.uk/download/55802693.pdf"
}