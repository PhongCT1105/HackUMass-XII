{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Metadata:\n",
      "Title: A Hybrid Approach to Audio-to-Score Alignment\n",
      "Authors: Agrawal, R, Dixon, S, Machine Learning for Music Discovery Workshop at International Conference on Machine Learning (ICML)\n",
      "Year: No year available\n",
      "Abstract: None\n",
      "Full Text: A Hybrid Approach to Audio-to-Score AlignmentRuchit Agrawal 1 Simon Dixon 1AbstractAudio-to-score alignment aims at generating anaccurate mapping between a performance audioand the score of a given piece. Standard align-ment methods are based on Dynamic Time Warp-ing (DTW) and employ handcrafted features. Weexplore the usage of neural networks as a prepro-cessing step for DTW-based automatic alignmentmethods. Experiments on music data from dif-ferent acoustic conditions demonstrate that thismethod generates robust alignments whilst beingadaptable at the same time.1. Introduction and MotivationAudio-to-score alignment is the task of finding the optimalmapping between a performance and the score for a givenpiece of music. Dynamic Time Warping (Sakoe & Chiba,1978) has been the de facto standard for this task, typi-cally incorporating handcrafted features (Dixon, 2005; Arzt,2016). Recent advances in Music Information Retrievalhave demonstrated the efficacy of Deep Neural Networks(DNNs) to ...\n",
      "Link: https://core.ac.uk/download/334428924.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Load the API key from an environment variable\n",
    "API_KEY = os.getenv('CORE_API_KEY')\n",
    "BASE_URL = 'https://api.core.ac.uk/v3'\n",
    "\n",
    "def fetch_data(endpoint, params=None):\n",
    "    \"\"\"\n",
    "    Fetches data from the specified CORE API endpoint.\n",
    "    \n",
    "    Args:\n",
    "        endpoint (str): The endpoint of the API to call.\n",
    "        params (dict): Optional dictionary of parameters to include in the request.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The JSON response from the API as a dictionary.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}'\n",
    "    }\n",
    "    response = requests.get(f'{BASE_URL}/{endpoint}', headers=headers, params=params)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        # Raise an error if the request was not successful\n",
    "        response.raise_for_status()\n",
    "\n",
    "def get_single_research(query):\n",
    "    \"\"\"\n",
    "    Retrieves a single research article with selected metadata fields.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query (e.g., \"machine learning\").\n",
    "        \n",
    "    Returns:\n",
    "        dict: Selected metadata fields of the first research article that matches the search query.\n",
    "    \"\"\"\n",
    "    search_params = {\n",
    "        'q': query,\n",
    "        'page': 1,\n",
    "        'pageSize': 1\n",
    "    }\n",
    "    \n",
    "    # Search for articles\n",
    "    search_results = fetch_data('search/works', params=search_params)\n",
    "    \n",
    "    # Extract the first result's ID\n",
    "    if 'results' in search_results and len(search_results['results']) > 0:\n",
    "        article_id = search_results['results'][0]['id']\n",
    "        \n",
    "        # Fetch full metadata and text for the article\n",
    "        article_data = fetch_data(f'works/{article_id}')\n",
    "        \n",
    "        # Extract specific fields\n",
    "        title = article_data.get('title', 'No title available')\n",
    "        authors = [author.get('name', 'Unknown') for author in article_data.get('authors', [])]\n",
    "        year = article_data.get('year', 'No year available')\n",
    "        abstract = article_data.get('abstract', 'No abstract available')\n",
    "        full_text = article_data.get('fullText', 'No full text available')\n",
    "        full_text_link = article_data.get('downloadUrl', 'No link available')\n",
    "        \n",
    "        # Format and return selected metadata fields\n",
    "        return {\n",
    "            \"Title\": title,\n",
    "            \"Authors\": \", \".join(authors),\n",
    "            \"Year\": year,\n",
    "            \"Abstract\": abstract,\n",
    "            \"Full Text\": full_text[:1000] + '...' if len(full_text) > 1000 else full_text,  # Truncate for display\n",
    "            \"Link\": full_text_link\n",
    "        }\n",
    "    else:\n",
    "        print(\"No results found for the query.\")\n",
    "        return None\n",
    "\n",
    "# Example usage of the function\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"machine learning\"  # Change the query as needed\n",
    "    article = get_single_research(query)\n",
    "    \n",
    "    if article:\n",
    "        print(\"Selected Metadata:\")\n",
    "        for key, value in article.items():\n",
    "            print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
